{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PatchPal \u2014 An Agentic Coding and Automation Assistant","text":"<p>Supporting both local and cloud LLMs, with autopilot mode and extensible tools.</p> <p>PatchPal is an AI coding agent that helps you build software, debug issues, and automate tasks. It supports agent skills, tool use, and executable Python generation, enabling interactive workflows for tasks such as data analysis, visualization, web scraping, API interactions, and research with synthesized findings.</p> <p>Most agent frameworks are built in TypeScript. PatchPal is Python-native, designed for developers who want both interactive terminal use (<code>patchpal</code>) and programmatic API access (<code>agent.run(\"task\")</code>) in the same tool\u2014without switching ecosystems.</p> <p>Key Features</p> <ul> <li>Terminal Interface for interactive development</li> <li>Python SDK for flexibility and extensibility</li> <li>Built-In and Custom Tools</li> <li>Skills System</li> <li>Autopilot Mode using Ralph Wiggum loops</li> <li>Project Memory automatically loads project context from <code>~/.patchpal/repos/&lt;repo-name&gt;/MEMORY.md</code> at startup.</li> </ul> <p>PatchPal prioritizes customizability: custom tools, custom skills, a flexible Python API, and support for any tool-calling LLM.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>$ pip install patchpal  # install\n$ patchpal              # start\n</code></pre> <p>Platform support: Linux, macOS, and Windows are all supported</p>"},{"location":"#beyond-coding-general-problem-solving","title":"Beyond Coding: General Problem-Solving","text":"<p>While originally designed for software development, PatchPal is also a general-      purpose assistant. With web search, file operations, shell commands, and custom      tools/skills, it can help with research, data analysis, document processing, log     file analyses, etc.</p> <p></p>"},{"location":"configuration/","title":"Configuration","text":"<p>PatchPal can be configured through <code>PATCHPAL_*</code> environment variables to customize behavior, security, and performance.</p>"},{"location":"configuration/#model-selection","title":"Model Selection","text":"<pre><code>export PATCHPAL_MODEL=openai/gpt-5.2          # Override default model\n# Priority: CLI arg &gt; PATCHPAL_MODEL env var &gt; default (anthropic/claude-sonnet-4-5)\n\n# Extra LiteLLM parameters (JSON format)\nexport PATCHPAL_LITELLM_KWARGS='{\"reasoning_effort\": \"high\", \"temperature\": 0.7}'\n# Use for: reasoning models (gpt-oss, deepseek-reasoner), temperature, max_tokens, etc.\n# See: https://docs.litellm.ai/docs/completion/input\n</code></pre>"},{"location":"configuration/#security-permissions","title":"Security &amp; Permissions","text":""},{"location":"configuration/#maximum-security-mode","title":"Maximum Security Mode","text":"<p>For environments requiring the highest level of security, use the <code>--maximum-security</code> CLI flag:</p> <pre><code>patchpal --maximum-security\n</code></pre> <p>This single flag enables all security restrictions: - Permission for all operations: Requires approval for ALL operations including read operations (<code>read_file</code>, <code>list_files</code>, etc.) - Repository-only access: Blocks reading/writing files outside the repository directory (<code>PATCHPAL_RESTRICT_TO_REPO=true</code>) - Web access disabled: Disables web search and fetch tools to prevent data spillage (<code>PATCHPAL_ENABLE_WEB=false</code>)</p> <p>When to use: - Processing sensitive codebases with PII or confidential data - Working in compliance-driven environments (HIPAA, SOC2, etc.) - Evaluating untrusted prompts or skills</p> <p>Granular Control:</p> <p>You can also enable these restrictions individually:</p> <pre><code># Require permission for all operations (including reads)\npatchpal --require-permission-for-all\n\n# Or use environment variables for fine-grained control\nexport PATCHPAL_RESTRICT_TO_REPO=true  # Block access outside repository\nexport PATCHPAL_ENABLE_WEB=false       # Disable web access\npatchpal\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<pre><code># Permission System\nexport PATCHPAL_REQUIRE_PERMISSION=true      # Prompt before executing commands/modifying files (default: true)\n                                              # \u26a0\ufe0f  WARNING: Setting to false disables prompts - only use in trusted environments\n\n# File Safety\nexport PATCHPAL_MAX_FILE_SIZE=512000         # Maximum file size in bytes for read/write (default: 500KB)\n                                             # Applies to: text files, SVG files\n                                             # Reduced from 10MB to prevent context window explosions\nexport PATCHPAL_MAX_IMAGE_SIZE=10485760      # Maximum image file size in bytes (default: 10MB)\n                                             # Applies to: PNG, JPG, GIF, BMP, WEBP (not SVG)\n                                             # Images are formatted as multimodal content, bypassing tool output limits\n                                             # Vision APIs resize images automatically, so 1-2MB is optimal\nexport PATCHPAL_MAX_TOOL_OUTPUT_LINES=2000   # Maximum lines per tool output (default: 2000)\n                                             # Prevents any single tool from dominating context\nexport PATCHPAL_MAX_TOOL_OUTPUT_CHARS=100000 # Maximum characters per tool output (default: 100K)\n                                             # Applied after tool execution to all tool results\n                                             # Character-based (not bytes) to avoid breaking Unicode\nexport PATCHPAL_READ_ONLY=true               # Prevent ALL file modifications (default: false)\n                                             # Useful for: code review, exploration, security audits\nexport PATCHPAL_ALLOW_SENSITIVE=true         # Allow access to .env, credentials (default: false - blocked)\n                                             # Only enable with test/dummy credentials\nexport PATCHPAL_RESTRICT_TO_REPO=true        # Restrict file access to repository only (default: false)\n                                             # Prevents reading/writing files outside the repository directory\n                                             # Useful for: preventing PII leakage from external files\n                                             # Examples of blocked paths: /tmp/file.txt, ~/Documents/notes.txt, ../../etc/passwd\n\n# Command Safety\nexport PATCHPAL_ALLOW_SUDO=true              # Allow sudo/privilege escalation (default: false - blocked)\n                                              # \u26a0\ufe0f  WARNING: Only enable in trusted, controlled environments\nexport PATCHPAL_SHELL_TIMEOUT=60             # Shell command timeout in seconds (default: 30)\n\n# Output Filtering\nexport PATCHPAL_FILTER_OUTPUTS=true          # Filter verbose command outputs (default: true)\n                                              # Only applies to specific commands: test runners, git log, build tools\n                                              # Patterns matched: pytest, npm test, git log, pip install, cargo build, etc.\n                                              # Shows only failures, errors, and summaries for matched commands\n                                              # Can save 75%+ on output tokens for verbose commands\n                                              # All other commands return full output\nexport PATCHPAL_MAX_OUTPUT_LINES=500         # Max lines of shell output (default: 500)\n                                              # Applied to ALL shell commands to prevent context flooding\n                                              # If output exceeds this, shows first/last portions with truncation notice\n</code></pre>"},{"location":"configuration/#operational-controls","title":"Operational Controls","text":"<pre><code># Logging &amp; Auditing\nexport PATCHPAL_AUDIT_LOG=false              # Log operations to ~/.patchpal/repos/&lt;repo-name&gt;/audit.log (default: true)\nexport PATCHPAL_ENABLE_BACKUPS=true          # Auto-backup files before modification (default: false)\n\n# Streaming Output\nexport PATCHPAL_STREAM_OUTPUT=false          # Disable streaming progress indicator (default: true - enabled)\n                                              # When enabled, shows animated spinner + token counter during LLM API calls\n                                              # Helps detect when LLM is hanging vs. actively generating\n\n# Resource Limits\nexport PATCHPAL_MAX_OPERATIONS=10000         # Max operations per session (default: 10000)\nexport PATCHPAL_MAX_ITERATIONS=150           # Max agent iterations per task (default: 100)\n                                              # Increase for complex multi-file tasks\nexport PATCHPAL_LLM_TIMEOUT=300              # LLM API timeout in seconds (default: 300 = 5 minutes)\n                                              # Prevents indefinite stalls when API is unresponsive\n</code></pre>"},{"location":"configuration/#context-window-management","title":"Context Window Management","text":"<pre><code># Auto-Compaction\nexport PATCHPAL_DISABLE_AUTOCOMPACT=true     # Disable auto-compaction (default: false - enabled)\nexport PATCHPAL_COMPACT_THRESHOLD=0.75       # Trigger compaction at % full (default: 0.75 = 75%)\n\n# Context Limits\nexport PATCHPAL_CONTEXT_LIMIT=100000         # Override model's context limit (for testing)\n                                              # Leave unset to use model's actual capacity\n\n# Pruning Controls\nexport PATCHPAL_PROACTIVE_PRUNING=true       # Prune tool outputs after calls when &gt; PRUNE_PROTECT (default: true)\n                                              # Uses intelligent summarization to preserve context\nexport PATCHPAL_PRUNE_PROTECT=40000          # Keep last N tokens of tool outputs (default: 40000)\nexport PATCHPAL_PRUNE_MINIMUM=20000          # Minimum tokens to prune (default: 20000)\n</code></pre>"},{"location":"configuration/#mcp-model-context-protocol-integration","title":"MCP (Model Context Protocol) Integration","text":"<pre><code># Enable/Disable MCP Tools\nexport PATCHPAL_ENABLE_MCP=false             # Disable MCP tool loading (default: true - enabled)\n                                              # Useful for: testing, faster startup, minimal environments\n                                              # Note: MCP tools are loaded dynamically from ~/.patchpal/config.json\n</code></pre>"},{"location":"configuration/#minimal-tools-mode","title":"Minimal Tools Mode","text":"<pre><code># Limit to Essential Tools Only\nexport PATCHPAL_MINIMAL_TOOLS=true           # Enable minimal tools mode (default: false)\n                                              # Limits agent to 5 essential tools: read_file, edit_file, write_file, run_shell, grep\n                                              # Recommended for: local models &lt;20B params, models that struggle with tool selection\n                                              # Improves: decision speed (2-3s vs 10-30s), tool accuracy (~95% vs ~60%)\n                                              # Trade-off: No code_structure, web tools, TODO tools, etc.\n</code></pre>"},{"location":"configuration/#web-tools","title":"Web Tools","text":"<pre><code># Enable/Disable Web Access\nexport PATCHPAL_ENABLE_WEB=false             # Disable web search/fetch for air-gapped environments (default: true)\n\n# SSL Certificate Verification (for web_search)\nexport PATCHPAL_VERIFY_SSL=true              # SSL verification for web searches (default: true)\n                                              # Set to 'false' to disable (not recommended for production)\n                                              # Or set to path of CA bundle file for corporate certificates\n                                              # Auto-detects SSL_CERT_FILE and REQUESTS_CA_BUNDLE if not set\n                                              # Examples:\n                                              #   export PATCHPAL_VERIFY_SSL=false  # Disable verification\n                                              #   export PATCHPAL_VERIFY_SSL=/path/to/ca-bundle.crt  # Custom CA bundle\n                                              #   (Leave unset to auto-detect from SSL_CERT_FILE/REQUESTS_CA_BUNDLE)\n\n# Web Request Limits\nexport PATCHPAL_WEB_TIMEOUT=60               # Web request timeout in seconds (default: 30)\nexport PATCHPAL_MAX_WEB_SIZE=10485760        # Max web content size in bytes (default: 5MB)\n                                              # Character limits are controlled by PATCHPAL_MAX_TOOL_OUTPUT_CHARS\n</code></pre>"},{"location":"configuration/#custom-system-prompt","title":"Custom System Prompt","text":"<pre><code>export PATCHPAL_SYSTEM_PROMPT=~/.patchpal/my_prompt.md  # Use custom system prompt\n                                                          # File can use template variables: {platform_info}, {web_usage}\n                                                          # Useful for: custom behavior, team standards, domain-specific instructions\n</code></pre>"},{"location":"configuration/#configuration-examples","title":"Configuration Examples","text":"<p>Air-Gapped Environment (Offline, No Web Access): <pre><code>export PATCHPAL_ENABLE_WEB=false\npatchpal --model hosted_vllm/openai/gpt-oss-120b\n</code></pre></p> <p>Reasoning Model with High Effort: <pre><code>export PATCHPAL_MODEL=ollama_chat/gpt-oss:120b\nexport PATCHPAL_LITELLM_KWARGS='{\"reasoning_effort\": \"high\"}'\npatchpal\n</code></pre></p> <p>Maximum Security: <pre><code># Single flag for all security restrictions\npatchpal --maximum-security\n# Enables: permission for all ops, repo-only access, web disabled\n</code></pre></p> <p>Read-Only Mode (No File Modifications): <pre><code>export PATCHPAL_READ_ONLY=true\npatchpal\n# Agent can read files and run commands but cannot modify files\n</code></pre></p> <p>Testing Context Management: <pre><code>export PATCHPAL_CONTEXT_LIMIT=10000          # Small limit to trigger compaction quickly\nexport PATCHPAL_COMPACT_THRESHOLD=0.75       # Trigger at 75% instead of 85%\nexport PATCHPAL_PRUNE_PROTECT=500            # Keep only last 500 tokens\npatchpal\n</code></pre></p> <p>Autonomous Mode (Trusted Environment Only): <pre><code>export PATCHPAL_REQUIRE_PERMISSION=false     # \u26a0\ufe0f  Disables all permission prompts\nexport PATCHPAL_MAX_ITERATIONS=200           # Allow longer runs\npatchpal\n</code></pre></p> <p>Autopilot Mode (CI/CD Integration): <pre><code>export PATCHPAL_AUTOPILOT_CONFIRMED=true     # Skip autopilot safety confirmation (default: false)\n                                              # \u26a0\ufe0f  Only use in CI/CD or automation contexts\n                                              # Autopilot mode allows continuous iterative execution\npatchpal autopilot \"Implement feature X\"\n</code></pre></p> <p>Image Analysis with Vision Models: <pre><code># Anthropic/Claude (5MB limit via Bedrock or Direct API)\nexport PATCHPAL_MODEL=anthropic/claude-3-5-sonnet-20241022\npatchpal\n\n# OpenAI/GPT-4o (20MB limit)\nexport PATCHPAL_MODEL=openai/gpt-4o\npatchpal\n\n# Both work the same way from user perspective:\nYou: Look at screenshot.png and explain what's wrong\n\n# The agent automatically:\n# - Detects the model provider\n# - Formats images appropriately:\n#   * Anthropic: multimodal content in tool results\n#   * OpenAI: images injected as user messages (API workaround)\n\n# For images exceeding provider limits, increase PatchPal's limit:\nexport PATCHPAL_MAX_IMAGE_SIZE=$((20*1024*1024))  # 20MB\n\n# Tip: Use compressed images (1-2MB) for faster processing\n# Vision APIs resize large images automatically anyway\n\n# Block images for non-vision models (or for privacy):\nexport PATCHPAL_BLOCK_IMAGES=true                # Replace images with text placeholders (default: false)\n                                                 # Useful for:\n                                                 # - Non-vision models (gpt-3.5-turbo, claude-instant, local models)\n                                                 # - Privacy compliance (prevent image data from being sent)\n                                                 # Images are replaced with: \"[Image blocked - PATCHPAL_BLOCK_IMAGES=true...]\"\n</code></pre></p>"},{"location":"context-management/","title":"Context Management","text":"<p>PatchPal automatically manages the context window to prevent \"input too long\" errors during long coding sessions.</p> <p>Features: - Automatic token tracking: Monitors context usage in real-time - Smart pruning: Removes old tool outputs (keeps last 40k tokens) before resorting to full compaction - Auto-compaction: Summarizes conversation history when approaching 75% capacity - Manual control: Check status with <code>/status</code>, compact with <code>/compact</code>, prune with <code>/prune</code></p> <p>Commands: <pre><code># Check context window usage\nYou: /status\n\n# Output shows:\n# - Messages in history\n# - Token usage breakdown\n# - Visual progress bar\n# - Auto-compaction status\n# - Session statistics:\n#   - Total LLM calls made\n#   - Cumulative input tokens (all requests combined)\n#   - Cumulative output tokens (all responses combined)\n#   - Total tokens (helps estimate API costs)\n\n# Manually trigger compaction\nYou: /compact\n\n# Useful when:\n# - You want to free up context space before a large operation\n# - Testing compaction behavior\n# - Context is getting full but hasn't auto-compacted yet\n# Note: Requires at least 5 messages; most effective when context &gt;50% full\n\n# Manually prune old tool outputs\nYou: /prune\n\n# Useful when:\n# - Large tool outputs (e.g., from grep, file reads) are filling context\n# - You want to reclaim space without full compaction\n# - Testing pruning behavior\n# Note: Keeps last 2 conversational turns; prunes all older tool outputs\n</code></pre></p> <p>Understanding Session Statistics:</p> <p>The <code>/status</code> command shows cumulative token usage:</p> <ul> <li>Cumulative input tokens: Total tokens sent to the LLM across all calls</li> <li>Each LLM call resends the entire conversation history</li> <li> <p>Note on Anthropic models: PatchPal uses prompt caching</p> <ul> <li>System prompt and last 2 messages are cached</li> <li>Cached tokens cost much less than regular input tokens</li> <li>The displayed token counts show raw totals, not cache-adjusted costs</li> </ul> </li> <li> <p>Cumulative output tokens: Total tokens generated by the LLM</p> </li> <li>Usually much smaller than input (just the generated responses)</li> <li>Typically costs more per token than input</li> </ul> <p>Important: The token counts shown are raw totals and don't reflect prompt caching discounts. For accurate cost information, check your provider's usage dashboard which shows cache hits and actual billing.</p> <p>Configuration:</p> <p>See the Configuration section for context management settings including: - <code>PATCHPAL_DISABLE_AUTOCOMPACT</code> - Disable auto-compaction - <code>PATCHPAL_COMPACT_THRESHOLD</code> - Adjust compaction threshold - <code>PATCHPAL_CONTEXT_LIMIT</code> - Override context limit for testing - <code>PATCHPAL_PROACTIVE_PRUNING</code> - Prune tool outputs proactively after calls (default: true, uses smart summarization) - <code>PATCHPAL_PRUNE_PROTECT</code> / <code>PATCHPAL_PRUNE_MINIMUM</code> - Pruning controls</p> <p>Testing Context Management:</p> <p>You can test the context management system with small values to trigger compaction quickly:</p> <pre><code># Set up small context window for testing\nexport PATCHPAL_CONTEXT_LIMIT=10000      # Force 10k token limit (instead of 200k for Claude)\nexport PATCHPAL_COMPACT_THRESHOLD=0.75   # Trigger at 75% (default, but shown for clarity)\n                                         # Note: System prompt + output reserve = ~6.4k tokens baseline\n                                         # So 75% of 10k = 7.5k, leaving ~1k for conversation\nexport PATCHPAL_PRUNE_PROTECT=500        # Keep only last 500 tokens of tool outputs\nexport PATCHPAL_PRUNE_MINIMUM=100        # Prune if we can save 100+ tokens\n\n# Start PatchPal and watch it compact quickly\npatchpal\n\n# Generate context with tool calls (tool outputs consume tokens)\nYou: list all python files\nYou: read patchpal/agent.py\nYou: read patchpal/cli.py\n\n# Check status - should show compaction happening\nYou: /status\n\n# Continue - should see pruning messages\nYou: search for \"context\" in all files\n# You should see:\n# \u26a0\ufe0f  Context window at 75% capacity. Compacting...\n#    Pruned old tool outputs (saved ~400 tokens)\n# \u2713 Compaction complete. Saved 850 tokens (75% \u2192 58%)\n</code></pre> <p>How It Works:</p> <ol> <li>Phase 1 - Pruning: When context fills up, old tool outputs are pruned first</li> <li>Keeps last 40k tokens of tool outputs protected (only tool outputs, not conversation)</li> <li>Only prunes if it saves &gt;20k tokens</li> <li>Pruning is transparent and fast</li> <li> <p>Requires at least 5 messages in history</p> </li> <li> <p>Phase 2 - Compaction: If pruning isn't enough, full compaction occurs</p> </li> <li>Requires at least 5 messages to be effective</li> <li>LLM summarizes the entire conversation</li> <li>Summary replaces old messages, keeping last 2 complete conversation turns</li> <li>Work continues seamlessly from the summary</li> <li>Preserves complete tool call/result pairs (important for Bedrock compatibility)</li> </ol> <p>Example: <pre><code>Context Window Status\n======================================================================\n  Model: anthropic/claude-sonnet-4-5\n  Messages in history: 47\n  System prompt: 15,234 tokens\n  Conversation: 142,567 tokens\n  Output reserve: 4,096 tokens\n  Total: 161,897 / 200,000 tokens\n  Usage: 80%\n  [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591]\n\n  Auto-compaction: Enabled (triggers at 75%)\n======================================================================\n</code></pre></p> <p>The system ensures you can work for extended periods without hitting context limits.</p>"},{"location":"safety/","title":"Safety","text":"<p>The agent operates with a security model inspired by Claude Code:</p> <ul> <li>Permission system: User approval required for all shell commands and file modifications (can be customized)</li> <li>Write boundary enforcement: Write operations restricted to repository (matches Claude Code)</li> <li>Read operations allowed anywhere (system files, libraries, debugging, automation)</li> <li>Write operations outside repository require explicit permission</li> <li>Privilege escalation blocking: Platform-aware blocking of privilege escalation commands</li> <li>Unix/Linux/macOS: <code>sudo</code>, <code>su</code></li> <li>Windows: <code>runas</code>, <code>psexec</code></li> <li>Dangerous pattern detection: Blocks patterns like <code>&gt; /dev/</code>, <code>rm -rf /</code>, <code>| dd</code>, <code>--force</code></li> <li>Timeout protection: Shell commands timeout after 30 seconds</li> </ul>"},{"location":"safety/#security-guardrails-fully-enabled","title":"Security Guardrails \u2705 FULLY ENABLED","text":"<p>PatchPal includes comprehensive security protections enabled by default:</p> <p>Critical Security: - Permission prompts: Agent asks for permission before executing commands or modifying files (like Claude Code) - Sensitive file protection: Blocks access to <code>.env</code>, credentials, API keys - File size limits: Prevents OOM and context explosions with configurable size limits (500KB default) - Binary file detection: Blocks reading non-text files - Critical file warnings: Warns when modifying infrastructure files (package.json, Dockerfile, etc.) - Read-only mode: Optional mode that prevents all modifications - Command timeout: 30-second timeout on shell commands - Pattern-based blocking: Blocks dangerous command patterns (<code>&gt; /dev/</code>, <code>--force</code>, etc.) - Write boundary protection: Requires permission for write operations</p> <p>Operational Safety: - Operation audit logging: All file operations and commands logged to <code>~/.patchpal/repos/&lt;repo-name&gt;/audit.log</code> (enabled by default)   - Includes user prompts to show what triggered each operation   - Rotates at 10 MB with 3 backups (40 MB total max) - Command history: User commands saved to <code>~/.patchpal/repos/&lt;repo-name&gt;/history.txt</code> (last 1000 commands)   - Clean, user-friendly format for reviewing past interactions - Automatic backups: Optional auto-backup of files to <code>~/.patchpal/repos/&lt;repo-name&gt;/backups/</code> before modification - Resource limits: Configurable operation counter prevents infinite loops (10000 operations default) - Git state awareness: Warns when modifying files with uncommitted changes</p> <p>See the Configuration section for all available <code>PATCHPAL_*</code> environment variables to customize security, permissions, logging, and more.</p> <p>Permission System:</p> <p>When the agent wants to execute a command or modify a file, you'll see a prompt like:</p> <pre><code>================================================================================\nRun Shell\n--------------------------------------------------------------------------------\n   pytest tests/test_cli.py -v\n--------------------------------------------------------------------------------\n\nDo you want to proceed?\n  1. Yes\n  2. Yes, and don't ask again this session for 'pytest'\n  3. No, and tell me what to do differently\n\nChoice [1-3]:\n</code></pre> <ul> <li>Option 1: Allow this one operation</li> <li>Option 2: Allow for the rest of this session (like Claude Code - resets when you restart PatchPal)</li> <li>Option 3: Cancel the operation</li> </ul> <p>Advanced: You can manually edit <code>~/.patchpal/repos/&lt;repo-name&gt;/permissions.json</code> to grant persistent permissions across sessions.</p> <p>Example permissions.json:</p> <pre><code>{\n  \"run_shell\": [\"pytest\", \"npm\", \"git\"],\n  \"write_file\": true,\n  \"edit_file\": [\"config.py\", \"settings.json\"]\n}\n</code></pre> <p>Format: - <code>\"tool_name\": true</code> - Grant all operations for this tool (no more prompts) - <code>\"tool_name\": [\"pattern1\", \"pattern2\"]</code> - Grant only specific patterns (e.g., specific commands or file names)</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>Error: \"maximum iterations reached\" - The default number of iterations is 100. - Increase with <code>export PATCHPAL_MAX_ITERATIONS=200</code> (see Configuration)</p> <p>Error: \"Context Window Error - Input is too long\" - PatchPal includes automatic context management (compaction) to prevent this error. - Quick fix: Run <code>/prune</code> to remove old tool outputs, or <code>/compact</code> to compact the conversation history. - Use <code>/status</code> to check your context window usage and see how close you are to the limit. - If auto-compaction is disabled, re-enable it: <code>unset PATCHPAL_DISABLE_AUTOCOMPACT</code> - Context is automatically managed at 75% capacity through pruning and compaction. - Note: Token estimation may be slightly inaccurate compared to the model's actual counting. If you see this error despite auto-compaction being enabled, the 75% threshold may need to be lowered further for your workload. You can adjust it with <code>export PATCHPAL_COMPACT_THRESHOLD=0.70</code> (or lower). - See Configuration for context management settings.</p> <p>Reducing API Costs via Token Optimization</p> <p>When using cloud LLM providers (Anthropic, OpenAI, etc.), token usage directly impacts costs. PatchPal includes several features to help minimize token consumption:</p> <p>1. Use Pruning to Manage Long Sessions - Automatic pruning removes old tool outputs while preserving conversation context - Configure pruning thresholds to be more aggressive:   <pre><code>export PATCHPAL_PRUNE_PROTECT=20000    # Reduce from 40k to 20k tokens\nexport PATCHPAL_PRUNE_MINIMUM=10000    # Reduce minimum saved from 20k to 10k\n</code></pre> - Pruning happens transparently before compaction and is much faster (no LLM call needed)</p> <p>2. Monitor Session Token Usage - Use <code>/status</code> to see cumulative token usage in real-time - Session Statistics section shows:   - Total LLM calls made   - Cumulative input tokens (raw totals, before caching discounts)   - Cumulative output tokens   - Total tokens for the session - Check periodically during long sessions to monitor usage - Important: Token counts don't reflect prompt caching discounts (Anthropic models) - For actual costs, check your provider's usage dashboard which shows cache-adjusted billing</p> <p>3. Manual Context Management for Cost Control - Use <code>/status</code> regularly to monitor context window usage - Run <code>/prune</code> to remove old tool outputs (fast, no LLM call) - Run <code>/compact</code> proactively when context grows large (before hitting auto-compact threshold) - Manual control gives you flexibility over when to optimize context</p> <p>4. Adjust Auto-Compaction Threshold - Lower threshold = more frequent compaction = smaller context = lower per-request costs - Higher threshold = fewer compaction calls = larger context = higher per-request costs   <pre><code># More aggressive compaction (compact at 60% instead of 75%)\nexport PATCHPAL_COMPACT_THRESHOLD=0.60\n</code></pre> - Find the sweet spot for your workload (balance between compaction frequency and context size)</p> <p>5. Use Local Models for Zero API Costs - Best option: Run vLLM locally to eliminate API costs entirely   <pre><code>export HOSTED_VLLM_API_BASE=http://localhost:8000\nexport HOSTED_VLLM_API_KEY=token-abc123\npatchpal --model hosted_vllm/openai/gpt-oss-120b\n</code></pre> - Alternative: Use Ollama (requires <code>OLLAMA_CONTEXT_LENGTH=32768</code>) - See Using Local Models for setup</p> <p>6. Start Fresh When Appropriate - Use <code>/clear</code> command to reset conversation history without restarting PatchPal - Exit and restart PatchPal between unrelated tasks to clear context completely - Each fresh start begins with minimal tokens (just the system prompt) - Better than carrying large conversation history across different tasks</p> <p>7. Use Smaller Models for Simple Tasks - Use less expensive models for routine tasks:   <pre><code>patchpal --model anthropic/claude-3-7-sonnet-latest  # Cheaper than claude-sonnet-4-5\npatchpal --model openai/gpt-5-mini                   # Cheaper than gpt-5.2\n</code></pre> - Reserve premium models for complex reasoning tasks</p> <p>Cost Monitoring Tips: - Check <code>/status</code> before large operations to see current token usage - Anthropic models: Prompt caching reduces costs (system prompt + last 2 messages cached)</p> <ul> <li>Most cloud providers offer usage dashboards showing cache hits and actual charges</li> <li>Set up billing alerts with your provider to avoid surprises</li> <li>Consider local models (vLLM recommended) for high-volume usage or zero API costs</li> </ul>"},{"location":"features/custom-tools/","title":"Custom Tools","text":"<p>Custom tools extend PatchPal's capabilities by adding new Python functions that the agent can call. Unlike skills (which are prompt-based workflows), custom tools are executable Python code that the agent invokes automatically when needed.</p> <p>Key Differences: - Skills: Markdown files with instructions for the agent to follow - Custom Tools: Python functions that execute code and return results</p>"},{"location":"features/custom-tools/#installation","title":"Installation","text":"<p>Custom tools can be installed globally (available in all projects) or locally (specific to a repository).</p>"},{"location":"features/custom-tools/#global-tools","title":"Global Tools","text":"<ol> <li> <p>Create the global tools directory: <pre><code>mkdir -p ~/.patchpal/tools\n</code></pre></p> </li> <li> <p>Copy the example tools (or create your own): <pre><code># After pip install patchpal, get the example tools\ncurl -L https://github.com/amaiya/patchpal/archive/main.tar.gz | tar xz --strip=1 patchpal-main/examples\n\n# Copy to your tools directory\ncp examples/tools/calculator.py ~/.patchpal/tools/\n</code></pre></p> </li> </ol>"},{"location":"features/custom-tools/#repository-specific-tools","title":"Repository-Specific Tools","text":"<p>For project-specific tools that shouldn't be available globally:</p> <ol> <li> <p>Create the repository tools directory: <pre><code>mkdir -p .patchpal/tools\n</code></pre></p> </li> <li> <p>Add your custom tools: <pre><code># Example: Create a project-specific tool\ncat &gt; .patchpal/tools/project_tool.py &lt;&lt; 'EOF'\ndef get_project_info(key: str) -&gt; str:\n    \"\"\"Get project-specific information.\n\n    Args:\n        key: Information key to retrieve\n    \"\"\"\n    info = {\"name\": \"MyProject\", \"version\": \"1.0.0\"}\n    return info.get(key, \"Unknown\")\nEOF\n</code></pre></p> </li> <li> <p>Tools are loaded automatically: <pre><code>$ patchpal\n================================================================================\nPatchPal - AI coding and automation assistant\n================================================================================\n\nUsing model: anthropic/claude-sonnet-4-5\n\ud83d\udd27 Loaded 8 custom tool(s): add, subtract, multiply, divide, calculate_percentage, fahrenheit_to_celsius, celsius_to_fahrenheit, get_project_info\n</code></pre></p> </li> </ol> <p>Note: Repository-specific tools with the same name will override global tools.</p>"},{"location":"features/custom-tools/#creating-custom-tools","title":"Creating Custom Tools","text":"<p>Custom tools are Python functions with specific requirements:</p> <p>Requirements: 1. Type hints for all parameters 2. Docstring with description and Args section (Google-style) 3. Module-level functions (not nested inside classes) 4. Return type should typically be <code>str</code> (for LLM consumption) 5. Function names cannot start with underscore (private functions ignored)</p> <p>Example:</p> <pre><code># ~/.patchpal/tools/my_tools.py\n\ndef calculator(x: int, y: int, operation: str = \"add\") -&gt; str:\n    \"\"\"Perform basic arithmetic operations.\n\n    Args:\n        x: First number\n        y: Second number\n        operation: Operation to perform (add, subtract, multiply, divide)\n\n    Returns:\n        Result as a string\n    \"\"\"\n    if operation == \"add\":\n        return f\"{x} + {y} = {x + y}\"\n    elif operation == \"subtract\":\n        return f\"{x} - {y} = {x - y}\"\n    elif operation == \"multiply\":\n        return f\"{x} * {y} = {x * y}\"\n    elif operation == \"divide\":\n        if y == 0:\n            return \"Error: Cannot divide by zero\"\n        return f\"{x} / {y} = {x / y}\"\n    return \"Unknown operation\"\n\n\ndef convert_currency(amount: float, from_currency: str, to_currency: str) -&gt; str:\n    \"\"\"Convert between currencies.\n\n    Args:\n        amount: Amount to convert\n        from_currency: Source currency code (e.g., USD)\n        to_currency: Target currency code (e.g., EUR)\n\n    Returns:\n        Converted amount as a string\n    \"\"\"\n    # Your implementation here (API call, etc.)\n    # This is just a simple example\n    rates = {\"USD\": 1.0, \"EUR\": 0.85, \"GBP\": 0.73}\n    usd_amount = amount / rates.get(from_currency, 1.0)\n    result = usd_amount * rates.get(to_currency, 1.0)\n    return f\"{amount} {from_currency} = {result:.2f} {to_currency}\"\n</code></pre>"},{"location":"features/custom-tools/#using-custom-tools","title":"Using Custom Tools","text":"<p>Once loaded, the agent calls your custom tools automatically:</p> <pre><code>You: What's 15 + 27?\nAgent: [Calls calculator(15, 27, \"add\")]\n        15 + 27 = 42\n\nYou: What's 100 divided by 4?\nAgent: [Calls calculator(100, 4, \"divide\")]\n        100 / 4 = 25\n\nYou: Convert 100 USD to EUR\nAgent: [Calls convert_currency(100, \"USD\", \"EUR\")]\n        100 USD = 85.00 EUR\n</code></pre>"},{"location":"features/custom-tools/#tool-discovery","title":"Tool Discovery","text":"<p>PatchPal discovers tools from two locations at startup:</p> <ol> <li>Global tools: <code>~/.patchpal/tools/*.py</code> - Available in all projects</li> <li>Repository-specific tools: <code>&lt;repo&gt;/.patchpal/tools/*.py</code> - Only available in that repository</li> </ol> <p>All <code>.py</code> files in these directories are scanned for valid tool functions. Repository-specific tools with the same name will override global tools.</p> <p>What Gets Loaded: - \u2705 Functions with type hints and docstrings - \u2705 Multiple functions per file - \u2705 Files can import standard libraries - \u274c Functions without type hints - \u274c Functions without docstrings - \u274c Private functions (starting with <code>_</code>) - \u274c Imported functions (must be defined in the file)</p>"},{"location":"features/custom-tools/#example-tools","title":"Example Tools","text":"<p>The repository includes example tools that demonstrate different use cases:</p>"},{"location":"features/custom-tools/#calculatorpy","title":"calculator.py","text":"<p>Basic arithmetic and temperature conversion (7 tools):</p> <ul> <li><code>add(x, y)</code> - Add two integers</li> <li><code>subtract(x, y)</code> - Subtract two integers</li> <li><code>multiply(x, y)</code> - Multiply two floats</li> <li><code>divide(x, y)</code> - Divide two floats (with zero check)</li> <li><code>calculate_percentage(value, percentage)</code> - Calculate percentage of value</li> <li><code>fahrenheit_to_celsius(fahrenheit)</code> - Convert F to C</li> <li><code>celsius_to_fahrenheit(celsius)</code> - Convert C to F</li> </ul> <p>Requirements: No external dependencies (uses Python standard library)</p> <p>Example usage: <pre><code>You: What's 25 + 17?\nAgent: [Calls add tool automatically]\n        25 + 17 = 42\n\nYou: Convert 72\u00b0F to Celsius\nAgent: [Calls fahrenheit_to_celsius tool]\n        72\u00b0F = 22.22\u00b0C\n</code></pre></p>"},{"location":"features/custom-tools/#system_toolspy","title":"system_tools.py","text":"<p>Get system information and analyze disk usage (6 tools):</p> <ul> <li><code>get_disk_usage(path)</code> - Show disk usage statistics for a path</li> <li><code>get_system_info()</code> - Get OS, Python version, and architecture info</li> <li><code>get_env_var(var_name)</code> - Get an environment variable (masks sensitive values)</li> <li><code>list_env_vars(filter_pattern)</code> - List environment variables with optional filter</li> <li><code>get_directory_size(directory)</code> - Calculate total size of a directory</li> <li><code>check_path_exists(path)</code> - Check if path exists and show info</li> </ul> <p>Requirements: No external dependencies (uses Python standard library)</p> <p>Example usage: <pre><code>You: What's the disk usage for the current directory?\nAgent: [Calls get_disk_usage(\".\")]\n\nYou: Show me system information\nAgent: [Calls get_system_info()]\n\nYou: What's the value of PATH?\nAgent: [Calls get_env_var(\"PATH\")]\n\nYou: How big is the examples directory?\nAgent: [Calls get_directory_size(\"examples\")]\n</code></pre></p>"},{"location":"features/custom-tools/#github_toolspy","title":"github_tools.py","text":"<p>Search and get information from GitHub API (3 tools):</p> <ul> <li><code>search_github_repos(query, language, max_results)</code> - Search repositories</li> <li><code>get_github_user(username)</code> - Get user profile information</li> <li><code>get_repo_info(owner, repo)</code> - Get detailed repository info</li> </ul> <p>Requirements: <code>pip install requests</code></p> <p>Example usage: <pre><code>You: Search for Python machine learning repos\nAgent: [Calls search_github_repos(\"machine learning\", \"Python\", 5)]\n\nYou: Get info about torvalds\nAgent: [Calls get_github_user(\"torvalds\")]\n\nYou: Show details for amaiya/patchpal\nAgent: [Calls get_repo_info(\"amaiya\", \"patchpal\")]\n</code></pre></p> <p>View the examples/tools/ directory for complete source code.</p>"},{"location":"features/custom-tools/#real-world-tool-ideas","title":"Real-World Tool Ideas","text":"<p>Here are some ideas for custom tools you might create:</p> <p>API Integration: <pre><code>def get_weather(city: str) -&gt; str:\n    \"\"\"Get current weather for a city.\n\n    Args:\n        city: City name\n    \"\"\"\n    # Call weather API (e.g., OpenWeatherMap)\n    # Return formatted weather information\n    pass\n</code></pre></p> <p>Database Queries: <pre><code>def query_users(limit: int = 10) -&gt; str:\n    \"\"\"Query database for users.\n\n    Args:\n        limit: Maximum number of users to return\n    \"\"\"\n    # Execute SQL query\n    # Return formatted results\n    pass\n</code></pre></p> <p>File Processing: <pre><code>def parse_csv(filepath: str) -&gt; str:\n    \"\"\"Parse CSV file and return summary.\n\n    Args:\n        filepath: Path to CSV file\n    \"\"\"\n    import csv\n    # Process file and return statistics\n    pass\n</code></pre></p> <p>System Operations: <pre><code>def backup_directory(source: str, destination: str) -&gt; str:\n    \"\"\"Create a backup of a directory.\n\n    Args:\n        source: Source directory path\n        destination: Backup destination path\n    \"\"\"\n    import shutil\n    # Create backup and return status\n    pass\n</code></pre></p> <p>The agent will automatically discover and use your tools when they're relevant to the user's request!</p>"},{"location":"features/custom-tools/#security-note","title":"Security Note","text":"<p>\u26a0\ufe0f Custom tools execute arbitrary Python code on your system. Only install tools from sources you trust.</p> <p>Tool Locations: - Global tools: <code>~/.patchpal/tools/</code> - Your personal tools directory - Repository-specific tools: <code>&lt;repo&gt;/.patchpal/tools/</code> - Project-specific tools</p> <p>Security Considerations: - Tools run with your user permissions - Repository-specific tools make it easy to share project-specific functionality - Review tools in <code>.patchpal/tools/</code> when cloning repositories - Repository tools override global tools with the same name</p>"},{"location":"features/custom-tools/#advanced-features","title":"Advanced Features","text":"<p>Optional Parameters: <pre><code>from typing import Optional\n\ndef greet(name: str, greeting: Optional[str] = \"Hello\") -&gt; str:\n    \"\"\"Greet someone.\n\n    Args:\n        name: Person's name\n        greeting: Optional greeting message (default: \"Hello\")\n    \"\"\"\n    return f\"{greeting}, {name}!\"\n</code></pre></p> <p>Complex Types: <pre><code>from typing import List\n\ndef sum_numbers(numbers: List[int]) -&gt; str:\n    \"\"\"Sum a list of numbers.\n\n    Args:\n        numbers: List of integers to sum\n    \"\"\"\n    total = sum(numbers)\n    return f\"Sum of {numbers} = {total}\"\n</code></pre></p>"},{"location":"features/custom-tools/#using-custom-tools-in-python-api","title":"Using Custom Tools in Python API","text":"<p>Custom tools can also be used programmatically when using PatchPal as a library:</p> <pre><code>from patchpal.agent import create_agent\n\ndef calculator(x: int, y: int) -&gt; str:\n    \"\"\"Add two numbers.\n\n    Args:\n        x: First number\n        y: Second number\n    \"\"\"\n    return str(x + y)\n\ndef get_user_count() -&gt; str:\n    \"\"\"Get the current user count from database.\n\n    Returns:\n        User count as a string\n    \"\"\"\n    # Your database logic here\n    return \"Total users: 1,234\"\n\n# Create agent with custom tools\nagent = create_agent(custom_tools=[calculator, get_user_count])\n\n# The agent can now use these tools automatically\nresponse = agent.run(\"What's 5 + 3?\")\n# Agent will call calculator(5, 3) automatically\n\nresponse = agent.run(\"How many users do we have?\")\n# Agent will call get_user_count() automatically\n</code></pre> <p>See the Python API documentation for more details.</p>"},{"location":"features/custom-tools/#troubleshooting","title":"Troubleshooting","text":"<p>If tools aren't loading: 1. Check the file has a <code>.py</code> extension 2. Ensure functions have type hints for all parameters 3. Verify docstrings follow Google style (with Args: section) 4. Look for warning messages when starting PatchPal 5. Test the function directly in Python to check for syntax errors</p> <p>Example warning message: <pre><code>\u26a0\ufe0f  Warning: Failed to load custom tool from broken.py: missing type hints\n</code></pre></p>"},{"location":"features/mcp/","title":"MCP (Model Context Protocol)","text":"<p>PatchPal supports the Model Context Protocol (MCP), enabling AI assistants to connect to external data sources and tools through both local and remote MCP servers.</p>"},{"location":"features/mcp/#quick-start","title":"Quick Start","text":""},{"location":"features/mcp/#1-install-mcp-support","title":"1. Install MCP Support","text":"<pre><code>pip install patchpal[mcp]\n</code></pre>"},{"location":"features/mcp/#2-add-an-mcp-server","title":"2. Add an MCP Server","text":"<p>Using the CLI (recommended):</p> <pre><code># Add a remote server\npatchpal-mcp add huggingface https://huggingface.co/mcp \\\n  --header \"Authorization: Bearer ${HF_TOKEN}\"\n\n# Add a local server\npatchpal-mcp add filesystem --transport stdio -- \\\n  npx -y @modelcontextprotocol/server-filesystem /path/to/dir\n\n# List configured servers\npatchpal-mcp list\n\n# Test a server connection\npatchpal-mcp test huggingface\n</code></pre>"},{"location":"features/mcp/#3-use-in-patchpal","title":"3. Use in PatchPal","text":"<pre><code>patchpal\n\n# In session - use MCP commands\n&gt; /mcp servers        # List configured servers\n&gt; /mcp tools          # Show all MCP tools\n&gt; /mcp resources      # List resources (view only)\n&gt; /mcp prompts        # List prompts (view only)\n&gt; /mcp help           # Show MCP commands\n</code></pre> <p>MCP tools are automatically loaded and available to the agent (e.g., <code>filesystem_read_file</code>, <code>hf_model_search</code>).</p>"},{"location":"features/mcp/#configuration","title":"Configuration","text":"<p>MCP servers are configured in JSON files. PatchPal merges configurations from: - Global: <code>~/.patchpal/mcp-config.json</code> (used across all projects) - Project: <code>.patchpal/mcp-config.json</code> (project-specific, overrides global)</p>"},{"location":"features/mcp/#local-servers-stdio","title":"Local Servers (stdio)","text":"<p>Run as processes on your machine:</p> <pre><code>{\n  \"mcp\": {\n    \"filesystem\": {\n      \"type\": \"local\",\n      \"command\": [\"npx\", \"-y\", \"@modelcontextprotocol/server-filesystem\", \"/allowed/path\"],\n      \"enabled\": true\n    }\n  }\n}\n</code></pre>"},{"location":"features/mcp/#remote-servers-httpsse","title":"Remote Servers (HTTP/SSE)","text":"<p>Connect to hosted MCP services:</p> <pre><code>{\n  \"mcp\": {\n    \"huggingface\": {\n      \"type\": \"remote\",\n      \"url\": \"https://huggingface.co/mcp\",\n      \"enabled\": true,\n      \"headers\": {\n        \"Authorization\": \"Bearer ${HF_TOKEN}\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"features/mcp/#environment-variables","title":"Environment Variables","text":"<p>Keep credentials secure using environment variable expansion:</p> <pre><code>{\n  \"mcp\": {\n    \"api\": {\n      \"type\": \"remote\",\n      \"url\": \"${API_URL:-https://api.example.com}\",\n      \"headers\": {\n        \"Authorization\": \"Bearer ${API_TOKEN}\"\n      }\n    }\n  }\n}\n</code></pre> <p>Syntax: - <code>${VAR}</code> - Required variable (fails if not set) - <code>${VAR:-default}</code> - Optional with default value</p>"},{"location":"features/mcp/#config-merging","title":"Config Merging","text":"<p>Project configs override global configs by server name:</p> <pre><code>// Global: ~/.patchpal/mcp-config.json\n{\"mcp\": {\"api\": {\"url\": \"https://dev.example.com\"}}}\n\n// Project: .patchpal/mcp-config.json\n{\"mcp\": {\"api\": {\"url\": \"https://prod.example.com\"}}}\n\n// Result: Project uses prod URL\n</code></pre> <p>Disable a global server for specific projects:</p> <pre><code>// Project: .patchpal/mcp-config.json\n{\"mcp\": {\"filesystem\": {\"enabled\": false}}}\n</code></pre>"},{"location":"features/mcp/#finding-mcp-servers","title":"Finding MCP Servers","text":""},{"location":"features/mcp/#official-modelcontextprotocol-servers","title":"Official @modelcontextprotocol Servers","text":"<p>The MCP steering group maintains official reference servers available via npm:</p> <ul> <li>@modelcontextprotocol/server-filesystem - Secure file operations with configurable access controls</li> <li>@modelcontextprotocol/server-git - Git repository management and operations</li> <li>@modelcontextprotocol/server-everything - Reference/test server demonstrating all MCP features</li> <li>@modelcontextprotocol/server-fetch - Web content fetching and conversion</li> <li>@modelcontextprotocol/server-memory - Knowledge graph-based persistent memory</li> <li>@modelcontextprotocol/server-sequential-thinking - Dynamic problem-solving through thought sequences</li> <li>@modelcontextprotocol/server-time - Time and timezone conversion capabilities</li> </ul> <p>Browse all official packages: https://www.npmjs.com/org/modelcontextprotocol</p> <p>Usage: <pre><code># View available servers\nnpm search @modelcontextprotocol\n\n# Add to PatchPal (npx -y auto-installs if needed)\npatchpal-mcp add filesystem --transport stdio -- \\\n  npx -y @modelcontextprotocol/server-filesystem /allowed/path\n</code></pre></p>"},{"location":"features/mcp/#community-servers","title":"Community Servers","text":"<ul> <li>MCP Server Registry - Searchable directory of 500+ servers</li> <li>GitHub Official Servers - Reference implementations &amp; archived servers</li> <li>FastMCP Cloud - Host your own servers</li> </ul>"},{"location":"features/mcp/#managing-servers","title":"Managing Servers","text":"<pre><code># Add server\npatchpal-mcp add &lt;name&gt; &lt;url&gt; [options]\n\n# List all servers\npatchpal-mcp list\n\n# Get server details\npatchpal-mcp get &lt;name&gt;\n\n# Test connection\npatchpal-mcp test &lt;name&gt;\n\n# Remove server\npatchpal-mcp remove &lt;name&gt;\n\n# Scope (--scope flag)\n#   user    : ~/.patchpal/mcp-config.json (default, all projects)\n#   project : .patchpal/mcp-config.json (current project only)\n</code></pre>"},{"location":"features/mcp/#in-session-commands","title":"In-Session Commands","text":"<p>Once in a PatchPal session:</p> <pre><code>/mcp servers                # List configured servers\n/mcp tools                  # List all loaded MCP tools\n/mcp tools [server]         # List tools from specific server\n/mcp resources              # List available resources (view only)\n/mcp resources [server]     # List resources from specific server\n/mcp prompts                # List available prompts (view only)\n/mcp prompts [server]       # List prompts from specific server\n/mcp help                   # Show all MCP commands\n</code></pre> <p>Note: Resources and prompts are displayed for reference but are not automatically exposed as agent tools. MCP tools are the primary way for agents to interact with MCP servers.</p>"},{"location":"features/mcp/#examples","title":"Examples","text":""},{"location":"features/mcp/#hugging-face-hub","title":"Hugging Face Hub","text":"<p>Access the Hugging Face Hub - search models, datasets, Spaces, papers, and documentation.</p> <p>Setup:</p> <ol> <li>Get your API token from https://huggingface.co/settings/tokens</li> <li>Set environment variable:    <pre><code>export HF_TOKEN=\"hf_your_token_here\"\n</code></pre></li> <li>Add to config:    <pre><code>patchpal-mcp add huggingface https://huggingface.co/mcp \\\n  --header \"Authorization: Bearer ${HF_TOKEN}\"\n</code></pre></li> </ol> <p>Available Tools: - <code>hf_model_search</code> - Search for ML models - <code>hf_dataset_search</code> - Find datasets - <code>hf_space_search</code> - Discover AI apps/demos - <code>hf_paper_search</code> - Search ML research papers - <code>hf_doc_search</code> - Search Hugging Face documentation</p> <p>Example Queries: - \"Find quantized versions of Qwen 3\" - \"Search for datasets about weather time-series\" - \"What are the most popular text-to-image models?\"</p>"},{"location":"features/mcp/#filesystem-access","title":"Filesystem Access","text":"<p>Secure file operations with path restrictions:</p> <pre><code>patchpal-mcp add filesystem --transport stdio -- \\\n  npx -y @modelcontextprotocol/server-filesystem /home/user/projects\n\n# Agent can now access files in /home/user/projects\n</code></pre>"},{"location":"features/mcp/#mcp-resources-and-prompts","title":"MCP Resources and Prompts","text":"<p>In addition to tools, MCP servers can expose:</p> <ul> <li>Resources - Data and documents that servers make available (e.g., configuration files, documentation, database schemas)</li> <li>Prompts - Pre-defined prompt templates with arguments for common tasks</li> </ul> <p>These are available for viewing and reference via <code>/mcp resources</code> and <code>/mcp prompts</code> commands in a PatchPal session, but are not automatically exposed as agent tools. This allows you to discover what a server provides without cluttering the agent's tool list.</p> <p>Use Cases: - Resources: View what data sources are available before deciding how to access them - Prompts: See pre-built templates that demonstrate common workflows with the server</p> <p>Demo:</p> <p>See resources and prompts in action:</p> <pre><code>python examples/mcp/demo_resources_prompts.py\n</code></pre>"},{"location":"features/mcp/#authentication","title":"Authentication","text":"<p>Most MCP servers that require authentication accept personal access tokens or API keys.</p>"},{"location":"features/mcp/#recommended-workflow","title":"Recommended Workflow","text":"<p>Step 1: Get a personal access token</p> <p>Visit the service's settings page (e.g., \"API Keys\", \"Access Tokens\", or \"Developer Settings\").</p> <p>Step 2: Store token as environment variable</p> <pre><code># Add to your ~/.bashrc, ~/.zshrc, or equivalent\nexport HF_TOKEN=\"hf_xxxxxxxxxxxxxxxxxxxx\"\n\n# Reload your shell\nsource ~/.bashrc\n</code></pre> <p>Step 3: Configure PatchPal to use the token</p> <pre><code>patchpal-mcp add huggingface https://huggingface.co/mcp \\\n  --header \"Authorization: Bearer ${HF_TOKEN}\"\n</code></pre> <p>Your config file will contain the variable reference, not the actual token:</p> <pre><code>{\n  \"huggingface\": {\n    \"type\": \"remote\",\n    \"url\": \"https://huggingface.co/mcp\",\n    \"enabled\": true,\n    \"headers\": {\n      \"Authorization\": \"Bearer ${HF_TOKEN}\"\n    }\n  }\n}\n</code></pre>"},{"location":"features/mcp/#benefits","title":"Benefits","text":"<ul> <li>\u2705 Secure - Tokens never stored in config files</li> <li>\u2705 Simple - No browser popups or OAuth flows needed</li> <li>\u2705 Portable - Works in SSH sessions, containers, CI/CD</li> </ul>"},{"location":"features/mcp/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/mcp/#mcp-tools-not-loading","title":"MCP Tools Not Loading","text":"<pre><code># Check MCP SDK installation\npip install patchpal[mcp]\npython -c \"import mcp; print('OK')\"\n\n# Validate configuration\ncat ~/.patchpal/mcp-config.json | python -m json.tool\n</code></pre>"},{"location":"features/mcp/#environment-variable-not-found","title":"Environment Variable Not Found","text":"<p>Set the environment variable or use a default value: <pre><code>\"url\": \"${API_URL:-https://default.example.com}\"\n</code></pre></p>"},{"location":"features/mcp/#remote-server-connection-failed","title":"Remote Server Connection Failed","text":"<pre><code># Test server accessibility\ncurl -I https://huggingface.co/mcp\n\n# Test with patchpal-mcp\npatchpal-mcp test huggingface\n</code></pre>"},{"location":"features/mcp/#local-server-wont-start","title":"Local Server Won't Start","text":"<pre><code># Verify command works standalone\nnpx -y @modelcontextprotocol/server-filesystem /tmp\n\n# Check logs when starting PatchPal\npatchpal  # Look for error messages about MCP server initialization\n</code></pre> <p>Build your own MCP server with Python:</p> <pre><code>from mcp.server import Server\n\nserver = Server(\"my-server\")\n\n@server.list_tools()\nasync def list_tools():\n    return [...]  # Define tools\n\n@server.call_tool()\nasync def call_tool(name: str, arguments: dict):\n    # Handle tool execution\n    return [TextContent(type=\"text\", text=result)]\n\n# Run with stdio transport\nserver.run(transport=\"stdio\")\n</code></pre> <p>See <code>examples/mcp/simple_server.py</code> for a complete example.</p>"},{"location":"features/mcp/#resources","title":"Resources","text":"<ul> <li>MCP Specification - Official protocol docs</li> <li>Example Servers - Local examples and testing guides</li> <li>MCP CLI Reference - Detailed CLI documentation</li> <li>Python SDK - Build custom servers</li> </ul>"},{"location":"features/memory/","title":"Project Memory","text":"<p>PatchPal automatically loads project context from <code>~/.patchpal/repos/&lt;repo-name&gt;/MEMORY.md</code> at startup. Use this file to store project-specific information, technical decisions, conventions, and known issues that persist across sessions. The agent can read and update this file to maintain continuity.</p>"},{"location":"features/memory/#what-to-store-in-memorymd","title":"What to Store in MEMORY.md","text":"<ul> <li>Project context: What this project is and what it does</li> <li>Important decisions: Technical choices and why they were made</li> <li>Key facts: Deployment info, database details, API endpoints</li> <li>Known issues: Bugs to fix, technical debt, TODOs</li> <li>Team conventions: Code style preferences, workflow guidelines</li> </ul>"},{"location":"features/memory/#how-it-works","title":"How It Works","text":"<p>When you start PatchPal in a git repository, it automatically: 1. Detects the repository name 2. Looks for <code>~/.patchpal/repos/&lt;repo-name&gt;/MEMORY.md</code> 3. Loads the content into the agent's context 4. Makes it available for reference throughout the session</p> <p>The agent can also read and update MEMORY.md during a session to maintain continuity across multiple sessions.</p>"},{"location":"features/memory/#location","title":"Location","text":"<p>Memory files are stored per-repository in: <pre><code>~/.patchpal/repos/&lt;repo-name&gt;/MEMORY.md\n</code></pre></p> <p>For example, if you're working in a repository named <code>patchpal</code>, the memory file is at: <pre><code>~/.patchpal/repos/patchpal/MEMORY.md\n</code></pre></p>"},{"location":"features/memory/#availability","title":"Availability","text":"<p>Project memory is available in: - CLI mode: Loaded automatically at startup - Python API: Loaded automatically when agent is created - Autopilot mode: Available throughout autonomous execution</p>"},{"location":"features/memory/#example-memorymd","title":"Example MEMORY.md","text":"<pre><code># Project Notes\n\nThis file persists across PatchPal sessions.\n\n## Project Context\nThis is a REST API for managing user accounts built with FastAPI.\n\n## Important Decisions\n- Using PostgreSQL for the database (MySQL had performance issues)\n- JWT tokens expire after 24 hours\n- API rate limit: 100 requests per minute per IP\n\n## Key Facts\n- Production: https://api.example.com\n- Database: PostgreSQL 14 on RDS\n- Redis cache on ElastiCache\n\n## Known Issues\n- TODO: Add pagination to /users endpoint\n- TODO: Implement proper error logging\n- Technical debt: Refactor authentication module\n\n## Team Conventions\n- Use Black for code formatting\n- All API endpoints require authentication except /health\n- Write tests for all new endpoints\n</code></pre>"},{"location":"features/skills/","title":"Skills System","text":"<p>Skills are reusable workflows and custom commands that can be invoked by name or discovered automatically by the agent.</p>"},{"location":"features/skills/#creating-your-own-skills","title":"Creating Your Own Skills","text":"<ol> <li>Choose a location:</li> <li>Personal skills (all projects): <code>~/.patchpal/skills/&lt;skill-name&gt;/SKILL.md</code></li> <li> <p>Project-specific skills: <code>&lt;repo&gt;/.patchpal/skills/&lt;skill-name&gt;/SKILL.md</code></p> </li> <li> <p>Create the skill file: <pre><code># Create a personal skill\nmkdir -p ~/.patchpal/skills/my-skill\ncat &gt; ~/.patchpal/skills/my-skill/SKILL.md &lt;&lt;'EOF'\n---\nname: my-skill\ndescription: Brief description of what this skill does\n---\n# Instructions\nYour detailed instructions here...\nEOF\n</code></pre></p> </li> <li> <p>Skill File Format: <pre><code>---\nname: skill-name\ndescription: One-line description\n---\n# Detailed Instructions\n- Step 1: Do this\n- Step 2: Do that\n- Use specific PatchPal tools like read_file, code_structure, run_shell, etc.\n</code></pre></p> </li> </ol>"},{"location":"features/skills/#example-skills","title":"Example Skills","text":"<p>The PatchPal repository includes example skills you can use as templates:</p>"},{"location":"features/skills/#patchpal-created-skills","title":"PatchPal-Created Skills","text":"<ul> <li>commit - Best practices for creating git commits with proper formatting and conventional commit standards</li> <li>review - Comprehensive code review checklist covering security, performance, code quality, and documentation</li> <li>add-tests - Add comprehensive pytest tests (includes code block templates and test structure examples)</li> </ul>"},{"location":"features/skills/#from-anthropics-official-skills-repository","title":"From Anthropic's Official Skills Repository","text":"<ul> <li>slack-gif-creator - Create animated GIFs optimized for Slack (from Anthropic's official skills repo, demonstrates Claude Code compatibility)</li> <li>skill-creator - Guide for creating effective skills with bundled scripts and references (from Anthropic's official skills repo, demonstrates full bundled resources support)</li> </ul> <p>After <code>pip install patchpal</code>, get examples:</p> <pre><code># Quick way: Download examples directly from GitHub\ncurl -L https://github.com/amaiya/patchpal/archive/main.tar.gz | tar xz --strip=1 patchpal-main/examples\n\n# Or clone the repository\ngit clone https://github.com/amaiya/patchpal.git\ncd patchpal\n\n# Copy examples to your personal skills directory\ncp -r examples/skills/commit ~/.patchpal/skills/\ncp -r examples/skills/review ~/.patchpal/skills/\ncp -r examples/skills/add-tests ~/.patchpal/skills/\ncp -r examples/skills/skill-creator ~/.patchpal/skills/\n</code></pre> <p>View examples online: Browse the examples/skills/ directory on GitHub to see the skill format and create your own.</p> <p>You can also try out the example skills at anthropic/skills.</p>"},{"location":"features/skills/#using-skills","title":"Using Skills","text":"<p>There are two ways to invoke skills:</p> <ol> <li> <p>Direct invocation - Type <code>/skillname</code> at the prompt: <pre><code>$ patchpal\nYou: /commit Fix authentication bug\n</code></pre></p> </li> <li> <p>Natural language - Just ask, and the agent discovers the right skill: <pre><code>You: Help me commit these changes following best practices\n# Agent automatically discovers and uses the commit skill\n</code></pre></p> </li> </ol>"},{"location":"features/skills/#finding-available-skills","title":"Finding Available Skills","text":"<p>Ask the agent to list them: <pre><code>You: list skills\n</code></pre></p>"},{"location":"features/skills/#skill-priority","title":"Skill Priority","text":"<p>Project skills (<code>.patchpal/skills/</code>) override personal skills (<code>~/.patchpal/skills/</code>) with the same name.</p>"},{"location":"features/skills/#bundled-resources","title":"Bundled Resources","text":"<p>Skills can include additional files alongside the main <code>SKILL.md</code>:</p> <pre><code>~/.patchpal/skills/my-skill/\n\u251c\u2500\u2500 SKILL.md              # Main skill file (required)\n\u251c\u2500\u2500 template.py           # Code template\n\u251c\u2500\u2500 checklist.md          # Reference document\n\u2514\u2500\u2500 scripts/              # Helper scripts\n    \u2514\u2500\u2500 validate.py\n</code></pre> <p>Reference bundled files in your skill: <pre><code>Use the template in `template.py` as a starting point.\nRun `python scripts/validate.py` to check results.\n</code></pre></p> <p>The <code>skill-creator</code> example demonstrates full bundled resources support with scripts and reference documents.</p>"},{"location":"features/skills/#real-world-skill-ideas","title":"Real-World Skill Ideas","text":"<p>Documentation generator: <pre><code>---\nname: document\ndescription: Generate documentation for code\n---\n# Instructions\n1. Read the source file with `read_file`\n2. Analyze functions and classes\n3. Generate docstrings following project style\n4. Add usage examples\n</code></pre></p> <p>Refactoring assistant: <pre><code>---\nname: refactor\ndescription: Refactor code following best practices\n---\n# Instructions\n1. Analyze current code structure\n2. Identify code smells\n3. Suggest improvements\n4. Apply changes with user approval\n</code></pre></p> <p>Deployment checklist: <pre><code>---\nname: deploy\ndescription: Pre-deployment checklist\n---\n# Instructions\n1. Check tests pass: `run_shell(\"pytest\")`\n2. Verify git status is clean with `git_status`\n3. Review CHANGELOG.md\n4. Confirm version bump\n5. Check CI/CD pipeline status\n</code></pre></p>"},{"location":"features/skills/#skills-vs-custom-tools","title":"Skills vs. Custom Tools","text":"Feature Skills Custom Tools Type Markdown instructions Python functions Purpose Guide agent through workflow Execute code Location <code>~/.patchpal/skills/</code> or <code>.patchpal/skills/</code> <code>~/.patchpal/tools/</code> or <code>.patchpal/tools/</code> Invocation <code>/skillname</code> or natural language Automatic (when relevant) Execution Agent follows instructions Python code runs Best For Complex workflows, checklists Calculations, API calls, data processing <p>Choose skills for guiding the agent through processes, choose custom tools for executing specific code operations!</p>"},{"location":"features/tools/","title":"Built-In Tools","text":"<p>PatchPal provides 18 built-in tools for file operations, code analysis, web access, task planning, and user interaction.</p> <p>For Local Models: Set <code>PATCHPAL_MINIMAL_TOOLS=true</code> and <code>PATCHPAL_ENABLE_WEB=false</code> to use only 5 essential tools (<code>read_file</code>, <code>read_lines</code>, <code>write_file</code>, <code>edit_file</code>, <code>run_shell</code>), reducing tool confusion with smaller models.</p>"},{"location":"features/tools/#file-reading-2-tools","title":"File Reading (2 tools)","text":""},{"location":"features/tools/#read_file","title":"read_file","text":"<p>Read contents of files anywhere on the system (repository files, logs, configs).</p> <ul> <li>Example: <code>read_file(\"src/app.py\")</code></li> <li>Supports text files, images (PNG, JPG, GIF, etc.), and documents (PDF, DOCX, PPTX)</li> <li>Image Support: When using vision-capable models (GPT-4o, Claude 3.5 Sonnet), images are automatically formatted for the model</li> <li>Example: Just mention image files in your prompt: \"Look at screenshot.png and tell me what's wrong\"</li> <li>Supported formats: PNG, JPG, JPEG, GIF, BMP, WEBP (SVG returned as text)</li> <li>The agent will automatically call <code>read_file</code> on image files when needed</li> <li>Size limits:<ul> <li>Maximum file size: 10MB (configurable with <code>PATCHPAL_MAX_IMAGE_SIZE</code>)</li> <li>Provider limits: OpenAI (20MB), Anthropic/Bedrock (5MB)</li> <li>Images bypass tool output truncation limits (100K chars)</li> </ul> </li> <li>Multi-provider support:<ul> <li>Anthropic/Claude: Images in tool results (multimodal content)</li> <li>OpenAI/GPT: Images injected as user messages (API limitation workaround)</li> <li>Automatic detection and formatting based on model provider</li> </ul> </li> <li>Non-vision models: Set <code>PATCHPAL_BLOCK_IMAGES=true</code> to replace images with text placeholders<ul> <li>Prevents API errors from non-vision models (gpt-3.5-turbo, claude-instant, local models)</li> <li>Also useful for privacy compliance (prevent image data from being sent to LLM)</li> </ul> </li> <li>Recommendation: Use compressed images for faster processing (1-2MB optimal)</li> <li>Text file limit: 500KB by default (configurable with <code>PATCHPAL_MAX_FILE_SIZE</code>)</li> <li>For larger files, use <code>read_lines</code> for targeted access</li> </ul>"},{"location":"features/tools/#read_lines","title":"read_lines","text":"<p>Read specific line ranges from a file without loading the entire file.</p> <ul> <li>Example: <code>read_lines(\"app.py\", 100, 150)</code> - read lines 100-150</li> <li>More efficient than <code>read_file</code> when you only need a few lines</li> <li>Useful for viewing code sections, error context, or specific regions</li> </ul>"},{"location":"features/tools/#file-writing-2-tools","title":"File Writing (2 tools)","text":""},{"location":"features/tools/#write_file","title":"write_file","text":"<p>Modify files by replacing entire contents.</p> <ul> <li>Example: <code>write_file(\"config.py\", new_content)</code></li> <li>Use for large-scale changes or multiple edits</li> <li>Returns unified diff showing changes</li> <li>Best for rewriting entire files or complex modifications</li> </ul>"},{"location":"features/tools/#edit_file","title":"edit_file","text":"<p>Edit a file by replacing an exact string (efficient for small changes).</p> <ul> <li>Example: <code>edit_file(\"config.py\", \"port = 3000\", \"port = 8080\")</code></li> <li>More efficient than <code>write_file</code> for targeted changes</li> <li>Old string must appear exactly once in the file</li> <li>Best for single-line or small multi-line edits</li> </ul>"},{"location":"features/tools/#shell-1-tool","title":"Shell (1 tool)","text":""},{"location":"features/tools/#run_shell","title":"run_shell","text":"<p>Execute shell commands in the repository.</p> <ul> <li>Example: <code>run_shell(\"pytest tests/test_auth.py\")</code></li> <li>Example: <code>run_shell(\"npm install lodash\")</code></li> <li>Commands execute from repository root automatically (no need for <code>cd</code>)</li> <li>80+ harmless commands auto-granted (no permission prompts):</li> <li>File operations: <code>wc</code>, <code>stat</code>, <code>find</code>, <code>ls</code>, <code>cat</code>, <code>head</code>, <code>tail</code></li> <li>Search: <code>grep</code>, <code>awk</code></li> <li>Git (read-only): <code>git status</code>, <code>git diff</code>, <code>git log</code></li> <li>Test runners: <code>pytest</code>, <code>jest</code>, <code>mocha</code>, <code>go test</code>, <code>cargo test</code>, <code>mvn test</code>, <code>dotnet test</code>, etc.</li> <li>System info: <code>whoami</code>, <code>hostname</code>, <code>date</code>, <code>uname</code></li> <li>Network diagnostics: <code>ping</code>, <code>tracert</code>, <code>nslookup</code></li> <li>Dangerous commands require permission (e.g., <code>rm</code>, <code>pip install</code>, script execution)</li> <li>Privilege escalation blocked by default (set <code>PATCHPAL_ALLOW_SUDO=true</code> to enable)</li> </ul>"},{"location":"features/tools/#web-tools-2-tools","title":"Web Tools (2 tools)","text":""},{"location":"features/tools/#web_search","title":"web_search","text":"<p>Search the web using DuckDuckGo (no API key required).</p> <ul> <li>Example: <code>web_search(\"Python asyncio best practices\")</code></li> <li>Look up error messages and solutions</li> <li>Find current documentation and best practices</li> <li>Research library versions and compatibility</li> <li>Returns top search results with titles, snippets, and URLs</li> </ul>"},{"location":"features/tools/#web_fetch","title":"web_fetch","text":"<p>Fetch and read content from URLs.</p> <ul> <li>Example: <code>web_fetch(\"https://docs.python.org/3/library/asyncio.html\")</code></li> <li>Read documentation pages and API references</li> <li>Extract text from HTML, PDF, DOCX (Word), and PPTX (PowerPoint)</li> <li>Supports plain text, JSON, XML, and other text formats</li> <li>Warns about unsupported binary formats (images, videos, archives)</li> </ul>"},{"location":"features/tools/#code-analysis-2-tools","title":"Code Analysis (2 tools)","text":""},{"location":"features/tools/#code_structure","title":"code_structure","text":"<p>Analyze code structure using tree-sitter AST parsing without reading full files.</p> <ul> <li>Example: <code>code_structure(\"app.py\")</code> - see all classes, functions, methods with line numbers</li> <li>95% token savings vs <code>read_file</code> for large code files</li> <li>Supports 40+ languages: Python, JavaScript, TypeScript, Go, Rust, Java, C/C++, Ruby, PHP, and more</li> <li>Shows function signatures and line numbers for easy navigation</li> <li>Best practice: Use with <code>read_lines</code> - analyze structure first, then read specific sections</li> </ul>"},{"location":"features/tools/#get_repo_map","title":"get_repo_map","text":"<p>Get an overview of the entire codebase in one call.</p> <ul> <li>Example: <code>get_repo_map(max_files=100)</code> - see structure of up to 100 files at once</li> <li>Shows function/class signatures from ALL files in a consolidated view</li> <li>Filtering: <code>get_repo_map(include_patterns=[\"*.py\"], exclude_patterns=[\"*test*\"])</code></li> <li>38-70% token savings vs calling <code>code_structure</code> on each file individually</li> <li>Ideal for understanding codebase structure and finding relevant files</li> </ul>"},{"location":"features/tools/#task-planning-6-tools","title":"Task Planning (6 tools)","text":""},{"location":"features/tools/#todo_add","title":"todo_add","text":"<p>Add a new task to break down complex work into manageable subtasks.</p> <ul> <li>Example: <code>todo_add(\"Implement authentication\", details=\"Use JWT tokens\")</code></li> <li>Each task gets a unique ID for tracking</li> <li>Use for multi-step workflows</li> </ul>"},{"location":"features/tools/#todo_list","title":"todo_list","text":"<p>Show all tasks with their status and progress.</p> <ul> <li>Example: <code>todo_list()</code> - show pending tasks only</li> <li>Example: <code>todo_list(show_completed=True)</code> - show all tasks including completed</li> </ul>"},{"location":"features/tools/#todo_complete","title":"todo_complete","text":"<p>Mark a task as done.</p> <ul> <li>Example: <code>todo_complete(1)</code> - mark task #1 as completed</li> </ul>"},{"location":"features/tools/#todo_update","title":"todo_update","text":"<p>Update task description or details.</p> <ul> <li>Example: <code>todo_update(1, description=\"Implement OAuth2 authentication\")</code></li> </ul>"},{"location":"features/tools/#todo_remove","title":"todo_remove","text":"<p>Remove a task from the list.</p> <ul> <li>Example: <code>todo_remove(1)</code> - remove task #1</li> </ul>"},{"location":"features/tools/#todo_clear","title":"todo_clear","text":"<p>Clear completed tasks or start fresh.</p> <ul> <li>Example: <code>todo_clear()</code> - clear completed tasks only</li> <li>Example: <code>todo_clear(completed_only=False)</code> - clear all tasks</li> </ul>"},{"location":"features/tools/#skills-2-tools","title":"Skills (2 tools)","text":""},{"location":"features/tools/#list_skills","title":"list_skills","text":"<p>List all available skills (e.g., /commit, /test, /debug).</p> <ul> <li>Skills are higher-level commands that combine multiple tools</li> <li>Users invoke skills with <code>/skillname</code> syntax at the CLI</li> </ul>"},{"location":"features/tools/#use_skill","title":"use_skill","text":"<p>Invoke a skill programmatically when relevant to the request.</p> <ul> <li>Example: <code>use_skill(\"commit\", args=\"Fix authentication bug\")</code></li> <li>Note: Users invoke skills via <code>/skillname</code> at CLI, not by calling this tool</li> </ul>"},{"location":"features/tools/#user-interaction-1-tool","title":"User Interaction (1 tool)","text":""},{"location":"features/tools/#ask_user","title":"ask_user","text":"<p>Ask the user a question during task execution.</p> <ul> <li>Example: <code>ask_user(\"Which database should I use?\", options=[\"PostgreSQL\", \"MySQL\", \"SQLite\"])</code></li> <li>Useful for clarifying requirements, getting decisions, or gathering additional information</li> <li>Supports multiple choice options or free-form answers</li> </ul>"},{"location":"features/tools/#tool-count-by-category","title":"Tool Count by Category","text":"Category Tools Count File Reading read_file, read_lines 2 File Writing write_file, edit_file 2 Shell run_shell 1 Code Analysis code_structure, get_repo_map 2 Web web_search, web_fetch 2 Task Planning todo_add, todo_list, todo_complete, todo_update, todo_remove, todo_clear 6 Skills list_skills, use_skill 2 User Interaction ask_user 1 Total 18"},{"location":"features/tools/#configuration","title":"Configuration","text":""},{"location":"features/tools/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>PATCHPAL_MAX_FILE_SIZE</code> - Maximum file size for text files in read_file (default: 500KB)</li> <li><code>PATCHPAL_MAX_IMAGE_SIZE</code> - Maximum image file size for read_file (default: 10MB)</li> <li><code>PATCHPAL_BLOCK_IMAGES</code> - Block images from being sent to LLM (default: false)</li> <li><code>PATCHPAL_ENABLE_WEB</code> - Enable/disable web tools (default: true)</li> <li><code>PATCHPAL_ALLOW_SUDO</code> - Allow sudo/su commands (default: false)</li> <li><code>PATCHPAL_MINIMAL_TOOLS</code> - Use minimal tools mode: 4-6 core tools only (default: false)</li> </ul>"},{"location":"features/tools/#minimal-tools-mode","title":"Minimal Tools Mode","text":"<p>When <code>PATCHPAL_MINIMAL_TOOLS=true</code>, only these tools are available: - <code>read_file</code>, <code>read_lines</code>, <code>write_file</code>, <code>edit_file</code>, <code>run_shell</code> - <code>web_search</code>, <code>web_fetch</code> (if <code>PATCHPAL_ENABLE_WEB=true</code>)</p> <p>This reduces tool count to 4-6 for local models with tool confusion issues. Harmless shell commands still work without permission prompts.</p>"},{"location":"features/tools/#permission-system","title":"Permission System","text":""},{"location":"features/tools/#read-operations-auto-granted","title":"Read Operations (Auto-Granted)","text":"<ul> <li>Reading repository files (including images)</li> <li>Listing files and directories</li> <li>Searching with grep</li> <li>Analyzing code structure</li> <li>Git read-only operations (status, diff, log)</li> <li>System information commands</li> </ul>"},{"location":"features/tools/#write-operations-require-permission","title":"Write Operations (Require Permission)","text":"<ul> <li>Editing/patching files outside repository</li> <li>Dangerous shell commands</li> <li>Web access (to prevent info leakage)</li> <li>Installation commands (pip, npm, etc.)</li> </ul>"},{"location":"features/tools/#bypass-permission-prompts","title":"Bypass Permission Prompts","text":"<p>Set <code>PATCHPAL_REQUIRE_PERMISSION=false</code> to auto-grant all operations (use carefully).</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<p>Install PatchPal from PyPI:</p> <pre><code>pip install patchpal\n</code></pre> <p>Supported Operating Systems:  Linux, MacOS, MS Windows.</p>"},{"location":"getting-started/#setup","title":"Setup","text":"<ol> <li>Get an API key or a Local LLM Engine:</li> <li>[Cloud] For Anthropic models (default): Sign up at https://console.anthropic.com/</li> <li>[Cloud] For OpenAI models: Get a key from https://platform.openai.com/</li> <li>[Local] For vLLM: Install from https://docs.vllm.ai/ (free - no API charges) Recommended for Local Use</li> <li>[Local] For Ollama: Install from https://ollama.com/ (\u26a0\ufe0f requires <code>OLLAMA_CONTEXT_LENGTH=32768</code> - see Ollama section below)</li> <li> <p>For other providers: Check the LiteLLM documentation</p> </li> <li> <p>Set up your API key as environment variable: <pre><code># For Anthropic (default)\nexport ANTHROPIC_API_KEY=your_api_key_here\n\n# For OpenAI\nexport OPENAI_API_KEY=your_api_key_here\n\n# For vLLM - API key required only if configured\nexport HOSTED_VLLM_API_BASE=http://localhost:8000 # depends on your vLLM setup\nexport HOSTED_VLLM_API_KEY=token-abc123           # optional depending on your vLLM setup\n\n# No API required for Ollama.\n\n# For other providers, check LiteLLM docs\n</code></pre></p> </li> <li> <p>Run PatchPal: <pre><code># Use default model (anthropic/claude-sonnet-4-5)\npatchpal\n\n# Use a specific model via command-line argument\npatchpal --model openai/gpt-5.2-codex  # or openai/gpt-5-mini, anthropic/claude-opus-4-5, etc.\n\n# Use vLLM (local)\n# Note: vLLM server must be started with --tool-call-parser and --enable-auto-tool-choice\nexport HOSTED_VLLM_API_BASE=http://localhost:8000\nexport HOSTED_VLLM_API_KEY=token-abc123\npatchpal --model hosted_vllm/openai/gpt-oss-120b\n\n# Use Ollama (local - requires OLLAMA_CONTEXT_LENGTH=32768)\nexport OLLAMA_CONTEXT_LENGTH=32768\npatchpal --model ollama_chat/glm-4.7-flash:q4_K_M\n\n# Or set the model via environment variable\nexport PATCHPAL_MODEL=anthropic/claude-opus-4-5\npatchpal\n</code></pre></p> </li> </ol> <p>Tip for Local Models: Local models (i.e., models served by Ollama or vLLM) may work better with the environment variable settings, <code>PATCHPAL_MINIMAL_TOOLS=true</code> and <code>PATCHPAL_ENABLE_WEB=false</code>, which provides only essential tools (<code>read_file</code>, <code>read_lines</code>, <code>write_file</code>, <code>edit_file</code>, <code>run_shell</code>), reducing tool confusion with smaller models.</p>"},{"location":"models/local-models/","title":"Using Local Models (vLLM &amp; Ollama)","text":"<p>Run models locally on your machine without needing API keys or internet access.</p> <p>\u26a0\ufe0f IMPORTANT: For local models, we recommend vLLM.</p> <p>vLLM provides: - \u2705 Robust multi-turn tool calling - \u2705 3-10x faster inference than Ollama - \u2705 Production-ready reliability</p>"},{"location":"models/local-models/#vllm-recommended-for-local-models","title":"vLLM (Recommended for Local Models)","text":"<p>vLLM is significantly faster than Ollama due to optimized inference with continuous batching and PagedAttention.</p> <p>Important: vLLM &gt;= 0.10.2 is required for proper tool calling support.</p> <p>Using Local vLLM Server:</p> <pre><code># 1. Install vLLM (&gt;= 0.10.2)\npip install vllm\n\n# 2. Start vLLM server with tool calling enabled\nvllm serve openai/gpt-oss-120b \\\n  --dtype auto \\\n  --api-key token-abc123 \\\n  --tool-call-parser openai \\\n  --enable-auto-tool-choice\n\n# 3. Use with PatchPal (in another terminal)\nexport HOSTED_VLLM_API_BASE=http://localhost:8000\nexport HOSTED_VLLM_API_KEY=token-abc123\npatchpal --model hosted_vllm/openai/gpt-oss-120b\n</code></pre> <p>Using Remote/Hosted vLLM Server:</p> <pre><code># For remote vLLM servers (e.g., hosted by your organization)\nexport HOSTED_VLLM_API_BASE=https://your-vllm-server.com\nexport HOSTED_VLLM_API_KEY=your_api_key_here\npatchpal --model hosted_vllm/openai/gpt-oss-120b\n</code></pre> <p>Environment Variables: - Use <code>HOSTED_VLLM_API_BASE</code> and <code>HOSTED_VLLM_API_KEY</code></p> <p>Using YAML Configuration (Alternative):</p> <p>Create a <code>config.yaml</code>: <pre><code>host: \"0.0.0.0\"\nport: 8000\napi-key: \"token-abc123\"\ntool-call-parser: \"openai\"  # Use appropriate parser for your model\nenable-auto-tool-choice: true\ndtype: \"auto\"\n</code></pre></p> <p>Then start vLLM: <pre><code>vllm serve openai/gpt-oss-120b --config config.yaml\n\n# Use with PatchPal\nexport HOSTED_VLLM_API_BASE=http://localhost:8000\nexport HOSTED_VLLM_API_KEY=token-abc123\npatchpal --model hosted_vllm/openai/gpt-oss-120b\n</code></pre></p> <p>Recommended models for vLLM: - <code>openai/gpt-oss-120b</code> - OpenAI's open-source model (use parser: <code>openai</code>)</p> <p>Tool Call Parser Reference: Different models require different parsers. Common parsers include: <code>qwen3_xml</code>, <code>openai</code>, <code>deepseek_v3</code>, <code>llama3_json</code>, <code>mistral</code>, <code>hermes</code>, <code>pythonic</code>, <code>xlam</code>. See vLLM Tool Calling docs for the complete list.</p>"},{"location":"models/local-models/#ollama","title":"Ollama","text":"<p>Ollama v0.14+ supports tool calling for agentic workflows. However, proper configuration is critical for reliable operation.</p> <p>Requirements:</p> <ol> <li>Ollama v0.14.0 or later - Required for tool calling support</li> <li>Sufficient context window - Default 4096 tokens is too small; increase to at least 32K</li> </ol> <p>Setup Instructions:</p> <p>For Native Ollama Installation:</p> <pre><code># Set context window size (required!)\nexport OLLAMA_CONTEXT_LENGTH=32768\n\n# Start Ollama server\nollama serve\n\n# In another terminal, use with PatchPal\npatchpal --model ollama_chat/gpt-oss:120b\n</code></pre> <p>For Docker:</p> <pre><code># Stop existing container (if running)\ndocker stop ollama\ndocker rm ollama\n\n# Start with proper configuration\ndocker run -d \\\n  --gpus all \\\n  -e OLLAMA_CONTEXT_LENGTH=32768 \\\n  -v ollama:/root/.ollama \\\n  -p 11434:11434 \\\n  --name ollama \\\n  ollama/ollama\n\n# Verify configuration\ndocker exec -it ollama ollama run gpt-oss:120b\n# In the Ollama prompt, type: /show parameters\n# Should show num_ctx much larger than default 4096\n\n# Use with PatchPal\npatchpal --model ollama_chat/glm-4.7-flash:q4_K_M\n</code></pre> <p>Verifying Context Window Size:</p> <pre><code># Check your Ollama container configuration\ndocker inspect ollama | grep OLLAMA_CONTEXT_LENGTH\n\n# Or run a model and check parameters\ndocker exec -it ollama ollama run glm-4.7-flash:q4_K_M\n&gt;&gt;&gt; /show parameters\n</code></pre> <p>Recommended Models for Tool Calling:</p> <ul> <li><code>gpt-oss:120b</code> - OpenAI's open-source model</li> <li><code>glm-4.7-flash:q4_K_M</code> - Z.ai's GLM model, excellent tool calling</li> <li><code>qwen3:32b</code> - Qwen3 model with good agentic capabilities</li> <li><code>qwen3-coder</code> - Specialized for coding tasks</li> </ul> <p>Performance Note:</p> <p>While Ollama now works with proper configuration, vLLM is still recommended for production use due to: - 3-10x faster inference - More robust tool calling implementation - Better memory management</p> <p>Examples:</p> <pre><code># Ollama (works with proper configuration)\nexport OLLAMA_CONTEXT_LENGTH=32768\npatchpal --model ollama_chat/qwen3:32b\npatchpal --model ollama_chat/gpt-oss:120b\npatchpal --model ollama_chat/glm-4.7-flash:q4_K_M\n\n# vLLM (recommended for production)\npatchpal --model hosted_vllm/openai/gpt-oss-120b\n</code></pre>"},{"location":"models/offline-deployment/","title":"Air-Gapped and Offline Environments","text":"<p>For environments without internet access (air-gapped, offline, or restricted networks), you can disable web search and fetch tools:</p> <pre><code># Disable web tools for air-gapped environment\nexport PATCHPAL_ENABLE_WEB=false\npatchpal\n\n# Or combine with local vLLM for complete offline operation (recommended)\nexport PATCHPAL_ENABLE_WEB=false\nexport HOSTED_VLLM_API_BASE=http://localhost:8000\nexport HOSTED_VLLM_API_KEY=token-abc123\npatchpal --model hosted_vllm/openai/gpt-oss-120b\n</code></pre> <p>When web tools are disabled: - <code>web_search</code> and <code>web_fetch</code> are removed from available tools - With a local model, the agent won't attempt any network requests - Perfect for secure, isolated, or offline development environments</p>"},{"location":"models/offline-deployment/#viewing-help","title":"Viewing Help","text":"<pre><code>patchpal --help\n</code></pre>"},{"location":"models/offline-deployment/#maximum-security-mode","title":"Maximum Security Mode","text":"<p>For maximum security and control, you can require permission for all operations including read operations:</p> <pre><code>patchpal --require-permission-for-all\n</code></pre> <p>When enabled, the agent will prompt for permission before: - Read operations: <code>read_file</code>, <code>read_lines</code>, <code>code_structure</code>, <code>get_repo_map</code> - Write operations: <code>edit_file</code>, <code>write_file</code> (always require permission) - Shell commands: <code>run_shell</code> (always requires permission) - Web operations: <code>web_search</code>, <code>web_fetch</code> (always require permission)</p> <p>Granular session permissions: When you grant permission for read operations, you can choose to grant it for: - This specific operation only (option 1) - This specific file/pattern for the session (option 2) - e.g., grant permission to read <code>config.py</code> for the session, but still prompt for other files - Cancel the operation (option 3)</p> <p>This provides fine-grained control over what the agent can access during the session.</p> <p>Use cases: - Working with highly sensitive codebases - Security audits where every operation must be reviewed - Training/demonstration purposes where you want to see exactly what the agent does - Untrusted environments where you want complete control</p> <p>Example session: <pre><code>$ patchpal --require-permission-for-all\n================================================================================\nPatchPal - AI coding and automation assistant\n================================================================================\n\nUsing model: anthropic/claude-sonnet-4-5\n\ud83d\udd12 Permission required for ALL operations (including reads)\n\nYou: Read config.py and database.py\n\n================================================================================\nRead File\n--------------------------------------------------------------------------------\n   Read: config.py\n--------------------------------------------------------------------------------\n\nDo you want to proceed?\n  1. Yes\n  2. Yes, and don't ask again this session for 'config.py'\n  3. No, and tell me what to do differently\n\nChoice [1-3]: 2\n\n# Agent reads config.py, then prompts for database.py\n\n================================================================================\nRead File\n--------------------------------------------------------------------------------\n   Read: database.py\n--------------------------------------------------------------------------------\n\nDo you want to proceed?\n  1. Yes\n  2. Yes, and don't ask again this session for 'database.py'\n  3. No, and tell me what to do differently\n\nChoice [1-3]: 1\n\n# Agent reads database.py, but will prompt again if it tries to read it later\n# Won't prompt again for config.py since you chose option 2\n</code></pre></p> <p>Note: This mode is separate from and overrides <code>PATCHPAL_REQUIRE_PERMISSION=false</code>. Even if you've disabled the standard permission system, <code>--require-permission-for-all</code> will still prompt for all operations.</p>"},{"location":"models/overview/","title":"Model Configuration","text":"<p>PatchPal supports any LiteLLM-compatible model. You can configure the model in three ways (in order of priority):</p>"},{"location":"models/overview/#1-command-line-argument","title":"1. Command-line Argument","text":"<pre><code>patchpal --model openai/gpt-5.2-codex\npatchpal --model anthropic/claude-sonnet-4-5\npatchpal --model hosted_vllm/openai/gpt-oss-120b # local model - no API charges\n</code></pre>"},{"location":"models/overview/#2-environment-variable","title":"2. Environment Variable","text":"<pre><code>export PATCHPAL_MODEL=openai/gpt-5.2-codex\npatchpal\n</code></pre>"},{"location":"models/overview/#3-default-model","title":"3. Default Model","text":"<p>If no model is specified, PatchPal uses <code>anthropic/claude-sonnet-4-5</code> (Claude Sonnet 4.5).</p>"},{"location":"models/overview/#supported-models","title":"Supported Models","text":"<p>PatchPal works with any model supported by LiteLLM, including:</p> <ul> <li>Anthropic (Recommended): <code>anthropic/claude-sonnet-4-5</code>, <code>anthropic/claude-opus-4-5</code>, <code>anthropic/claude-3-7-sonnet-latest</code></li> <li>OpenAI: <code>openai/gpt-5.2</code>, <code>openai/gpt-5.2-codex</code>, <code>openai/gpt-5-mini</code></li> <li>AWS Bedrock: <code>bedrock/anthropic.claude-sonnet-4-5-v1:0</code></li> <li>vLLM (Local) (Recommended for local): See vLLM section below for setup</li> <li>Ollama (Local):  See Ollama section below for setup</li> <li>Google: <code>gemini/gemini-pro</code>, <code>vertex_ai/gemini-pro</code></li> <li>Others: Cohere, Azure OpenAI, and many more</li> </ul> <p>See the LiteLLM providers documentation for the complete list.</p>"},{"location":"reference/agent/","title":"Agent API","text":"<p>The core agent implementation for PatchPal, providing the main interface for interacting with LLMs and executing tools.</p>"},{"location":"reference/agent/#creating-an-agent","title":"Creating an Agent","text":""},{"location":"reference/agent/#patchpal.agent.create_agent","title":"<code>patchpal.agent.create_agent(model_id='anthropic/claude-sonnet-4-5', custom_tools=None, litellm_kwargs=None)</code>","text":"<p>Create and return a PatchPal agent.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>LiteLLM model identifier (default: anthropic/claude-sonnet-4-5)</p> <code>'anthropic/claude-sonnet-4-5'</code> <code>custom_tools</code> <code>Optional[List[Callable]]</code> <p>Optional list of Python functions to use as custom tools.          Each function should have type hints and a docstring.</p> <code>None</code> <code>litellm_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Optional dict of extra parameters to pass to litellm.completion()            (e.g., {\"reasoning_effort\": \"high\"} for reasoning models)</p> <code>None</code> <p>Returns:</p> Type Description <code>PatchPalAgent</code> <p>A configured PatchPalAgent instance</p> Example <p>def calculator(x: int, y: int) -&gt; str:     '''Add two numbers.</p> <pre><code>Args:\n    x: First number\n    y: Second number\n'''\nreturn str(x + y)\n</code></pre> <p>agent = create_agent(custom_tools=[calculator]) response = agent.run(\"What's 5 + 3?\")</p> Source code in <code>patchpal/agent.py</code> <pre><code>def create_agent(\n    model_id: str = \"anthropic/claude-sonnet-4-5\",\n    custom_tools: Optional[List[Callable]] = None,\n    litellm_kwargs: Optional[Dict[str, Any]] = None,\n) -&gt; PatchPalAgent:\n    \"\"\"Create and return a PatchPal agent.\n\n    Args:\n        model_id: LiteLLM model identifier (default: anthropic/claude-sonnet-4-5)\n        custom_tools: Optional list of Python functions to use as custom tools.\n                     Each function should have type hints and a docstring.\n        litellm_kwargs: Optional dict of extra parameters to pass to litellm.completion()\n                       (e.g., {\"reasoning_effort\": \"high\"} for reasoning models)\n\n    Returns:\n        A configured PatchPalAgent instance\n\n    Example:\n        def calculator(x: int, y: int) -&gt; str:\n            '''Add two numbers.\n\n            Args:\n                x: First number\n                y: Second number\n            '''\n            return str(x + y)\n\n        agent = create_agent(custom_tools=[calculator])\n        response = agent.run(\"What's 5 + 3?\")\n\n        # With reasoning model\n        agent = create_agent(\n            model_id=\"ollama_chat/gpt-oss:120b\",\n            litellm_kwargs={\"reasoning_effort\": \"high\"}\n        )\n    \"\"\"\n    # Reset session todos for new session\n    from patchpal.tools import reset_session_todos\n\n    reset_session_todos()\n\n    return PatchPalAgent(\n        model_id=model_id, custom_tools=custom_tools, litellm_kwargs=litellm_kwargs\n    )\n</code></pre>"},{"location":"reference/agent/#patchpal.agent.create_agent--with-reasoning-model","title":"With reasoning model","text":"<p>agent = create_agent(     model_id=\"ollama_chat/gpt-oss:120b\",     litellm_kwargs={\"reasoning_effort\": \"high\"} )</p>"},{"location":"reference/agent/#agent-class","title":"Agent Class","text":""},{"location":"reference/agent/#patchpal.agent.PatchPalAgent","title":"<code>patchpal.agent.PatchPalAgent(model_id='anthropic/claude-sonnet-4-5', custom_tools=None, litellm_kwargs=None)</code>","text":"<p>Simple agent that uses LiteLLM for tool calling.</p> <p>Initialize the agent.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>LiteLLM model identifier</p> <code>'anthropic/claude-sonnet-4-5'</code> <code>custom_tools</code> <code>Optional[List[Callable]]</code> <p>Optional list of Python functions to add as tools</p> <code>None</code> <code>litellm_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Optional dict of extra parameters to pass to litellm.completion()           (e.g., {\"reasoning_effort\": \"high\"} for reasoning models)</p> <code>None</code> Source code in <code>patchpal/agent.py</code> <pre><code>def __init__(\n    self,\n    model_id: str = \"anthropic/claude-sonnet-4-5\",\n    custom_tools: Optional[List[Callable]] = None,\n    litellm_kwargs: Optional[Dict[str, Any]] = None,\n):\n    \"\"\"Initialize the agent.\n\n    Args:\n        model_id: LiteLLM model identifier\n        custom_tools: Optional list of Python functions to add as tools\n        litellm_kwargs: Optional dict of extra parameters to pass to litellm.completion()\n                      (e.g., {\"reasoning_effort\": \"high\"} for reasoning models)\n    \"\"\"\n    # Store custom tools\n    self.custom_tools = custom_tools or []\n    self.custom_tool_funcs = {func.__name__: func for func in self.custom_tools}\n\n    # Convert ollama/ to ollama_chat/ for LiteLLM compatibility\n    if model_id.startswith(\"ollama/\"):\n        model_id = model_id.replace(\"ollama/\", \"ollama_chat/\", 1)\n\n    self.model_id = _normalize_bedrock_model_id(model_id)\n\n    # Initialize image handler for vision model support\n    from patchpal.tools.image_handler import ImageHandler\n\n    self.image_handler = ImageHandler(self.model_id)\n\n    # Register Ollama models as supporting native function calling\n    # LiteLLM defaults to JSON mode if not explicitly registered\n    if self.model_id.startswith(\"ollama_chat/\"):\n        # Suppress verbose output from register_model\n        import sys\n        from io import StringIO\n\n        old_stdout = sys.stdout\n        sys.stdout = StringIO()\n        try:\n            litellm.register_model(\n                {\"model_cost\": {self.model_id: {\"supports_function_calling\": True}}}\n            )\n        finally:\n            sys.stdout = old_stdout\n\n    # Set up Bedrock environment if needed\n    if self.model_id.startswith(\"bedrock/\"):\n        _setup_bedrock_env()\n\n    # Conversation history (list of message dicts)\n    self.messages: List[Dict[str, Any]] = []\n\n    # Initialize context manager\n    self.context_manager = ContextManager(self.model_id, SYSTEM_PROMPT)\n\n    # Check if auto-compaction is enabled (default: True)\n    self.enable_auto_compact = not config.DISABLE_AUTOCOMPACT\n\n    # Track last compaction to prevent compaction loops\n    self._last_compaction_message_count = 0\n\n    # Track cumulative token usage across all LLM calls\n    self.total_llm_calls = 0\n    self.cumulative_input_tokens = 0\n    self.cumulative_output_tokens = 0\n\n    # Track cache-related tokens (for Anthropic/Bedrock models with prompt caching)\n    self.cumulative_cache_creation_tokens = 0\n    self.cumulative_cache_read_tokens = 0\n\n    # Track OpenAI cache tokens (prompt_tokens_details.cached_tokens)\n    self.cumulative_openai_cached_tokens = 0\n\n    # Track cumulative costs across all LLM calls\n    self.cumulative_cost = 0.0\n    self.last_message_cost = 0.0\n\n    # LiteLLM settings for models that need parameter dropping\n    self.litellm_kwargs = {}\n    if self.model_id.startswith(\"bedrock/\"):\n        self.litellm_kwargs[\"drop_params\"] = True\n        # Configure LiteLLM to handle Bedrock's strict message alternation requirement\n        # This must be set globally, not as a completion parameter\n        litellm.modify_params = True\n    elif self.model_id.startswith(\"openai/\") and os.getenv(\"OPENAI_API_BASE\"):\n        # Custom OpenAI-compatible servers (vLLM, etc.) often don't support all parameters\n        self.litellm_kwargs[\"drop_params\"] = True\n\n    # Merge in any user-provided litellm_kwargs\n    if litellm_kwargs:\n        self.litellm_kwargs.update(litellm_kwargs)\n\n    # Load MEMORY.md if it exists and has non-template content\n    self._load_project_memory()\n</code></pre>"},{"location":"reference/agent/#patchpal.agent.PatchPalAgent.run","title":"<code>run(user_message, max_iterations=100)</code>","text":"<p>Run the agent on a user message.</p> <p>Parameters:</p> Name Type Description Default <code>user_message</code> <code>str</code> <p>The user's request</p> required <code>max_iterations</code> <code>int</code> <p>Maximum number of agent iterations (default: 100)</p> <code>100</code> <p>Returns:</p> Type Description <code>str</code> <p>The agent's final response</p> Source code in <code>patchpal/agent.py</code> <pre><code>def run(self, user_message: str, max_iterations: int = 100) -&gt; str:\n    \"\"\"Run the agent on a user message.\n\n    Args:\n        user_message: The user's request\n        max_iterations: Maximum number of agent iterations (default: 100)\n\n    Returns:\n        The agent's final response\n    \"\"\"\n    # Add user message to history\n    self.messages.append({\"role\": \"user\", \"content\": user_message})\n\n    # Check for compaction BEFORE starting work\n    # This ensures we never compact mid-execution and lose tool results\n    if self.enable_auto_compact and self.context_manager.needs_compaction(self.messages):\n        self._perform_auto_compaction()\n\n    # Agent loop with interrupt handling\n    try:\n        return self._run_agent_loop(max_iterations)\n    except KeyboardInterrupt:\n        # Clean up conversation state if interrupted mid-execution\n        self._cleanup_interrupted_state()\n        raise  # Re-raise so CLI can handle it\n</code></pre>"},{"location":"reference/agent/#helper-functions","title":"Helper Functions","text":""},{"location":"reference/agent/#patchpal.agent._is_bedrock_arn","title":"<code>patchpal.agent._is_bedrock_arn(model_id)</code>","text":"<p>Check if a model ID is a Bedrock ARN.</p> Source code in <code>patchpal/agent.py</code> <pre><code>def _is_bedrock_arn(model_id: str) -&gt; bool:\n    \"\"\"Check if a model ID is a Bedrock ARN.\"\"\"\n    return (\n        model_id.startswith(\"arn:aws\")\n        and \":bedrock:\" in model_id\n        and \":inference-profile/\" in model_id\n    )\n</code></pre>"},{"location":"reference/agent/#usage-example","title":"Usage Example","text":"<pre><code>from patchpal.agent import create_agent\n\n# Create agent with default model\nagent = create_agent()\n\n# Or specify a model\nagent = create_agent(model_id=\"anthropic/claude-sonnet-4-5\")\n\n# Run a task\nresponse = agent.run(\"List all Python files\")\nprint(response)\n\n# Check token usage\nprint(f\"Total tokens: {agent.cumulative_input_tokens + agent.cumulative_output_tokens:,}\")\n</code></pre>"},{"location":"reference/agent/#related","title":"Related","text":"<ul> <li>Python API Guide - Comprehensive guide to using the Python API</li> <li>Context Management - How context windows are managed</li> <li>Custom Tools - Adding your own tools to the agent</li> </ul>"},{"location":"reference/context/","title":"Context Management API","text":"<p>PatchPal's context management system handles token estimation, context window limits, and automatic compaction.</p>"},{"location":"reference/context/#tokenestimator","title":"TokenEstimator","text":""},{"location":"reference/context/#patchpal.context.TokenEstimator","title":"<code>patchpal.context.TokenEstimator(model_id)</code>","text":"<p>Estimate tokens in messages for context management.</p> Source code in <code>patchpal/context.py</code> <pre><code>def __init__(self, model_id: str):\n    self.model_id = model_id\n    self._encoder = self._get_encoder()\n</code></pre>"},{"location":"reference/context/#patchpal.context.TokenEstimator.estimate_tokens","title":"<code>estimate_tokens(text)</code>","text":"<p>Estimate tokens in text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to estimate tokens for</p> required <p>Returns:</p> Type Description <code>int</code> <p>Estimated token count</p> Source code in <code>patchpal/context.py</code> <pre><code>def estimate_tokens(self, text: str) -&gt; int:\n    \"\"\"Estimate tokens in text.\n\n    Args:\n        text: Text to estimate tokens for\n\n    Returns:\n        Estimated token count\n    \"\"\"\n    if not text:\n        return 0\n\n    if self._encoder:\n        try:\n            return len(self._encoder.encode(str(text)))\n        except Exception:\n            pass\n\n    # Fallback: ~3 chars per token (conservative for code-heavy content)\n    # This is more accurate than 4 chars/token for technical content\n    return len(str(text)) // 3\n</code></pre>"},{"location":"reference/context/#patchpal.context.TokenEstimator.estimate_message_tokens","title":"<code>estimate_message_tokens(message)</code>","text":"<p>Estimate tokens in a single message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Dict[str, Any]</code> <p>Message dict with role, content, tool_calls, etc.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Estimated token count</p> Source code in <code>patchpal/context.py</code> <pre><code>def estimate_message_tokens(self, message: Dict[str, Any]) -&gt; int:\n    \"\"\"Estimate tokens in a single message.\n\n    Args:\n        message: Message dict with role, content, tool_calls, etc.\n\n    Returns:\n        Estimated token count\n    \"\"\"\n    tokens = 0\n\n    # Role and content\n    if \"role\" in message:\n        tokens += 4  # Role overhead\n\n    if \"content\" in message and message[\"content\"]:\n        content = message[\"content\"]\n\n        # Handle multimodal content (list of content blocks)\n        if isinstance(content, list):\n            for block in content:\n                if isinstance(block, dict):\n                    if block.get(\"type\") == \"text\":\n                        # Text content\n                        tokens += self.estimate_tokens(str(block.get(\"text\", \"\")))\n                    elif block.get(\"type\") == \"image_url\":\n                        # Image content - vision models charge varying amounts depending on:\n                        # - Image dimensions (larger = more tokens)\n                        # - Detail level (low/high/auto)\n                        # - Provider (OpenAI: 765-2,298, Anthropic/others: similar)\n                        # Use 1200 tokens as conservative cross-provider estimate\n                        # Reference: oh-my-pi uses same value for reliable context management\n                        tokens += 1200\n                else:\n                    # Fallback for unexpected structure\n                    tokens += self.estimate_tokens(str(block))\n        else:\n            # Regular text content\n            tokens += self.estimate_tokens(str(content))\n\n    # Tool calls\n    if message.get(\"tool_calls\"):\n        for tool_call in message[\"tool_calls\"]:\n            tokens += 10  # Tool call overhead\n            if hasattr(tool_call, \"function\"):\n                tokens += self.estimate_tokens(tool_call.function.name)\n                tokens += self.estimate_tokens(tool_call.function.arguments)\n\n    # Tool call ID\n    if message.get(\"tool_call_id\"):\n        tokens += 5\n\n    # Name field\n    if message.get(\"name\"):\n        tokens += self.estimate_tokens(message[\"name\"])\n\n    return tokens\n</code></pre>"},{"location":"reference/context/#patchpal.context.TokenEstimator.estimate_messages_tokens","title":"<code>estimate_messages_tokens(messages)</code>","text":"<p>Estimate tokens in a list of messages.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>List[Dict[str, Any]]</code> <p>List of message dicts</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total estimated token count</p> Source code in <code>patchpal/context.py</code> <pre><code>def estimate_messages_tokens(self, messages: List[Dict[str, Any]]) -&gt; int:\n    \"\"\"Estimate tokens in a list of messages.\n\n    Args:\n        messages: List of message dicts\n\n    Returns:\n        Total estimated token count\n    \"\"\"\n    return sum(self.estimate_message_tokens(msg) for msg in messages)\n</code></pre>"},{"location":"reference/context/#contextmanager","title":"ContextManager","text":""},{"location":"reference/context/#patchpal.context.ContextManager","title":"<code>patchpal.context.ContextManager(model_id, system_prompt)</code>","text":"<p>Manage context window with auto-compaction and pruning.</p> <p>Initialize context manager.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>LiteLLM model identifier</p> required <code>system_prompt</code> <code>str</code> <p>System prompt text</p> required Source code in <code>patchpal/context.py</code> <pre><code>def __init__(self, model_id: str, system_prompt: str):\n    \"\"\"Initialize context manager.\n\n    Args:\n        model_id: LiteLLM model identifier\n        system_prompt: System prompt text\n    \"\"\"\n    self.model_id = model_id\n    self.system_prompt = system_prompt\n    self.estimator = TokenEstimator(model_id)\n    self.context_limit = self._get_context_limit()\n    self.output_reserve = 4_096  # Reserve tokens for model output\n</code></pre>"},{"location":"reference/context/#patchpal.context.ContextManager.needs_compaction","title":"<code>needs_compaction(messages)</code>","text":"<p>Check if context window needs compaction.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>List[Dict[str, Any]]</code> <p>Current message history</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if compaction is needed</p> Source code in <code>patchpal/context.py</code> <pre><code>def needs_compaction(self, messages: List[Dict[str, Any]]) -&gt; bool:\n    \"\"\"Check if context window needs compaction.\n\n    Args:\n        messages: Current message history\n\n    Returns:\n        True if compaction is needed\n    \"\"\"\n    # Estimate total tokens\n    # Note: Dynamic date/time message adds ~30 tokens on each LLM call\n    system_tokens = self.estimator.estimate_tokens(self.system_prompt)\n    datetime_tokens = 30  # Approximate size of dynamic date/time message\n    message_tokens = self.estimator.estimate_messages_tokens(messages)\n    total_tokens = system_tokens + datetime_tokens + message_tokens + self.output_reserve\n\n    # Check threshold\n    usage_ratio = total_tokens / self.context_limit\n    return usage_ratio &gt;= self.COMPACT_THRESHOLD\n</code></pre>"},{"location":"reference/context/#patchpal.context.ContextManager.get_usage_stats","title":"<code>get_usage_stats(messages)</code>","text":"<p>Get current context usage statistics.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>List[Dict[str, Any]]</code> <p>Current message history</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict with usage statistics</p> Source code in <code>patchpal/context.py</code> <pre><code>def get_usage_stats(self, messages: List[Dict[str, Any]]) -&gt; Dict[str, Any]:\n    \"\"\"Get current context usage statistics.\n\n    Args:\n        messages: Current message history\n\n    Returns:\n        Dict with usage statistics\n    \"\"\"\n    system_tokens = self.estimator.estimate_tokens(self.system_prompt)\n    datetime_tokens = 30  # Approximate size of dynamic date/time message\n    message_tokens = self.estimator.estimate_messages_tokens(messages)\n    total_tokens = system_tokens + datetime_tokens + message_tokens + self.output_reserve\n\n    return {\n        \"system_tokens\": system_tokens + datetime_tokens,  # Include datetime in system count\n        \"message_tokens\": message_tokens,\n        \"output_reserve\": self.output_reserve,\n        \"total_tokens\": total_tokens,\n        \"context_limit\": self.context_limit,\n        \"usage_ratio\": total_tokens / self.context_limit,\n        \"usage_percent\": int((total_tokens / self.context_limit) * 100),\n    }\n</code></pre>"},{"location":"reference/context/#usage-example","title":"Usage Example","text":"<pre><code>from patchpal.agent import create_agent\n\nagent = create_agent()\n\n# Check context usage\nstats = agent.context_manager.get_usage_stats(agent.messages)\nprint(f\"Token usage: {stats['total_tokens']:,} / {stats['context_limit']:,}\")\nprint(f\"Usage: {stats['usage_percent']}%\")\nprint(f\"Output budget remaining: {stats['output_budget_remaining']:,} tokens\")\n\n# Check if compaction is needed\nif agent.context_manager.needs_compaction(agent.messages):\n    print(\"Context window getting full - compaction will trigger soon\")\n\n# Manually trigger compaction (usually automatic)\nagent._perform_auto_compaction()\n</code></pre>"},{"location":"reference/context/#how-context-management-works","title":"How Context Management Works","text":"<ol> <li>Token Estimation: Uses tiktoken (or fallback character estimation) to estimate message tokens</li> <li>Context Limits: Tracks model-specific context window sizes (e.g., 200K for Claude Sonnet)</li> <li>Automatic Compaction: When context reaches 70% full, summarizes old messages to free space</li> <li>Output Budget: Reserves tokens for model output based on context window size</li> </ol>"},{"location":"reference/context/#context-limits-by-model-family","title":"Context Limits by Model Family","text":"<p>The context manager automatically detects limits for common models:</p> <ul> <li>Claude 3.5 Sonnet: 200,000 tokens</li> <li>Claude 3 Opus: 200,000 tokens</li> <li>GPT-4 Turbo: 128,000 tokens</li> <li>GPT-4: 8,192 tokens</li> <li>GPT-3.5: 16,385 tokens</li> </ul> <p>For unknown models, falls back to 128,000 tokens.</p>"},{"location":"reference/context/#related","title":"Related","text":"<ul> <li>Context Management Guide - Overview of context management</li> <li>Agent API - Using the agent with automatic context management</li> </ul>"},{"location":"reference/custom-tools/","title":"Custom Tools API","text":"<p>Create your own tools to extend PatchPal's capabilities with automatic schema generation from Python functions.</p>"},{"location":"reference/custom-tools/#tool-schema-generation","title":"Tool Schema Generation","text":""},{"location":"reference/custom-tools/#function_to_tool_schema","title":"function_to_tool_schema","text":""},{"location":"reference/custom-tools/#patchpal.tools.tool_schema.function_to_tool_schema","title":"<code>patchpal.tools.tool_schema.function_to_tool_schema(func)</code>","text":"<p>Convert a Python function to LiteLLM tool schema.</p> <p>Extracts schema from function signature and docstring.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>Python function with type hints and docstring</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>LiteLLM tool schema dict</p> Source code in <code>patchpal/tools/tool_schema.py</code> <pre><code>def function_to_tool_schema(func: Callable) -&gt; Dict[str, Any]:\n    \"\"\"Convert a Python function to LiteLLM tool schema.\n\n    Extracts schema from function signature and docstring.\n\n    Args:\n        func: Python function with type hints and docstring\n\n    Returns:\n        LiteLLM tool schema dict\n    \"\"\"\n    sig = inspect.signature(func)\n    docstring = inspect.getdoc(func) or \"\"\n\n    # Extract description (first paragraph)\n    description = (\n        docstring.split(\"\\n\\n\")[0].replace(\"\\n\", \" \").strip() or f\"Execute {func.__name__}\"\n    )\n\n    # Parse parameter descriptions\n    param_descriptions = parse_docstring_params(docstring)\n\n    # Get type hints\n    try:\n        type_hints = get_type_hints(func)\n    except Exception:\n        type_hints = {}\n\n    # Build parameters\n    properties = {}\n    required = []\n\n    for param_name, param in sig.parameters.items():\n        if param.kind in (inspect.Parameter.VAR_POSITIONAL, inspect.Parameter.VAR_KEYWORD):\n            continue\n\n        param_type = type_hints.get(param_name, str)\n        param_schema = python_type_to_json_schema(param_type)\n        param_schema[\"description\"] = param_descriptions.get(param_name, f\"Parameter {param_name}\")\n\n        properties[param_name] = param_schema\n\n        if param.default is inspect.Parameter.empty:\n            required.append(param_name)\n\n    return {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": func.__name__,\n            \"description\": description,\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": properties,\n                \"required\": required,\n            },\n        },\n    }\n</code></pre>"},{"location":"reference/custom-tools/#python_type_to_json_schema","title":"python_type_to_json_schema","text":""},{"location":"reference/custom-tools/#patchpal.tools.tool_schema.python_type_to_json_schema","title":"<code>patchpal.tools.tool_schema.python_type_to_json_schema(py_type)</code>","text":"<p>Convert Python type hint to JSON schema type.</p> <p>Parameters:</p> Name Type Description Default <code>py_type</code> <code>Any</code> <p>Python type hint</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>JSON schema type dict</p> Source code in <code>patchpal/tools/tool_schema.py</code> <pre><code>def python_type_to_json_schema(py_type: Any) -&gt; Dict[str, Any]:\n    \"\"\"Convert Python type hint to JSON schema type.\n\n    Args:\n        py_type: Python type hint\n\n    Returns:\n        JSON schema type dict\n    \"\"\"\n    if py_type is type(None):\n        return {\"type\": \"null\"}\n\n    origin = get_origin(py_type)\n\n    # Handle Optional/Union types\n    if origin is Union:\n        args = get_args(py_type)\n        non_none = [a for a in args if a is not type(None)]\n        if non_none:\n            return python_type_to_json_schema(non_none[0])\n\n    # Handle List\n    if origin is list:\n        args = get_args(py_type)\n        if args:\n            return {\"type\": \"array\", \"items\": python_type_to_json_schema(args[0])}\n        return {\"type\": \"array\"}\n\n    # Handle Dict\n    if origin is dict:\n        return {\"type\": \"object\"}\n\n    # Basic types\n    type_map = {\n        str: {\"type\": \"string\"},\n        int: {\"type\": \"integer\"},\n        float: {\"type\": \"number\"},\n        bool: {\"type\": \"boolean\"},\n        list: {\"type\": \"array\"},\n        dict: {\"type\": \"object\"},\n    }\n\n    return type_map.get(py_type, {\"type\": \"string\"})\n</code></pre>"},{"location":"reference/custom-tools/#parse_docstring_params","title":"parse_docstring_params","text":""},{"location":"reference/custom-tools/#patchpal.tools.tool_schema.parse_docstring_params","title":"<code>patchpal.tools.tool_schema.parse_docstring_params(docstring)</code>","text":"<p>Parse parameter descriptions from Google-style docstring.</p> <p>Parameters:</p> Name Type Description Default <code>docstring</code> <code>str</code> <p>Function docstring</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dict mapping parameter names to descriptions</p> Source code in <code>patchpal/tools/tool_schema.py</code> <pre><code>def parse_docstring_params(docstring: str) -&gt; Dict[str, str]:\n    \"\"\"Parse parameter descriptions from Google-style docstring.\n\n    Args:\n        docstring: Function docstring\n\n    Returns:\n        Dict mapping parameter names to descriptions\n    \"\"\"\n    if not docstring:\n        return {}\n\n    params = {}\n    lines = docstring.split(\"\\n\")\n    in_args = False\n\n    for i, line in enumerate(lines):\n        stripped = line.strip()\n\n        if stripped.lower() in (\"args:\", \"arguments:\", \"parameters:\"):\n            in_args = True\n            continue\n\n        if in_args:\n            # Check if we left the Args section\n            if stripped and not line.startswith((\" \", \"\\t\")) and \":\" in stripped:\n                break\n\n            # Parse \"param_name: description\"\n            if \":\" in stripped:\n                parts = stripped.split(\":\", 1)\n                param_name = parts[0].strip()\n                description = parts[1].strip()\n\n                # Collect continuation lines\n                for j in range(i + 1, len(lines)):\n                    next_line = lines[j].strip()\n                    if not next_line or \":\" in next_line:\n                        break\n                    description += \" \" + next_line\n\n                params[param_name] = description\n\n    return params\n</code></pre>"},{"location":"reference/custom-tools/#tool-discovery","title":"Tool Discovery","text":""},{"location":"reference/custom-tools/#discover_tools","title":"discover_tools","text":""},{"location":"reference/custom-tools/#patchpal.tools.tool_schema.discover_tools","title":"<code>patchpal.tools.tool_schema.discover_tools(tools_dir=None, repo_root=None)</code>","text":"<p>Discover custom tool functions from Python files.</p> <p>Loads all .py files from the tools directories and extracts functions that have proper type hints and docstrings.</p> <p>Tool functions must: - Have type hints for all parameters - Have a docstring with description and Args section - Be defined at module level (not nested) - Not start with underscore (private functions ignored)</p> <p>Searches in two locations (in order): 1. Global tools: ~/.patchpal/tools/ 2. Repository-specific tools: /.patchpal/tools/ (if repo_root provided) <p>Repository-specific tools with the same name will override global tools.</p> <p>Parameters:</p> Name Type Description Default <code>tools_dir</code> <code>Optional[Path]</code> <p>Explicit directory to search (overrides default discovery)</p> <code>None</code> <code>repo_root</code> <code>Optional[Path]</code> <p>Repository root path for discovering repo-specific tools</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Callable]</code> <p>List of callable tool functions</p> Source code in <code>patchpal/tools/tool_schema.py</code> <pre><code>def discover_tools(\n    tools_dir: Optional[Path] = None, repo_root: Optional[Path] = None\n) -&gt; List[Callable]:\n    \"\"\"Discover custom tool functions from Python files.\n\n    Loads all .py files from the tools directories and extracts functions\n    that have proper type hints and docstrings.\n\n    Tool functions must:\n    - Have type hints for all parameters\n    - Have a docstring with description and Args section\n    - Be defined at module level (not nested)\n    - Not start with underscore (private functions ignored)\n\n    Searches in two locations (in order):\n    1. Global tools: ~/.patchpal/tools/\n    2. Repository-specific tools: &lt;repo&gt;/.patchpal/tools/ (if repo_root provided)\n\n    Repository-specific tools with the same name will override global tools.\n\n    Args:\n        tools_dir: Explicit directory to search (overrides default discovery)\n        repo_root: Repository root path for discovering repo-specific tools\n\n    Returns:\n        List of callable tool functions\n    \"\"\"\n    tools_by_name = {}  # Track tools by name to allow overrides\n    loaded_modules = []\n\n    # Helper function to load tools from a directory\n    def _load_from_directory(directory: Path, source_label: str):\n        if not directory.exists():\n            return\n\n        # Discover all .py files\n        for tool_file in sorted(directory.glob(\"*.py\")):\n            try:\n                # Create a unique module name to avoid conflicts\n                module_name = f\"patchpal_custom_tools.{source_label}.{tool_file.stem}\"\n\n                # Load the module\n                spec = util.spec_from_file_location(module_name, tool_file)\n                if spec and spec.loader:\n                    module = util.module_from_spec(spec)\n\n                    # Store reference to prevent garbage collection\n                    sys.modules[module_name] = module\n                    loaded_modules.append(module)\n\n                    # Execute the module\n                    spec.loader.exec_module(module)\n\n                    # Extract valid tool functions\n                    for name, obj in inspect.getmembers(module, inspect.isfunction):\n                        # Skip private functions\n                        if name.startswith(\"_\"):\n                            continue\n\n                        # Skip functions from imports (only module-level definitions)\n                        if obj.__module__ != module_name:\n                            continue\n\n                        # Validate tool function\n                        if _is_valid_tool_function(obj):\n                            # Store by function name (later ones override earlier ones)\n                            tools_by_name[name] = obj\n\n            except Exception as e:\n                # Print warning but continue with other tools\n                print(\n                    f\"\\033[1;33m\u26a0\ufe0f  Warning: Failed to load custom tool from {tool_file.name}: {e}\\033[0m\"\n                )\n                continue\n\n    # If explicit tools_dir provided, use only that\n    if tools_dir is not None:\n        _load_from_directory(tools_dir, \"explicit\")\n    else:\n        # Load from global tools directory\n        global_tools_dir = Path.home() / \".patchpal\" / \"tools\"\n        _load_from_directory(global_tools_dir, \"global\")\n\n        # Load from repository-specific tools directory (overrides global)\n        if repo_root is not None:\n            repo_tools_dir = repo_root / \".patchpal\" / \"tools\"\n            _load_from_directory(repo_tools_dir, \"repo\")\n\n    return list(tools_by_name.values())\n</code></pre>"},{"location":"reference/custom-tools/#list_custom_tools","title":"list_custom_tools","text":""},{"location":"reference/custom-tools/#patchpal.tools.tool_schema.list_custom_tools","title":"<code>patchpal.tools.tool_schema.list_custom_tools(tools_dir=None, repo_root=None)</code>","text":"<p>List all custom tools with their descriptions.</p> <p>Parameters:</p> Name Type Description Default <code>tools_dir</code> <code>Optional[Path]</code> <p>Explicit directory to search (overrides default discovery)</p> <code>None</code> <code>repo_root</code> <code>Optional[Path]</code> <p>Repository root path for discovering repo-specific tools</p> <code>None</code> <p>Returns:</p> Type Description <code>List[tuple[str, str, Path]]</code> <p>List of (tool_name, description, file_path) tuples</p> Source code in <code>patchpal/tools/tool_schema.py</code> <pre><code>def list_custom_tools(\n    tools_dir: Optional[Path] = None, repo_root: Optional[Path] = None\n) -&gt; List[tuple[str, str, Path]]:\n    \"\"\"List all custom tools with their descriptions.\n\n    Args:\n        tools_dir: Explicit directory to search (overrides default discovery)\n        repo_root: Repository root path for discovering repo-specific tools\n\n    Returns:\n        List of (tool_name, description, file_path) tuples\n    \"\"\"\n    tools = discover_tools(tools_dir, repo_root)\n\n    result = []\n    for tool in tools:\n        # Extract description from docstring (first line)\n        description = \"\"\n        if tool.__doc__:\n            description = tool.__doc__.split(\"\\n\")[0].strip()\n\n        # Get source file\n        try:\n            source_file = Path(inspect.getfile(tool))\n        except Exception:\n            source_file = Path(\"unknown\")\n\n        result.append((tool.__name__, description, source_file))\n\n    return result\n</code></pre>"},{"location":"reference/custom-tools/#creating-custom-tools","title":"Creating Custom Tools","text":""},{"location":"reference/custom-tools/#basic-example","title":"Basic Example","text":"<pre><code>from typing import Optional\n\ndef calculator(x: int, y: int, operation: str = \"add\") -&gt; str:\n    \"\"\"Perform basic arithmetic operations.\n\n    Args:\n        x: First number\n        y: Second number\n        operation: Operation to perform (add, subtract, multiply, divide)\n\n    Returns:\n        Result as a string\n    \"\"\"\n    if operation == \"add\":\n        return f\"{x} + {y} = {x + y}\"\n    elif operation == \"subtract\":\n        return f\"{x} - {y} = {x - y}\"\n    elif operation == \"multiply\":\n        return f\"{x} * {y} = {x * y}\"\n    elif operation == \"divide\":\n        if y == 0:\n            return \"Error: Cannot divide by zero\"\n        return f\"{x} / {y} = {x / y}\"\n    return \"Unknown operation\"\n</code></pre>"},{"location":"reference/custom-tools/#using-custom-tools","title":"Using Custom Tools","text":"<pre><code>from patchpal.agent import create_agent\n\n# Pass custom tools when creating the agent\nagent = create_agent(custom_tools=[calculator])\n\n# The agent will automatically use your tool when appropriate\nresponse = agent.run(\"What's 15 times 23?\")\n</code></pre>"},{"location":"reference/custom-tools/#advanced-example-with-optional-parameters","title":"Advanced Example with Optional Parameters","text":"<pre><code>from typing import Optional\n\ndef search_code(\n    pattern: str,\n    file_glob: Optional[str] = None,\n    case_sensitive: bool = True\n) -&gt; str:\n    \"\"\"Search for patterns in code files.\n\n    Args:\n        pattern: Regular expression pattern to search for\n        file_glob: Optional glob pattern to filter files (e.g., '*.py')\n        case_sensitive: Whether search should be case-sensitive\n\n    Returns:\n        Search results as formatted string\n    \"\"\"\n    # Your implementation here\n    pass\n</code></pre>"},{"location":"reference/custom-tools/#tool-requirements","title":"Tool Requirements","text":"<p>For a function to work as a custom tool:</p> <ol> <li>Type hints required: All parameters and return type must have type hints</li> <li>Docstring required: Must have a docstring with Args and Returns sections</li> <li>Returns string: Must return a string (the agent sees tool output as text)</li> <li>Valid signature: No <code>*args</code> or <code>**kwargs</code> allowed</li> </ol>"},{"location":"reference/custom-tools/#automatic-schema-generation","title":"Automatic Schema Generation","text":"<p>PatchPal automatically converts your Python function into an LLM tool schema:</p> <ul> <li>Type hints \u2192 JSON schema types</li> <li>Docstring Args \u2192 parameter descriptions</li> <li>Default values \u2192 optional parameters</li> <li>Return type \u2192 validated as string</li> </ul>"},{"location":"reference/custom-tools/#related","title":"Related","text":"<ul> <li>Custom Tools Guide - Complete guide to creating custom tools</li> <li>Agent API - Using custom tools with the agent</li> <li>Python API - Comprehensive Python API guide</li> </ul>"},{"location":"reference/skills/","title":"Skills API","text":"<p>The Skills system allows you to create reusable workflows and custom commands.</p>"},{"location":"reference/skills/#skills-management","title":"Skills Management","text":""},{"location":"reference/skills/#discover_skills","title":"discover_skills","text":""},{"location":"reference/skills/#patchpal.skills.discover_skills","title":"<code>patchpal.skills.discover_skills(repo_root=None)</code>","text":"<p>Discover all available skills from personal and project directories.</p> <p>Parameters:</p> Name Type Description Default <code>repo_root</code> <code>Optional[Path]</code> <p>Repository root path (for project-specific skills)</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Skill]</code> <p>Dictionary mapping skill names to Skill objects</p> Source code in <code>patchpal/skills.py</code> <pre><code>def discover_skills(repo_root: Optional[Path] = None) -&gt; Dict[str, Skill]:\n    \"\"\"Discover all available skills from personal and project directories.\n\n    Args:\n        repo_root: Repository root path (for project-specific skills)\n\n    Returns:\n        Dictionary mapping skill names to Skill objects\n    \"\"\"\n    skills = {}\n\n    # Personal skills: ~/.patchpal/skills/\n    personal_skills_dir = Path.home() / \".patchpal\" / \"skills\"\n    if personal_skills_dir.exists():\n        for skill_dir in personal_skills_dir.iterdir():\n            if skill_dir.is_dir():\n                skill_file = skill_dir / \"SKILL.md\"\n                if skill_file.exists():\n                    skill = _parse_skill_file(skill_file)\n                    if skill:\n                        skills[skill.name] = skill\n\n    # Project-specific skills: &lt;repo&gt;/.patchpal/skills/\n    if repo_root:\n        project_skills_dir = repo_root / \".patchpal\" / \"skills\"\n        if project_skills_dir.exists():\n            for skill_dir in project_skills_dir.iterdir():\n                if skill_dir.is_dir():\n                    skill_file = skill_dir / \"SKILL.md\"\n                    if skill_file.exists():\n                        skill = _parse_skill_file(skill_file)\n                        if skill:\n                            # Project skills override personal skills\n                            skills[skill.name] = skill\n\n    return skills\n</code></pre>"},{"location":"reference/skills/#list_skills","title":"list_skills","text":""},{"location":"reference/skills/#patchpal.skills.list_skills","title":"<code>patchpal.skills.list_skills(repo_root=None)</code>","text":"<p>Get a list of all available skills.</p> <p>Parameters:</p> Name Type Description Default <code>repo_root</code> <code>Optional[Path]</code> <p>Repository root path</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Skill]</code> <p>List of Skill objects sorted by name</p> Source code in <code>patchpal/skills.py</code> <pre><code>def list_skills(repo_root: Optional[Path] = None) -&gt; List[Skill]:\n    \"\"\"Get a list of all available skills.\n\n    Args:\n        repo_root: Repository root path\n\n    Returns:\n        List of Skill objects sorted by name\n    \"\"\"\n    skills = discover_skills(repo_root)\n    return sorted(skills.values(), key=lambda s: s.name)\n</code></pre>"},{"location":"reference/skills/#get_skill","title":"get_skill","text":""},{"location":"reference/skills/#patchpal.skills.get_skill","title":"<code>patchpal.skills.get_skill(name, repo_root=None)</code>","text":"<p>Get a specific skill by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Skill name</p> required <code>repo_root</code> <code>Optional[Path]</code> <p>Repository root path</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[Skill]</code> <p>Skill object or None if not found</p> Source code in <code>patchpal/skills.py</code> <pre><code>def get_skill(name: str, repo_root: Optional[Path] = None) -&gt; Optional[Skill]:\n    \"\"\"Get a specific skill by name.\n\n    Args:\n        name: Skill name\n        repo_root: Repository root path\n\n    Returns:\n        Skill object or None if not found\n    \"\"\"\n    skills = discover_skills(repo_root)\n    return skills.get(name)\n</code></pre>"},{"location":"reference/skills/#skill-class","title":"Skill Class","text":""},{"location":"reference/skills/#patchpal.skills.Skill","title":"<code>patchpal.skills.Skill(name, description, instructions, path)</code>","text":"<p>Represents a PatchPal skill.</p> Source code in <code>patchpal/skills.py</code> <pre><code>def __init__(self, name: str, description: str, instructions: str, path: Path):\n    self.name = name\n    self.description = description\n    self.instructions = instructions\n    self.path = path\n</code></pre>"},{"location":"reference/skills/#usage-example","title":"Usage Example","text":"<pre><code>from patchpal.skills import list_skills, get_skill\n\n# List all available skills\nskills = list_skills()\nfor skill in skills:\n    print(f\"/{skill.name} - {skill.description}\")\n\n# Get a specific skill\nskill = get_skill(\"commit\")\nif skill:\n    print(f\"Name: {skill.name}\")\n    print(f\"Description: {skill.description}\")\n    print(f\"Instructions:\\n{skill.instructions}\")\n</code></pre>"},{"location":"reference/skills/#creating-skills-programmatically","title":"Creating Skills Programmatically","text":"<p>While skills are typically defined as markdown files, you can also work with them programmatically:</p> <pre><code>from pathlib import Path\nfrom patchpal.skills import discover_skills\n\n# Discover all skills in the repository and personal directories\nrepo_root = Path.cwd()\nskills_dict = discover_skills(repo_root)\n\n# Skills are keyed by name\nfor skill_name, skill in skills_dict.items():\n    print(f\"{skill_name}: {skill.description}\")\n</code></pre>"},{"location":"reference/skills/#skill-file-format","title":"Skill File Format","text":"<p>Skills are markdown files with YAML frontmatter:</p> <pre><code>---\nname: myskill\ndescription: A custom skill that does something useful\n---\n\nInstructions for the agent...\n\n1. First do this\n2. Then do that\n3. Finally, complete the task\n</code></pre>"},{"location":"reference/skills/#related","title":"Related","text":"<ul> <li>Skills System Guide - Complete guide to creating and using skills</li> <li>Agent API - Using skills through the agent</li> <li>use_skill tool - Invoking skills programmatically</li> </ul>"},{"location":"reference/tools/","title":"Built-in Tools API","text":"<p>PatchPal includes a comprehensive set of built-in tools for file operations, git, web access, and more.</p>"},{"location":"reference/tools/#file-reading","title":"File Reading","text":""},{"location":"reference/tools/#read_file","title":"read_file","text":""},{"location":"reference/tools/#patchpal.tools.file_reading.read_file","title":"<code>patchpal.tools.file_reading.read_file(path)</code>","text":"<p>Read the contents of a file.</p> <p>Supports text files, images, and documents (PDF, DOCX, PPTX) with automatic processing.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the file (relative to repository root or absolute)</p> required <p>Returns:</p> Type Description <code>str</code> <p>The file contents as a string (text extracted from documents, base64 for images)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If file is too large, unsupported binary format, or sensitive</p> Source code in <code>patchpal/tools/file_reading.py</code> <pre><code>@require_permission_for_read(\n    \"read_file\", get_description=lambda path: f\"   Read: {path}\", get_pattern=lambda path: path\n)\ndef read_file(path: str) -&gt; str:\n    \"\"\"\n    Read the contents of a file.\n\n    Supports text files, images, and documents (PDF, DOCX, PPTX) with automatic processing.\n\n    Args:\n        path: Path to the file (relative to repository root or absolute)\n\n    Returns:\n        The file contents as a string (text extracted from documents, base64 for images)\n\n    Raises:\n        ValueError: If file is too large, unsupported binary format, or sensitive\n    \"\"\"\n    _operation_limiter.check_limit(f\"read_file({path})\")\n\n    p = _check_path(path)\n\n    # Get file size and MIME type\n    size = p.stat().st_size\n    mime_type, _ = mimetypes.guess_type(str(p))\n    ext = p.suffix.lower()\n\n    # Image formats - return as base64 data URL for vision models\n    image_extensions = {\".png\", \".jpg\", \".jpeg\", \".gif\", \".bmp\", \".webp\", \".svg\", \".ico\"}\n    if ext in image_extensions or (mime_type and mime_type.startswith(\"image/\")):\n        # For SVG, return as text since it's XML-based\n        if ext == \".svg\" or mime_type == \"image/svg+xml\":\n            # SVG is text, so apply normal size limit\n            if size &gt; config.MAX_FILE_SIZE:\n                raise ValueError(\n                    f\"SVG file too large: {size:,} bytes (max {config.MAX_FILE_SIZE:,} bytes)\\n\"\n                    f\"Set PATCHPAL_MAX_FILE_SIZE env var to increase\"\n                )\n            with open(p, \"r\", encoding=\"utf-8\", errors=\"surrogateescape\", newline=None) as f:\n                content = f.read()\n            audit_logger.info(f\"READ: {path} ({size} bytes, SVG as text)\")\n            return content\n\n        # For raster images, allow larger files (up to 10MB) since they're for vision models\n        # Vision APIs have their own limits and will resize as needed\n        # Images are formatted as multimodal content by the agent, bypassing tool output truncation\n        max_image_size = config.MAX_IMAGE_SIZE\n        if size &gt; max_image_size:\n            raise ValueError(\n                f\"Image file too large: {size:,} bytes (max {max_image_size:,} bytes)\\n\"\n                f\"Set PATCHPAL_MAX_IMAGE_SIZE env var to increase\\n\"\n                f\"Note: Most vision APIs resize images automatically, so smaller images are recommended\"\n            )\n\n        # Encode as base64\n        import base64\n\n        try:\n            content_bytes = p.read_bytes()\n            b64_data = base64.b64encode(content_bytes).decode(\"utf-8\")\n        except Exception as e:\n            raise ValueError(\n                f\"Failed to read or encode image file '{path}': {e}\\n\"\n                f\"The file may be corrupted or inaccessible.\"\n            )\n\n        # Determine MIME type\n        if mime_type:\n            image_mime = mime_type\n        elif ext == \".jpg\" or ext == \".jpeg\":\n            image_mime = \"image/jpeg\"\n        elif ext == \".png\":\n            image_mime = \"image/png\"\n        elif ext == \".gif\":\n            image_mime = \"image/gif\"\n        elif ext == \".bmp\":\n            image_mime = \"image/bmp\"\n        elif ext == \".webp\":\n            image_mime = \"image/webp\"\n        elif ext == \".ico\":\n            image_mime = \"image/x-icon\"\n        else:\n            image_mime = \"image/png\"  # fallback\n\n        audit_logger.info(f\"READ: {path} ({size} bytes, IMAGE {image_mime})\")\n\n        # Return IMAGE_DATA format that agent will convert to multimodal content\n        # This bypasses tool output truncation limits (PATCHPAL_MAX_TOOL_OUTPUT_CHARS)\n        return f\"IMAGE_DATA:{image_mime}:{b64_data}\"\n\n    # For document formats (PDF/DOCX/PPTX), extract text first, then check extracted size\n    # This allows large binary documents as long as the extracted text fits in context\n    # Check both MIME type and extension (Windows doesn't always recognize Office formats)\n    if (mime_type and \"pdf\" in mime_type) or ext == \".pdf\":\n        # Extract text from PDF (no size check on binary - check extracted text instead)\n        content_bytes = p.read_bytes()\n        text_content = extract_text_from_pdf(content_bytes, source=str(path))\n        audit_logger.info(\n            f\"READ: {path} ({size} bytes binary, {len(text_content)} chars text, PDF)\"\n        )\n        return text_content\n    elif (mime_type and (\"wordprocessingml\" in mime_type or \"msword\" in mime_type)) or ext in (\n        \".docx\",\n        \".doc\",\n    ):\n        # Extract text from DOCX/DOC\n        content_bytes = p.read_bytes()\n        text_content = extract_text_from_docx(content_bytes, source=str(path))\n        audit_logger.info(\n            f\"READ: {path} ({size} bytes binary, {len(text_content)} chars text, DOCX)\"\n        )\n        return text_content\n    elif (mime_type and (\"presentationml\" in mime_type or \"ms-powerpoint\" in mime_type)) or ext in (\n        \".pptx\",\n        \".ppt\",\n    ):\n        # Extract text from PPTX/PPT\n        content_bytes = p.read_bytes()\n        text_content = extract_text_from_pptx(content_bytes, source=str(path))\n        audit_logger.info(\n            f\"READ: {path} ({size} bytes binary, {len(text_content)} chars text, PPTX)\"\n        )\n        return text_content\n\n    # For non-document files, check size before reading\n    if size &gt; config.MAX_FILE_SIZE:\n        raise ValueError(\n            f\"File too large: {size:,} bytes (max {config.MAX_FILE_SIZE:,} bytes)\\n\"\n            f\"Set PATCHPAL_MAX_FILE_SIZE env var to increase\"\n        )\n\n    # Check if binary (for non-document files)\n    if _is_binary_file(p):\n        raise ValueError(\n            f\"Cannot read binary file: {path}\\nType: {mime_type or 'unknown'}\\n\"\n            f\"Supported document formats: PDF, DOCX, PPTX\"\n        )\n\n    # Read as text file\n    with open(p, \"r\", encoding=\"utf-8\", errors=\"surrogateescape\", newline=None) as f:\n        content = f.read()\n    audit_logger.info(f\"READ: {path} ({size} bytes)\")\n    return content\n</code></pre>"},{"location":"reference/tools/#read_lines","title":"read_lines","text":""},{"location":"reference/tools/#patchpal.tools.file_reading.read_lines","title":"<code>patchpal.tools.file_reading.read_lines(path, start_line, end_line=None)</code>","text":"<p>Read specific lines from a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the file (relative to repository root or absolute)</p> required <code>start_line</code> <code>int</code> <p>Starting line number (1-indexed)</p> required <code>end_line</code> <code>Optional[int]</code> <p>Ending line number (inclusive, 1-indexed). If omitted, reads only start_line</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The requested lines with line numbers</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If file not found, binary, sensitive, or line numbers invalid</p> <p>Examples:</p> <p>read_lines(\"src/auth.py\", 45, 60)  # Read lines 45-60 read_lines(\"src/auth.py\", 45)       # Read only line 45</p> Tip <p>Use <code>wc -l filename</code> shell command to find total line count for reading from end</p> Source code in <code>patchpal/tools/file_reading.py</code> <pre><code>@require_permission_for_read(\n    \"read_lines\",\n    get_description=lambda path,\n    start_line,\n    end_line=None: f\"   Read lines {start_line}-{end_line or start_line}: {path}\",\n    get_pattern=lambda path, start_line, end_line=None: path,\n)\ndef read_lines(path: str, start_line: int, end_line: Optional[int] = None) -&gt; str:\n    \"\"\"\n    Read specific lines from a file.\n\n    Args:\n        path: Path to the file (relative to repository root or absolute)\n        start_line: Starting line number (1-indexed)\n        end_line: Ending line number (inclusive, 1-indexed). If omitted, reads only start_line\n\n    Returns:\n        The requested lines with line numbers\n\n    Raises:\n        ValueError: If file not found, binary, sensitive, or line numbers invalid\n\n    Examples:\n        read_lines(\"src/auth.py\", 45, 60)  # Read lines 45-60\n        read_lines(\"src/auth.py\", 45)       # Read only line 45\n\n    Tip:\n        Use `wc -l filename` shell command to find total line count for reading from end\n    \"\"\"\n    _operation_limiter.check_limit(f\"read_lines({path}, {start_line}-{end_line or start_line})\")\n\n    # Validate line numbers\n    if start_line &lt; 1:\n        raise ValueError(f\"start_line must be &gt;= 1, got {start_line}\")\n\n    if end_line is None:\n        end_line = start_line\n    elif end_line &lt; start_line:\n        raise ValueError(f\"end_line ({end_line}) must be &gt;= start_line ({start_line})\")\n\n    p = _check_path(path)\n\n    # Check if binary\n    if _is_binary_file(p):\n        raise ValueError(\n            f\"Cannot read binary file: {path}\\nType: {mimetypes.guess_type(str(p))[0] or 'unknown'}\"\n        )\n\n    # Read file and extract lines\n    try:\n        with open(p, \"r\", encoding=\"utf-8\", errors=\"surrogateescape\", newline=None) as f:\n            lines = f.readlines()\n    except Exception as e:\n        raise ValueError(f\"Failed to read file: {e}\")\n\n    total_lines = len(lines)\n\n    # Check if line numbers are within range\n    if start_line &gt; total_lines:\n        raise ValueError(f\"start_line {start_line} exceeds file length ({total_lines} lines)\")\n\n    # Adjust end_line if it exceeds file length\n    actual_end_line = min(end_line, total_lines)\n\n    # Extract requested lines (convert to 0-indexed)\n    requested_lines = lines[start_line - 1 : actual_end_line]\n\n    # Format output with line numbers\n    result = []\n    for i, line in enumerate(requested_lines, start=start_line):\n        # Remove trailing newline for cleaner output\n        result.append(f\"{i:4d}  {line.rstrip()}\")\n\n    output = \"\\n\".join(result)\n\n    # Add note if we truncated end_line\n    if actual_end_line &lt; end_line:\n        output += (\n            f\"\\n\\n(Note: Requested lines up to {end_line}, but file only has {total_lines} lines)\"\n        )\n\n    audit_logger.info(\n        f\"READ_LINES: {path} lines {start_line}-{actual_end_line} ({len(requested_lines)} lines)\"\n    )\n    return output\n</code></pre>"},{"location":"reference/tools/#file-writing","title":"File Writing","text":""},{"location":"reference/tools/#write_file","title":"write_file","text":""},{"location":"reference/tools/#patchpal.tools.file_writing.write_file","title":"<code>patchpal.tools.file_writing.write_file(path, content)</code>","text":"<p>Write complete file contents from scratch.</p> <p>Overwrites existing files entirely or creates new ones. Use edit_file for small targeted changes (1-20 lines).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Relative path to the file from the repository root</p> required <code>content</code> <code>str</code> <p>Complete file content (entire file, not just changes)</p> required <p>Returns:</p> Type Description <code>str</code> <p>A confirmation message with the unified diff</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If in read-only mode or file is too large</p> Source code in <code>patchpal/tools/file_writing.py</code> <pre><code>def write_file(path: str, content: str) -&gt; str:\n    \"\"\"\n    Write complete file contents from scratch.\n\n    Overwrites existing files entirely or creates new ones. Use edit_file for\n    small targeted changes (1-20 lines).\n\n    Args:\n        path: Relative path to the file from the repository root\n        content: Complete file content (entire file, not just changes)\n\n    Returns:\n        A confirmation message with the unified diff\n\n    Raises:\n        ValueError: If in read-only mode or file is too large\n    \"\"\"\n    _operation_limiter.check_limit(f\"write_file({path})\")\n\n    if config.READ_ONLY:\n        raise ValueError(\n            \"Cannot modify files in read-only mode\\n\"\n            \"Set PATCHPAL_READ_ONLY=false to allow modifications\"\n        )\n\n    p = _check_path(path, must_exist=False)\n\n    # Check size of new content\n    new_size = len(content.encode(\"utf-8\"))\n    if new_size &gt; config.MAX_FILE_SIZE:\n        raise ValueError(\n            f\"New content too large: {new_size:,} bytes (max {config.MAX_FILE_SIZE:,} bytes)\"\n        )\n\n    # Read old content if file exists (needed for diff in permission prompt)\n    old_content = \"\"\n    if p.exists():\n        with open(p, \"r\", encoding=\"utf-8\", errors=\"surrogateescape\", newline=None) as f:\n            old_content = f.read()\n        old = old_content.splitlines(keepends=True)\n    else:\n        old = []\n\n    # Check permission with colored diff\n    permission_manager = _get_permission_manager()\n    operation = \"Create\" if not p.exists() else \"Update\"\n    diff_display = _format_colored_diff(old_content, content, file_path=path)\n\n    # Get permission pattern (directory for outside repo, relative path for inside)\n    permission_pattern = _get_permission_pattern_for_path(path, p)\n\n    # Add warning if writing outside repository (unless it's PatchPal's managed files)\n    outside_repo_warning = _get_outside_repo_warning(p)\n\n    description = f\"   \u25cf {operation}({path}){outside_repo_warning}\\n{diff_display}\"\n\n    if not permission_manager.request_permission(\n        \"write_file\", description, pattern=permission_pattern\n    ):\n        return \"Operation cancelled by user.\"\n\n    # Check git status for uncommitted changes (only for files inside repo)\n    git_status = _check_git_status()\n    git_warning = \"\"\n    if _is_inside_repo(p) and git_status.get(\"is_repo\") and git_status.get(\"has_uncommitted\"):\n        relative_path = str(p.relative_to(common.REPO_ROOT))\n        if any(relative_path in change for change in git_status.get(\"changes\", [])):\n            git_warning = \"\\n\u26a0\ufe0f  Note: File has uncommitted changes in git\\n\"\n\n    # Backup existing file\n    backup_path = None\n    if p.exists():\n        backup_path = _backup_file(p)\n\n    new = content.splitlines(keepends=True)\n\n    # Generate diff\n    diff = difflib.unified_diff(\n        old,\n        new,\n        fromfile=f\"{path} (before)\",\n        tofile=f\"{path} (after)\",\n    )\n    diff_str = \"\".join(diff)\n\n    # Check if critical file\n    warning = \"\"\n    if _is_critical_file(p):\n        warning = \"\\n\u26a0\ufe0f  WARNING: Modifying critical infrastructure file!\\n\"\n\n    # Write the new content\n    p.parent.mkdir(parents=True, exist_ok=True)\n    with open(p, \"w\", encoding=\"utf-8\", errors=\"surrogateescape\", newline=\"\\n\") as f:\n        f.write(content)\n\n    # Audit log\n    audit_logger.info(\n        f\"WRITE: {path} ({new_size} bytes)\" + (f\" [BACKUP: {backup_path}]\" if backup_path else \"\")\n    )\n\n    backup_msg = f\"\\n[Backup saved: {backup_path}]\" if backup_path else \"\"\n\n    return f\"Successfully updated {path}{warning}{git_warning}{backup_msg}\\n\\nDiff:\\n{diff_str}\"\n</code></pre>"},{"location":"reference/tools/#edit_file","title":"edit_file","text":""},{"location":"reference/tools/#patchpal.tools.file_writing.edit_file","title":"<code>patchpal.tools.file_writing.edit_file(path, old_string, new_string)</code>","text":"<p>Edit a file by replacing a string match with flexible whitespace handling.</p> <p>Uses multiple matching strategies to find old_string: 1. Exact match 2. Trimmed line match (ignores indentation differences in search) 3. Normalized whitespace match (ignores spacing differences in search)</p> <p>Important: The flexible matching only applies to FINDING old_string. The new_string is used exactly as provided, so it should include proper indentation/formatting to match the surrounding code.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Relative path to the file from the repository root</p> required <code>old_string</code> <code>str</code> <p>The string to find (whitespace can be approximate)</p> required <code>new_string</code> <code>str</code> <p>The replacement string (use exact whitespace/indentation you want)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Confirmation message with the changes made</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If file not found, old_string not found, or multiple matches</p> Example Source code in <code>patchpal/tools/file_writing.py</code> <pre><code>def edit_file(path: str, old_string: str, new_string: str) -&gt; str:\n    \"\"\"\n    Edit a file by replacing a string match with flexible whitespace handling.\n\n    Uses multiple matching strategies to find old_string:\n    1. Exact match\n    2. Trimmed line match (ignores indentation differences in search)\n    3. Normalized whitespace match (ignores spacing differences in search)\n\n    Important: The flexible matching only applies to FINDING old_string.\n    The new_string is used exactly as provided, so it should include proper\n    indentation/formatting to match the surrounding code.\n\n    Args:\n        path: Relative path to the file from the repository root\n        old_string: The string to find (whitespace can be approximate)\n        new_string: The replacement string (use exact whitespace/indentation you want)\n\n    Returns:\n        Confirmation message with the changes made\n\n    Raises:\n        ValueError: If file not found, old_string not found, or multiple matches\n\n    Example:\n        # Find with flexible matching, but provide new_string with proper indent\n        edit_file(\"test.py\", \"print('hello')\", \"    print('world')\")  # 4 spaces\n    \"\"\"\n    _operation_limiter.check_limit(f\"edit_file({path[:30]}...)\")\n\n    if config.READ_ONLY:\n        raise ValueError(\n            \"Cannot edit files in read-only mode\\n\"\n            \"Set PATCHPAL_READ_ONLY=false to allow modifications\"\n        )\n\n    p = _check_path(path, must_exist=True)\n\n    # Read current content\n    try:\n        with open(p, \"r\", encoding=\"utf-8\", errors=\"surrogateescape\", newline=None) as f:\n            content = f.read()\n    except Exception as e:\n        raise ValueError(f\"Failed to read file: {e}\")\n\n    # Try to find a match using multiple strategies\n    matched_string = _find_match_with_strategies(content, old_string)\n\n    if not matched_string:\n        # No match found with any strategy\n        raise ValueError(\n            f\"String not found in {path}.\\n\\n\"\n            f\"Searched for:\\n{old_string[:200]}\\n\\n\"\n            f\"\ud83d\udca1 Tip: Use read_lines() to see exact content.\"\n        )\n\n    # Count occurrences of the matched string\n    count = content.count(matched_string)\n    if count &gt; 1:\n        # Show WHERE the matches are\n        positions = []\n        start = 0\n        while True:\n            pos = content.find(matched_string, start)\n            if pos == -1:\n                break\n            line_num = content[:pos].count(\"\\n\") + 1\n            positions.append(line_num)\n            start = pos + 1\n\n        raise ValueError(\n            f\"String appears {count} times in {path} at lines: {positions}\\n\"\n            f\"Add more context (3-5 surrounding lines) to make it unique.\\n\\n\"\n            f\"\ud83d\udca1 Tip: Use read_lines() to see the exact context.\"\n        )\n\n    # Perform indentation adjustment and trailing newline preservation BEFORE showing diff\n    # Important: Adjust indentation and preserve trailing newlines to maintain file structure\n    adjusted_new_string = new_string\n\n    # Step 1: Adjust indentation if needed\n    # Get the indentation of the first line in matched_string vs new_string\n    matched_lines = matched_string.split(\"\\n\")\n    new_lines = new_string.split(\"\\n\")\n\n    if matched_lines and new_lines and matched_lines[0] and new_lines[0]:\n        # Get leading whitespace of first line in matched string\n        matched_indent = len(matched_lines[0]) - len(matched_lines[0].lstrip())\n        new_indent = len(new_lines[0]) - len(new_lines[0].lstrip())\n\n        if matched_indent != new_indent:\n            # Need to adjust indentation\n            indent_diff = matched_indent - new_indent\n\n            # Apply the indentation adjustment to all non-empty lines in new_string\n            adjusted_lines = []\n            for line in new_lines:\n                if line.strip():  # Non-empty line\n                    if indent_diff &gt; 0:\n                        # Need to add spaces\n                        adjusted_lines.append((\" \" * indent_diff) + line)\n                    else:\n                        # Need to remove spaces (if possible)\n                        spaces_to_remove = abs(indent_diff)\n                        if line[:spaces_to_remove].strip() == \"\":  # All spaces\n                            adjusted_lines.append(line[spaces_to_remove:])\n                        else:\n                            # Can't remove that many spaces, keep as-is\n                            adjusted_lines.append(line)\n                else:\n                    # Empty line, keep as-is\n                    adjusted_lines.append(line)\n\n            adjusted_new_string = \"\\n\".join(adjusted_lines)\n\n    # Step 2: Preserve trailing newlines from matched_string\n    if matched_string.endswith(\"\\n\") and not adjusted_new_string.endswith(\"\\n\"):\n        # Matched block had trailing newline(s), preserve them\n        # Count consecutive trailing newlines in matched_string\n        trailing_newlines = len(matched_string) - len(matched_string.rstrip(\"\\n\"))\n        adjusted_new_string = adjusted_new_string + (\"\\n\" * trailing_newlines)\n\n    # Check permission before proceeding (use adjusted_new_string for accurate diff display)\n    permission_manager = _get_permission_manager()\n\n    # Format colored diff for permission prompt (use adjusted_new_string so user sees what will actually be written)\n    diff_display = _format_colored_diff(matched_string, adjusted_new_string, file_path=path)\n\n    # Get permission pattern (directory for outside repo, relative path for inside)\n    permission_pattern = _get_permission_pattern_for_path(path, p)\n\n    # Add warning if writing outside repository (unless it's PatchPal's managed files)\n    outside_repo_warning = _get_outside_repo_warning(p)\n\n    description = f\"   \u25cf Update({path}){outside_repo_warning}\\n{diff_display}\"\n\n    if not permission_manager.request_permission(\n        \"edit_file\", description, pattern=permission_pattern\n    ):\n        return \"Operation cancelled by user.\"\n\n    # Backup if enabled\n    backup_path = _backup_file(p)\n\n    new_content = content.replace(matched_string, adjusted_new_string)\n\n    # Write the new content\n    with open(p, \"w\", encoding=\"utf-8\", errors=\"surrogateescape\", newline=\"\\n\") as f:\n        f.write(new_content)\n\n    # Generate diff for the specific change (use adjusted_new_string for accurate diff)\n    old_lines = matched_string.split(\"\\n\")\n    new_lines = adjusted_new_string.split(\"\\n\")\n    diff = difflib.unified_diff(old_lines, new_lines, fromfile=\"old\", tofile=\"new\", lineterm=\"\")\n    diff_str = \"\\n\".join(diff)\n\n    audit_logger.info(f\"EDIT: {path} ({len(matched_string)} -&gt; {len(adjusted_new_string)} chars)\")\n\n    backup_msg = f\"\\n[Backup saved: {backup_path}]\" if backup_path else \"\"\n    return f\"Successfully edited {path}{backup_msg}\\n\\nChange:\\n{diff_str}\"\n</code></pre>"},{"location":"reference/tools/#patchpal.tools.file_writing.edit_file--find-with-flexible-matching-but-provide-new_string-with-proper-indent","title":"Find with flexible matching, but provide new_string with proper indent","text":"<p>edit_file(\"test.py\", \"print('hello')\", \"    print('world')\")  # 4 spaces</p>"},{"location":"reference/tools/#code-analysis","title":"Code Analysis","text":""},{"location":"reference/tools/#code_structure","title":"code_structure","text":""},{"location":"reference/tools/#patchpal.tools.code_analysis.code_structure","title":"<code>patchpal.tools.code_analysis.code_structure(path, max_symbols=50)</code>","text":"<p>Analyze code structure using tree-sitter AST parsing.</p> <p>Returns a compact view of: - File statistics (lines, size) - Functions with signatures and line numbers - Classes with methods - Module/file docstring (if present)</p> <p>This is much more efficient than read_file for understanding code layout. Supports 40+ languages via tree-sitter.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>File path to analyze (relative or absolute)</p> required <code>max_symbols</code> <code>int</code> <p>Maximum number of symbols to show (default: 50)</p> <code>50</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted code structure overview</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code_structure(\"patchpal/tools.py\")\nFile: patchpal/tools.py (2883 lines, 89.2 KB)\n</code></pre> <p>Functions (45):   Line  123: def read_file(path: str, *, encoding: str = \"utf-8\") -&gt; str   Line  234: def write_file(path: str, content: str) -&gt; str   ...</p> <p>Use read_lines('patchpal/tools.py', start, end) to read specific sections.</p> Source code in <code>patchpal/tools/code_analysis.py</code> <pre><code>def code_structure(path: str, max_symbols: int = 50) -&gt; str:\n    \"\"\"\n    Analyze code structure using tree-sitter AST parsing.\n\n    Returns a compact view of:\n    - File statistics (lines, size)\n    - Functions with signatures and line numbers\n    - Classes with methods\n    - Module/file docstring (if present)\n\n    This is much more efficient than read_file for understanding code layout.\n    Supports 40+ languages via tree-sitter.\n\n    Args:\n        path: File path to analyze (relative or absolute)\n        max_symbols: Maximum number of symbols to show (default: 50)\n\n    Returns:\n        Formatted code structure overview\n\n    Examples:\n        &gt;&gt;&gt; code_structure(\"patchpal/tools.py\")\n        File: patchpal/tools.py (2883 lines, 89.2 KB)\n\n        Functions (45):\n          Line  123: def read_file(path: str, *, encoding: str = \"utf-8\") -&gt; str\n          Line  234: def write_file(path: str, content: str) -&gt; str\n          ...\n\n        Use read_lines('patchpal/tools.py', start, end) to read specific sections.\n    \"\"\"\n    _operation_limiter.check_limit(f\"code_structure({path})\")\n\n    if not TREE_SITTER_AVAILABLE:\n        return (\n            \"\u274c Tree-sitter not available. Install with: pip install tree-sitter-language-pack\\n\\n\"\n            \"Fallback: Use read_lines() to read specific sections of the file.\"\n        )\n\n    # Validate and resolve path\n    resolved_path = _check_path(path, must_exist=True)\n\n    # Detect language\n    ext = resolved_path.suffix.lstrip(\".\")\n    language_name = LANGUAGE_MAP.get(ext)\n\n    if not language_name:\n        # Unsupported language, return basic info\n        return _basic_file_info(resolved_path, path)\n\n    try:\n        # Get parser for language\n        parser = get_parser(language_name)\n\n        # Read and parse file\n        with open(resolved_path, \"rb\") as f:\n            source = f.read()\n\n        tree = parser.parse(source)\n        root = tree.root_node\n\n        # Extract symbols\n        symbols = _extract_symbols(root, language_name, source)\n\n        # Format output\n        result = _format_output(resolved_path, path, symbols, max_symbols, source)\n\n        audit_logger.info(f\"CODE_STRUCTURE: {path} ({len(symbols)} symbols)\")\n        return result\n\n    except Exception as e:\n        # Fallback to basic info if parsing fails\n        audit_logger.warning(f\"CODE_STRUCTURE failed for {path}: {e}\")\n        return _basic_file_info(resolved_path, path) + f\"\\n\\n\u26a0\ufe0f  Tree-sitter parsing failed: {e}\"\n</code></pre>"},{"location":"reference/tools/#repository-map","title":"Repository Map","text":""},{"location":"reference/tools/#get_repo_map","title":"get_repo_map","text":""},{"location":"reference/tools/#patchpal.tools.repo_map.get_repo_map","title":"<code>patchpal.tools.repo_map.get_repo_map(max_files=100, include_patterns=None, exclude_patterns=None, focus_files=None)</code>","text":"<p>Generate a compact repository map showing code structure across all files.</p> <p>This provides a bird's-eye view of the codebase, showing function and class signatures without their implementations. Much more token-efficient than reading individual files.</p> <p>Supports 20+ languages including Python, JavaScript, TypeScript, Go, Rust, Java, C/C++, C#, Ruby, PHP, Swift, Kotlin, Scala, Elm, Elixir, and more.</p> <p>Parameters:</p> Name Type Description Default <code>max_files</code> <code>int</code> <p>Maximum number of files to include (default: 100)</p> <code>100</code> <code>include_patterns</code> <code>Optional[List[str]]</code> <p>Glob patterns to include (e.g., ['.py', '.js'])</p> <code>None</code> <code>exclude_patterns</code> <code>Optional[List[str]]</code> <p>Glob patterns to exclude (e.g., ['test', '*_pb2.py'])</p> <code>None</code> <code>focus_files</code> <code>Optional[List[str]]</code> <p>Files mentioned in conversation (prioritized in output)</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted repository map with file structures</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_repo_map(max_files=50)\nRepository Map (50 files):\n</code></pre> <p>src/auth.py:   Line   45: def login(username: str, password: str) -&gt; bool   Line   67: def logout(session_id: str) -&gt; None   Line   89: class AuthManager:</p> <p>src/database.py:   Line   23: class Database:   Line   45:   def connect(self) -&gt; None   ...</p> Token Efficiency <ul> <li>Traditional approach: Read 50 files \u00d7 2,000 tokens = 100,000 tokens</li> <li>With repo map: 50 files \u00d7 150 tokens = 7,500 tokens</li> <li>Savings: 92.5%</li> </ul> Source code in <code>patchpal/tools/repo_map.py</code> <pre><code>def get_repo_map(\n    max_files: int = 100,\n    include_patterns: Optional[List[str]] = None,\n    exclude_patterns: Optional[List[str]] = None,\n    focus_files: Optional[List[str]] = None,\n) -&gt; str:\n    \"\"\"Generate a compact repository map showing code structure across all files.\n\n    This provides a bird's-eye view of the codebase, showing function and class\n    signatures without their implementations. Much more token-efficient than\n    reading individual files.\n\n    Supports 20+ languages including Python, JavaScript, TypeScript, Go, Rust,\n    Java, C/C++, C#, Ruby, PHP, Swift, Kotlin, Scala, Elm, Elixir, and more.\n\n    Args:\n        max_files: Maximum number of files to include (default: 100)\n        include_patterns: Glob patterns to include (e.g., ['*.py', '*.js'])\n        exclude_patterns: Glob patterns to exclude (e.g., ['*test*', '*_pb2.py'])\n        focus_files: Files mentioned in conversation (prioritized in output)\n\n    Returns:\n        Formatted repository map with file structures\n\n    Examples:\n        &gt;&gt;&gt; get_repo_map(max_files=50)\n        Repository Map (50 files):\n\n        src/auth.py:\n          Line   45: def login(username: str, password: str) -&gt; bool\n          Line   67: def logout(session_id: str) -&gt; None\n          Line   89: class AuthManager:\n\n        src/database.py:\n          Line   23: class Database:\n          Line   45:   def connect(self) -&gt; None\n          ...\n\n    Token Efficiency:\n        - Traditional approach: Read 50 files \u00d7 2,000 tokens = 100,000 tokens\n        - With repo map: 50 files \u00d7 150 tokens = 7,500 tokens\n        - Savings: 92.5%\n    \"\"\"\n    _operation_limiter.check_limit(f\"get_repo_map(max_files={max_files})\")\n\n    audit_logger.info(\n        f\"REPO_MAP: Generating (max_files={max_files}, \"\n        f\"include={include_patterns}, exclude={exclude_patterns})\"\n    )\n\n    # Get supported file extensions\n    supported_extensions = set(LANGUAGE_MAP.keys())\n\n    # Convert patterns to sets for faster lookup\n    focus_set = set(focus_files or [])\n\n    # Collect all code files\n    file_structures: Dict[str, str] = {}\n    skipped_count = 0\n\n    for path in REPO_ROOT.rglob(\"*\"):\n        # Skip directories, hidden files, and non-code files\n        if not path.is_file():\n            continue\n        if any(part.startswith(\".\") for part in path.parts):\n            continue\n\n        ext = path.suffix.lstrip(\".\")\n        if ext not in supported_extensions:\n            continue\n\n        # Get relative path\n        try:\n            rel_path = path.relative_to(REPO_ROOT)\n        except ValueError:\n            continue\n\n        # Apply include/exclude patterns\n        if include_patterns:\n            if not any(rel_path.match(pattern) for pattern in include_patterns):\n                skipped_count += 1\n                continue\n        if exclude_patterns:\n            if any(rel_path.match(pattern) for pattern in exclude_patterns):\n                skipped_count += 1\n                continue\n\n        # Try to get from cache\n        structure = _REPO_MAP_CACHE.get(path)\n\n        if structure is None:\n            # Generate structure\n            try:\n                structure = code_structure(str(rel_path), max_symbols=20)\n                if structure and not structure.startswith(\"\u274c\"):\n                    # Extract just the essential parts (remove hints and verbose info)\n                    lines = structure.split(\"\\n\")\n                    essential_lines = []\n                    for line in lines:\n                        # Skip hint lines, empty lines, and file header\n                        if line.startswith(\"\ud83d\udca1\") or line.startswith(\"File:\"):\n                            continue\n                        if line.strip():\n                            essential_lines.append(line)\n\n                    # Limit to 30 lines per file to keep it compact\n                    structure = \"\\n\".join(essential_lines[:30])\n                    _REPO_MAP_CACHE.set(path, structure)\n                else:\n                    structure = None\n            except Exception:\n                structure = None\n\n        if structure:\n            file_structures[str(rel_path)] = structure\n\n    # Mark that we've completed a scan\n    _REPO_MAP_CACHE.mark_scanned()\n\n    # Rank files (focus files first, then alphabetically)\n    def rank_file(path: str) -&gt; Tuple[int, str]:\n        # Priority 0 = focus files, 1 = normal files\n        priority = 0 if path in focus_set else 1\n        return (priority, path)\n\n    ranked_files = sorted(file_structures.keys(), key=rank_file)\n\n    # Build output (limit to max_files)\n    total_files = len(ranked_files)\n    showing_files = min(max_files, total_files)\n\n    output_lines = [f\"Repository Map ({total_files} files analyzed, showing {showing_files}):\\n\"]\n\n    if skipped_count &gt; 0:\n        output_lines.append(f\"(Skipped {skipped_count} files based on include/exclude patterns)\\n\")\n\n    for file_path in ranked_files[:max_files]:\n        structure = file_structures[file_path]\n        output_lines.append(f\"\\n{file_path}:\")\n\n        # Show structure (truncate if needed for extremely long files)\n        structure_preview = structure[:800]  # ~250 tokens max per file\n        if len(structure) &gt; 800:\n            structure_preview += \"\\n  [... more symbols omitted ...]\"\n\n        output_lines.append(structure_preview)\n\n    # Add footer with helpful information\n    if total_files &gt; max_files:\n        output_lines.append(f\"\\n... and {total_files - max_files} more files not shown\")\n        output_lines.append(\n            \"\\n\ud83d\udca1 Increase max_files parameter or use include_patterns to refine results\"\n        )\n\n    output_lines.append(\"\\n\ud83d\udca1 Use code_structure(path) to see full details for a specific file\")\n    output_lines.append(\"\ud83d\udca1 Use read_file(path) to see complete implementation\")\n\n    result = \"\\n\".join(output_lines)\n\n    # Calculate rough token estimate (1 char \u2248 0.3 tokens for code)\n    estimated_tokens = len(result) // 3\n\n    audit_logger.info(\n        f\"REPO_MAP: Generated {len(result):,} chars (~{estimated_tokens:,} tokens) \"\n        f\"for {total_files} files\"\n    )\n\n    return result\n</code></pre>"},{"location":"reference/tools/#get_repo_map_stats","title":"get_repo_map_stats","text":""},{"location":"reference/tools/#patchpal.tools.repo_map.get_repo_map_stats","title":"<code>patchpal.tools.repo_map.get_repo_map_stats()</code>","text":"<p>Get statistics about the repository map cache.</p> <p>Returns:</p> Type Description <code>Dict[str, any]</code> <p>Dictionary with cache statistics including:</p> <code>Dict[str, any]</code> <ul> <li>cached_files: Number of files in cache</li> </ul> <code>Dict[str, any]</code> <ul> <li>last_scan: Timestamp of last full scan</li> </ul> <code>Dict[str, any]</code> <ul> <li>cache_age: Seconds since last scan</li> </ul> Source code in <code>patchpal/tools/repo_map.py</code> <pre><code>def get_repo_map_stats() -&gt; Dict[str, any]:\n    \"\"\"Get statistics about the repository map cache.\n\n    Returns:\n        Dictionary with cache statistics including:\n        - cached_files: Number of files in cache\n        - last_scan: Timestamp of last full scan\n        - cache_age: Seconds since last scan\n    \"\"\"\n    return {\n        \"cached_files\": len(_REPO_MAP_CACHE.cache),\n        \"last_scan\": _REPO_MAP_CACHE.last_full_scan,\n        \"cache_age\": time.time() - _REPO_MAP_CACHE.last_full_scan,\n    }\n</code></pre>"},{"location":"reference/tools/#clear_repo_map_cache","title":"clear_repo_map_cache","text":""},{"location":"reference/tools/#patchpal.tools.repo_map.clear_repo_map_cache","title":"<code>patchpal.tools.repo_map.clear_repo_map_cache()</code>","text":"<p>Clear the repository map cache.</p> <p>Useful if files have been added/removed outside of PatchPal's awareness, or if you want to force a fresh scan.</p> Source code in <code>patchpal/tools/repo_map.py</code> <pre><code>def clear_repo_map_cache():\n    \"\"\"Clear the repository map cache.\n\n    Useful if files have been added/removed outside of PatchPal's awareness,\n    or if you want to force a fresh scan.\n    \"\"\"\n    global _REPO_MAP_CACHE\n    _REPO_MAP_CACHE = RepoMapCache()\n    audit_logger.info(\"REPO_MAP: Cache cleared\")\n</code></pre>"},{"location":"reference/tools/#shell-execution","title":"Shell Execution","text":""},{"location":"reference/tools/#run_shell","title":"run_shell","text":""},{"location":"reference/tools/#patchpal.tools.shell_tools.run_shell","title":"<code>patchpal.tools.shell_tools.run_shell(cmd)</code>","text":"<p>Run a safe shell command in the repository.</p> <p>Parameters:</p> Name Type Description Default <code>cmd</code> <code>str</code> <p>The shell command to execute</p> required <p>Returns:</p> Type Description <code>str</code> <p>Combined stdout and stderr output</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If command contains forbidden operations</p> Source code in <code>patchpal/tools/shell_tools.py</code> <pre><code>def run_shell(cmd: str) -&gt; str:\n    \"\"\"\n    Run a safe shell command in the repository.\n\n    Args:\n        cmd: The shell command to execute\n\n    Returns:\n        Combined stdout and stderr output\n\n    Raises:\n        ValueError: If command contains forbidden operations\n    \"\"\"\n    # Check permission before proceeding\n    permission_manager = _get_permission_manager()\n    description = f\"   {cmd}\"\n    # Extract meaningful command pattern and working directory, handling compound commands\n    command_name, working_dir = _extract_shell_command_info(cmd)\n\n    # Create composite pattern: \"command@directory\" for cd commands, just \"command\" otherwise\n    # Using @ separator for cross-platform compatibility (: would conflict with Windows paths like C:\\temp)\n    if working_dir and command_name:\n        pattern = f\"{command_name}@{working_dir}\"\n    else:\n        pattern = command_name\n\n    # Pass working_dir separately for display purposes\n    if not permission_manager.request_permission(\n        \"run_shell\", description, pattern=pattern, context=working_dir, full_command=cmd\n    ):\n        return \"Operation cancelled by user.\"\n\n    _operation_limiter.check_limit(f\"run_shell({cmd[:50]}...)\")\n\n    # Check for dangerous tokens (privilege escalation commands)\n    # Token-based matching: splits command and checks each token\n    if any(tok in DANGEROUS_TOKENS for tok in cmd.split()):\n        raise ValueError(\n            f\"Blocked dangerous command: {cmd}\\nForbidden operations: {', '.join(DANGEROUS_TOKENS)}\"\n        )\n\n    # Check for dangerous patterns (destructive operations)\n    # Substring matching: checks if pattern appears anywhere in command\n    for pattern in DANGEROUS_PATTERNS:\n        if pattern in cmd:\n            raise ValueError(\n                f\"Blocked dangerous pattern in command: {pattern}\\nFull command: {cmd}\"\n            )\n\n    audit_logger.info(f\"SHELL: {cmd}\")\n\n    result = subprocess.run(\n        cmd,\n        shell=True,\n        capture_output=True,\n        cwd=common.REPO_ROOT,\n        timeout=config.SHELL_TIMEOUT,\n    )\n\n    # Decode output with error handling for problematic characters\n    # Use utf-8 on all platforms with 'replace' to handle encoding issues\n    stdout = result.stdout.decode(\"utf-8\", errors=\"replace\") if result.stdout else \"\"\n    stderr = result.stderr.decode(\"utf-8\", errors=\"replace\") if result.stderr else \"\"\n\n    output = stdout + stderr\n\n    # Apply output filtering to reduce token usage\n    if OutputFilter.should_filter(cmd):\n        filtered_output = OutputFilter.filter_output(cmd, output)\n        # Log if we filtered significantly\n        original_lines = len(output.split(\"\\n\"))\n        filtered_lines = len(filtered_output.split(\"\\n\"))\n        if filtered_lines &lt; original_lines * 0.5:\n            audit_logger.info(\n                f\"SHELL_FILTER: Reduced output from {original_lines} to {filtered_lines} lines \"\n                f\"(~{int((1 - filtered_lines / original_lines) * 100)}% reduction)\"\n            )\n        return filtered_output\n\n    return output\n</code></pre>"},{"location":"reference/tools/#web-tools","title":"Web Tools","text":""},{"location":"reference/tools/#web_search","title":"web_search","text":""},{"location":"reference/tools/#patchpal.tools.web_tools.web_search","title":"<code>patchpal.tools.web_tools.web_search(query, max_results=5)</code>","text":"<p>Search the web using DuckDuckGo and return results.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The search query</p> required <code>max_results</code> <code>int</code> <p>Maximum number of results to return (default: 5, max: 10)</p> <code>5</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted search results with titles, URLs, and snippets</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If search fails</p> Source code in <code>patchpal/tools/web_tools.py</code> <pre><code>def web_search(query: str, max_results: int = 5) -&gt; str:\n    \"\"\"\n    Search the web using DuckDuckGo and return results.\n\n    Args:\n        query: The search query\n        max_results: Maximum number of results to return (default: 5, max: 10)\n\n    Returns:\n        Formatted search results with titles, URLs, and snippets\n\n    Raises:\n        ValueError: If search fails\n    \"\"\"\n    # Check permission before proceeding\n    permission_manager = _get_permission_manager()\n    description = f\"   Search: {query}\"\n    if not permission_manager.request_permission(\"web_search\", description):\n        return \"Operation cancelled by user.\"\n\n    _operation_limiter.check_limit(f\"web_search({query[:30]}...)\")\n\n    # Limit max_results\n    max_results = min(max_results, 10)\n\n    try:\n        # Determine SSL verification setting\n        # Priority: PATCHPAL_VERIFY_SSL env var &gt; SSL_CERT_FILE &gt; REQUESTS_CA_BUNDLE &gt; default True\n        verify_ssl = config.VERIFY_SSL\n        if verify_ssl is not None:\n            # User explicitly set PATCHPAL_VERIFY_SSL\n            if verify_ssl.lower() in (\"false\", \"0\", \"no\"):\n                verify = False\n            elif verify_ssl.lower() in (\"true\", \"1\", \"yes\"):\n                verify = True\n            else:\n                # Treat as path to CA bundle\n                verify = verify_ssl\n        else:\n            # Use SSL_CERT_FILE or REQUESTS_CA_BUNDLE if set (for corporate environments)\n            verify = os.getenv(\"SSL_CERT_FILE\") or os.getenv(\"REQUESTS_CA_BUNDLE\") or True\n\n        # Perform search using DuckDuckGo\n        with DDGS(verify=verify) as ddgs:\n            results = list(ddgs.text(query, max_results=max_results))\n\n        if not results:\n            audit_logger.info(f\"WEB_SEARCH: {query} - No results\")\n            return f\"No search results found for: {query}\"\n\n        # Format results\n        formatted_results = [f\"Search results for: {query}\\n\"]\n        for i, result in enumerate(results, 1):\n            title = result.get(\"title\", \"No title\")\n            url = result.get(\"href\", \"No URL\")\n            snippet = result.get(\"body\", \"No description\")\n\n            formatted_results.append(f\"\\n{i}. {title}\\n   URL: {url}\\n   {snippet}\")\n\n        output = \"\\n\".join(formatted_results)\n        audit_logger.info(f\"WEB_SEARCH: {query} - Found {len(results)} results\")\n        return output\n\n    except Exception as e:\n        error_msg = str(e)\n\n        # Provide helpful error messages for common issues\n        if \"CERTIFICATE_VERIFY_FAILED\" in error_msg or \"TLS handshake failed\" in error_msg:\n            return (\n                \"Web search unavailable: SSL certificate verification failed.\\n\"\n                \"This may be due to:\\n\"\n                \"- Corporate proxy/firewall blocking requests\\n\"\n                \"- Network configuration issues\\n\"\n                \"- VPN interference\\n\\n\"\n                \"Consider using web_fetch with a specific URL if you have one.\"\n            )\n        elif \"RuntimeError\" in error_msg or \"error sending request\" in error_msg:\n            return (\n                \"Web search unavailable: Network connection failed.\\n\"\n                \"Please check your internet connection and try again.\"\n            )\n        else:\n            raise ValueError(f\"Web search failed: {e}\")\n</code></pre>"},{"location":"reference/tools/#web_fetch","title":"web_fetch","text":""},{"location":"reference/tools/#patchpal.tools.web_tools.web_fetch","title":"<code>patchpal.tools.web_tools.web_fetch(url, extract_text=True)</code>","text":"<p>Fetch content from a URL and optionally extract readable text.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to fetch</p> required <code>extract_text</code> <code>bool</code> <p>If True, extract readable text from HTML/PDF (default: True)</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>The fetched content (text extracted from HTML/PDF if extract_text=True)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If request fails or content is too large</p> Source code in <code>patchpal/tools/web_tools.py</code> <pre><code>def web_fetch(url: str, extract_text: bool = True) -&gt; str:\n    \"\"\"\n    Fetch content from a URL and optionally extract readable text.\n\n    Args:\n        url: The URL to fetch\n        extract_text: If True, extract readable text from HTML/PDF (default: True)\n\n    Returns:\n        The fetched content (text extracted from HTML/PDF if extract_text=True)\n\n    Raises:\n        ValueError: If request fails or content is too large\n    \"\"\"\n    # Check permission before proceeding\n    permission_manager = _get_permission_manager()\n    description = f\"   Fetch: {url}\"\n    if not permission_manager.request_permission(\"web_fetch\", description):\n        return \"Operation cancelled by user.\"\n\n    _operation_limiter.check_limit(f\"web_fetch({url[:50]}...)\")\n\n    # Validate URL format\n    if not url.startswith((\"http://\", \"https://\")):\n        raise ValueError(\"URL must start with http:// or https://\")\n\n    try:\n        # Make request with timeout and browser-like headers\n        response = requests.get(\n            url,\n            timeout=config.WEB_TIMEOUT,\n            headers=WEB_HEADERS,\n            stream=True,  # Stream to check size first\n            allow_redirects=True,  # Follow redirects (including moved repos)\n        )\n        response.raise_for_status()\n\n        # Check content size\n        content_length = response.headers.get(\"Content-Length\")\n        if content_length and int(content_length) &gt; config.MAX_WEB_SIZE:\n            raise ValueError(\n                f\"Content too large: {int(content_length):,} bytes \"\n                f\"(max {config.MAX_WEB_SIZE:,} bytes)\"\n            )\n\n        # Read content with size limit\n        content = b\"\"\n        for chunk in response.iter_content(chunk_size=8192):\n            content += chunk\n            if len(content) &gt; config.MAX_WEB_SIZE:\n                raise ValueError(f\"Content exceeds size limit ({config.MAX_WEB_SIZE:,} bytes)\")\n\n        # Get content type\n        content_type = response.headers.get(\"Content-Type\", \"\").lower()\n\n        # Extract text based on content type\n        if extract_text:\n            if \"pdf\" in content_type:\n                # Extract text from PDF\n                try:\n                    text_content = extract_text_from_pdf(content, source=url)\n                except ValueError as e:\n                    # Return helpful error message if extraction fails\n                    text_content = f\"[{e}]\"\n            elif \"wordprocessingml\" in content_type or \"msword\" in content_type:\n                # Extract text from DOCX (or DOC if saved as docx)\n                try:\n                    text_content = extract_text_from_docx(content, source=url)\n                except ValueError as e:\n                    text_content = f\"[{e}]\"\n            elif \"presentationml\" in content_type or \"ms-powerpoint\" in content_type:\n                # Extract text from PPTX (or PPT if saved as pptx)\n                try:\n                    text_content = extract_text_from_pptx(content, source=url)\n                except ValueError as e:\n                    text_content = f\"[{e}]\"\n            elif \"html\" in content_type:\n                # Extract text from HTML\n                text_content = content.decode(response.encoding or \"utf-8\", errors=\"replace\")\n                soup = BeautifulSoup(text_content, \"html.parser\")\n\n                # Remove script and style elements\n                for element in soup([\"script\", \"style\", \"nav\", \"footer\", \"header\"]):\n                    element.decompose()\n\n                # Get text\n                text = soup.get_text()\n\n                # Clean up whitespace\n                lines = (line.strip() for line in text.splitlines())\n                chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n                text_content = \"\\n\".join(chunk for chunk in chunks if chunk)\n            else:\n                # For other content types, check if it's a known binary format\n                binary_formats = [\n                    \"image/\",\n                    \"video/\",\n                    \"audio/\",\n                    \"application/zip\",\n                    \"application/x-zip\",\n                    \"application/x-rar\",\n                    \"application/x-tar\",\n                    \"spreadsheetml\",  # Excel files (xlsx) - not yet supported\n                    \"ms-excel\",  # Legacy Excel files (xls) - not yet supported\n                    \"application/octet-stream\",\n                ]\n                is_binary = any(fmt in content_type for fmt in binary_formats)\n\n                if is_binary:\n                    text_content = (\n                        f\"[WARNING: Unsupported binary format]\\n\\n\"\n                        f\"Content-Type: {content_type}\\n\"\n                        f\"URL: {url}\\n\\n\"\n                        f\"This appears to be a binary file format that cannot be extracted as text.\\n\"\n                        f\"Supported formats: HTML, PDF, DOCX, PPTX, plain text, JSON, XML.\\n\"\n                        f\"To access this content, download it locally or use a format-specific tool.\"\n                    )\n                else:\n                    # Assume it's text-based (JSON, XML, CSV, etc.)\n                    text_content = content.decode(response.encoding or \"utf-8\", errors=\"replace\")\n        else:\n            # No text extraction - just decode\n            text_content = content.decode(response.encoding or \"utf-8\", errors=\"replace\")\n\n        # Note: Output truncation is handled by universal MAX_TOOL_OUTPUT_CHARS limit in agent.py\n        audit_logger.info(f\"WEB_FETCH: {url} ({len(text_content)} chars)\")\n        return text_content\n\n    except requests.Timeout:\n        raise ValueError(f\"Request timed out after {config.WEB_TIMEOUT} seconds\")\n    except requests.RequestException as e:\n        raise ValueError(f\"Failed to fetch URL: {e}\")\n    except Exception as e:\n        raise ValueError(f\"Error processing content: {e}\")\n</code></pre>"},{"location":"reference/tools/#todo-management","title":"TODO Management","text":""},{"location":"reference/tools/#todo_add","title":"todo_add","text":""},{"location":"reference/tools/#patchpal.tools.todo_tools.todo_add","title":"<code>patchpal.tools.todo_tools.todo_add(description, details='')</code>","text":"<p>Add a new task to the TODO list.</p> <p>Use this to break down complex tasks into manageable subtasks. Each task gets a unique ID for tracking and completion.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>Brief task description (one line)</p> required <code>details</code> <code>str</code> <p>Optional detailed notes about the task</p> <code>''</code> <p>Returns:</p> Type Description <code>str</code> <p>Confirmation with the task ID</p> Example <p>todo_add(\"Read authentication module\", details=\"Focus on session handling logic\") todo_add(\"Add input validation to login endpoint\")</p> Source code in <code>patchpal/tools/todo_tools.py</code> <pre><code>def todo_add(description: str, details: str = \"\") -&gt; str:\n    \"\"\"\n    Add a new task to the TODO list.\n\n    Use this to break down complex tasks into manageable subtasks.\n    Each task gets a unique ID for tracking and completion.\n\n    Args:\n        description: Brief task description (one line)\n        details: Optional detailed notes about the task\n\n    Returns:\n        Confirmation with the task ID\n\n    Example:\n        todo_add(\"Read authentication module\", details=\"Focus on session handling logic\")\n        todo_add(\"Add input validation to login endpoint\")\n    \"\"\"\n    _operation_limiter.check_limit(f\"todo_add({description[:30]}...)\")\n\n    data = _load_todos()\n\n    # Create new task\n    task = {\n        \"id\": data[\"next_id\"],\n        \"description\": description,\n        \"details\": details,\n        \"completed\": False,\n        \"created_at\": datetime.now().isoformat(),\n    }\n\n    data[\"tasks\"].append(task)\n    data[\"next_id\"] += 1\n\n    _save_todos(data)\n\n    result = f\"\u2713 Added task #{task['id']}: {description}\"\n    if details:\n        result += f\"\\n  Details: {details}\"\n\n    audit_logger.info(f\"TODO_ADD: #{task['id']} - {description[:50]}\")\n    return result\n</code></pre>"},{"location":"reference/tools/#todo_list","title":"todo_list","text":""},{"location":"reference/tools/#patchpal.tools.todo_tools.todo_list","title":"<code>patchpal.tools.todo_tools.todo_list(show_completed=False)</code>","text":"<p>List all tasks in the TODO list.</p> <p>Parameters:</p> Name Type Description Default <code>show_completed</code> <code>bool</code> <p>If True, show completed tasks; if False, show only pending tasks (default: False)</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted list of tasks with IDs, status, and descriptions</p> Source code in <code>patchpal/tools/todo_tools.py</code> <pre><code>def todo_list(show_completed: bool = False) -&gt; str:\n    \"\"\"\n    List all tasks in the TODO list.\n\n    Args:\n        show_completed: If True, show completed tasks; if False, show only pending tasks (default: False)\n\n    Returns:\n        Formatted list of tasks with IDs, status, and descriptions\n    \"\"\"\n    _operation_limiter.check_limit(\"todo_list()\")\n\n    data = _load_todos()\n    tasks = data[\"tasks\"]\n\n    if not tasks:\n        return \"No tasks in TODO list.\\n\\nUse todo_add() to create a new task plan.\"\n\n    # Filter tasks based on show_completed\n    if show_completed:\n        display_tasks = tasks\n        header = \"TODO List (All Tasks):\"\n    else:\n        display_tasks = [t for t in tasks if not t[\"completed\"]]\n        header = \"TODO List (Pending Tasks):\"\n        if not display_tasks:\n            return \"No pending tasks. All tasks completed! \u2713\\n\\nUse todo_list(show_completed=True) to see completed tasks.\"\n\n    separator = \"=\" * 80\n\n    lines = [header, separator]\n\n    for task in display_tasks:\n        status = \"\u2713\" if task[\"completed\"] else \"\u25cb\"\n        lines.append(f\"\\n{status} Task #{task['id']}: {task['description']}\")\n\n        if task.get(\"details\"):\n            # Indent details\n            detail_lines = task[\"details\"].split(\"\\n\")\n            for line in detail_lines:\n                lines.append(f\"  {line}\")\n\n        # Show creation time\n        try:\n            created = datetime.fromisoformat(task[\"created_at\"])\n            lines.append(f\"  Created: {created.strftime('%Y-%m-%d %H:%M')}\")\n        except Exception:\n            pass\n\n        # Show completion time if completed\n        if task[\"completed\"] and task.get(\"completed_at\"):\n            try:\n                completed = datetime.fromisoformat(task[\"completed_at\"])\n                lines.append(f\"  Completed: {completed.strftime('%Y-%m-%d %H:%M')}\")\n            except Exception:\n                pass\n\n    # Summary\n    total = len(tasks)\n    completed = sum(1 for t in tasks if t[\"completed\"])\n    pending = total - completed\n\n    lines.append(f\"\\n{separator}\")\n    lines.append(f\"Summary: {pending} pending, {completed} completed, {total} total\")\n\n    audit_logger.info(f\"TODO_LIST: {pending} pending, {completed} completed\")\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/tools/#todo_complete","title":"todo_complete","text":""},{"location":"reference/tools/#patchpal.tools.todo_tools.todo_complete","title":"<code>patchpal.tools.todo_tools.todo_complete(task_id)</code>","text":"<p>Mark a task as completed.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>int</code> <p>The ID of the task to complete</p> required <p>Returns:</p> Type Description <code>str</code> <p>Confirmation message</p> Example <p>todo_complete(1)  # Mark task #1 as done</p> Source code in <code>patchpal/tools/todo_tools.py</code> <pre><code>def todo_complete(task_id: int) -&gt; str:\n    \"\"\"\n    Mark a task as completed.\n\n    Args:\n        task_id: The ID of the task to complete\n\n    Returns:\n        Confirmation message\n\n    Example:\n        todo_complete(1)  # Mark task #1 as done\n    \"\"\"\n    _operation_limiter.check_limit(f\"todo_complete({task_id})\")\n\n    data = _load_todos()\n\n    # Find the task\n    task = None\n    for t in data[\"tasks\"]:\n        if t[\"id\"] == task_id:\n            task = t\n            break\n\n    if not task:\n        available_ids = [t[\"id\"] for t in data[\"tasks\"]]\n        return f\"Task #{task_id} not found.\\n\\nAvailable task IDs: {available_ids}\\n\\nUse todo_list() to see all tasks.\"\n\n    if task[\"completed\"]:\n        return f\"Task #{task_id} is already completed: {task['description']}\"\n\n    # Mark as completed\n    task[\"completed\"] = True\n    task[\"completed_at\"] = datetime.now().isoformat()\n\n    _save_todos(data)\n\n    # Show progress\n    total = len(data[\"tasks\"])\n    completed = sum(1 for t in data[\"tasks\"] if t[\"completed\"])\n\n    result = f\"\u2713 Completed task #{task_id}: {task['description']}\"\n    result += f\"\\n\\nProgress: {completed}/{total} tasks completed\"\n\n    audit_logger.info(f\"TODO_COMPLETE: #{task_id} - {task['description'][:50]}\")\n    return result\n</code></pre>"},{"location":"reference/tools/#todo_update","title":"todo_update","text":""},{"location":"reference/tools/#patchpal.tools.todo_tools.todo_update","title":"<code>patchpal.tools.todo_tools.todo_update(task_id, description=None, details=None)</code>","text":"<p>Update a task's description or details.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>int</code> <p>The ID of the task to update</p> required <code>description</code> <code>str</code> <p>New description (optional)</p> <code>None</code> <code>details</code> <code>str</code> <p>New details (optional)</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Confirmation message</p> Example <p>todo_update(1, description=\"Read auth module and session handling\") todo_update(2, details=\"Need to check for SQL injection vulnerabilities\")</p> Source code in <code>patchpal/tools/todo_tools.py</code> <pre><code>def todo_update(task_id: int, description: str = None, details: str = None) -&gt; str:\n    \"\"\"\n    Update a task's description or details.\n\n    Args:\n        task_id: The ID of the task to update\n        description: New description (optional)\n        details: New details (optional)\n\n    Returns:\n        Confirmation message\n\n    Example:\n        todo_update(1, description=\"Read auth module and session handling\")\n        todo_update(2, details=\"Need to check for SQL injection vulnerabilities\")\n    \"\"\"\n    _operation_limiter.check_limit(f\"todo_update({task_id})\")\n\n    if description is None and details is None:\n        return \"Error: Must provide either description or details to update\"\n\n    data = _load_todos()\n\n    # Find the task\n    task = None\n    for t in data[\"tasks\"]:\n        if t[\"id\"] == task_id:\n            task = t\n            break\n\n    if not task:\n        available_ids = [t[\"id\"] for t in data[\"tasks\"]]\n        return f\"Task #{task_id} not found.\\n\\nAvailable task IDs: {available_ids}\"\n\n    # Update fields\n    changes = []\n    if description is not None:\n        old_desc = task[\"description\"]\n        task[\"description\"] = description\n        changes.append(f\"Description: '{old_desc}' \u2192 '{description}'\")\n\n    if details is not None:\n        task[\"details\"] = details\n        changes.append(\"Details updated\")\n\n    _save_todos(data)\n\n    result = f\"\u2713 Updated task #{task_id}\\n\"\n    result += \"\\n\".join(f\"  \u2022 {change}\" for change in changes)\n\n    audit_logger.info(f\"TODO_UPDATE: #{task_id} - {changes}\")\n    return result\n</code></pre>"},{"location":"reference/tools/#todo_remove","title":"todo_remove","text":""},{"location":"reference/tools/#patchpal.tools.todo_tools.todo_remove","title":"<code>patchpal.tools.todo_tools.todo_remove(task_id)</code>","text":"<p>Remove a task from the TODO list.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>int</code> <p>The ID of the task to remove</p> required <p>Returns:</p> Type Description <code>str</code> <p>Confirmation message</p> Example <p>todo_remove(1)  # Remove task #1</p> Source code in <code>patchpal/tools/todo_tools.py</code> <pre><code>def todo_remove(task_id: int) -&gt; str:\n    \"\"\"\n    Remove a task from the TODO list.\n\n    Args:\n        task_id: The ID of the task to remove\n\n    Returns:\n        Confirmation message\n\n    Example:\n        todo_remove(1)  # Remove task #1\n    \"\"\"\n    _operation_limiter.check_limit(f\"todo_remove({task_id})\")\n\n    data = _load_todos()\n\n    # Find and remove the task\n    task = None\n    for i, t in enumerate(data[\"tasks\"]):\n        if t[\"id\"] == task_id:\n            task = data[\"tasks\"].pop(i)\n            break\n\n    if not task:\n        available_ids = [t[\"id\"] for t in data[\"tasks\"]]\n        return f\"Task #{task_id} not found.\\n\\nAvailable task IDs: {available_ids}\"\n\n    _save_todos(data)\n\n    result = f\"\u2713 Removed task #{task_id}: {task['description']}\"\n    remaining = len(data[\"tasks\"])\n    result += f\"\\n\\n{remaining} task(s) remaining in TODO list\"\n\n    audit_logger.info(f\"TODO_REMOVE: #{task_id} - {task['description'][:50]}\")\n    return result\n</code></pre>"},{"location":"reference/tools/#todo_clear","title":"todo_clear","text":""},{"location":"reference/tools/#patchpal.tools.todo_tools.todo_clear","title":"<code>patchpal.tools.todo_tools.todo_clear(completed_only=True)</code>","text":"<p>Clear tasks from the TODO list.</p> <p>Parameters:</p> Name Type Description Default <code>completed_only</code> <code>bool</code> <p>If True, clear only completed tasks; if False, clear all tasks (default: True)</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Confirmation message</p> Example <p>todo_clear()              # Clear completed tasks todo_clear(completed_only=False)  # Clear all tasks (start fresh)</p> Source code in <code>patchpal/tools/todo_tools.py</code> <pre><code>def todo_clear(completed_only: bool = True) -&gt; str:\n    \"\"\"\n    Clear tasks from the TODO list.\n\n    Args:\n        completed_only: If True, clear only completed tasks; if False, clear all tasks (default: True)\n\n    Returns:\n        Confirmation message\n\n    Example:\n        todo_clear()              # Clear completed tasks\n        todo_clear(completed_only=False)  # Clear all tasks (start fresh)\n    \"\"\"\n    _operation_limiter.check_limit(\"todo_clear()\")\n\n    data = _load_todos()\n\n    if not data[\"tasks\"]:\n        return \"TODO list is already empty.\"\n\n    if completed_only:\n        completed_tasks = [t for t in data[\"tasks\"] if t[\"completed\"]]\n        if not completed_tasks:\n            return \"No completed tasks to clear.\"\n\n        # Keep only pending tasks\n        data[\"tasks\"] = [t for t in data[\"tasks\"] if not t[\"completed\"]]\n        count = len(completed_tasks)\n        _save_todos(data)\n\n        result = f\"\u2713 Cleared {count} completed task(s)\"\n        remaining = len(data[\"tasks\"])\n        if remaining &gt; 0:\n            result += f\"\\n\\n{remaining} pending task(s) remaining\"\n    else:\n        # Clear all tasks\n        count = len(data[\"tasks\"])\n        data[\"tasks\"] = []\n        _save_todos(data)\n\n        result = f\"\u2713 Cleared all {count} task(s)\\n\\nTODO list is now empty. Use todo_add() to create a new task plan.\"\n\n    audit_logger.info(f\"TODO_CLEAR: {count} task(s) cleared (completed_only={completed_only})\")\n    return result\n</code></pre>"},{"location":"reference/tools/#user-interaction","title":"User Interaction","text":""},{"location":"reference/tools/#list_skills","title":"list_skills","text":""},{"location":"reference/tools/#patchpal.tools.user_interaction.list_skills","title":"<code>patchpal.tools.user_interaction.list_skills()</code>","text":"<p>List all available skills that can be invoked.</p> <p>Skills are reusable workflows stored in: - Personal: ~/.patchpal/skills/ - Project: /.patchpal/skills/ <p>Returns:</p> Type Description <code>str</code> <p>Formatted list of available skills with names and descriptions</p> Source code in <code>patchpal/tools/user_interaction.py</code> <pre><code>def list_skills() -&gt; str:\n    \"\"\"\n    List all available skills that can be invoked.\n\n    Skills are reusable workflows stored in:\n    - Personal: ~/.patchpal/skills/\n    - Project: &lt;repo&gt;/.patchpal/skills/\n\n    Returns:\n        Formatted list of available skills with names and descriptions\n    \"\"\"\n    _operation_limiter.check_limit(\"list_skills()\")\n\n    from patchpal.skills import list_skills as discover_all_skills\n\n    skills = discover_all_skills(repo_root=common.REPO_ROOT)\n\n    if not skills:\n        return \"\"\"No skills found.\n\nTo get started:\n1. View examples: https://github.com/amaiya/patchpal/tree/main/examples/skills\n2. Copy examples to your personal skills directory:\n   mkdir -p ~/.patchpal/skills\n   # Download and copy the commit and review skills from the examples folder\n3. Or create your own skill in ~/.patchpal/skills/&lt;skill-name&gt;/SKILL.md\n\nSkills are markdown files with YAML frontmatter. See the examples for the format.\"\"\"\n\n    header = f\"Available Skills ({len(skills)}):\"\n    separator = \"-\" * 100\n\n    lines = [header, separator]\n    for skill in skills:\n        lines.append(f\"  /{skill.name}\")\n        lines.append(f\"    {skill.description}\")\n        lines.append(\"\")\n\n    lines.append(\"How to invoke skills:\")\n    lines.append(\"  - User types: /skill_name (e.g., /commit)\")\n    lines.append(\"  - Or just ask naturally and the agent will discover the right skill\")\n\n    audit_logger.info(f\"LIST_SKILLS: {len(skills)} skill(s)\")\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/tools/#use_skill","title":"use_skill","text":""},{"location":"reference/tools/#patchpal.tools.user_interaction.use_skill","title":"<code>patchpal.tools.user_interaction.use_skill(skill_name, args='')</code>","text":"<p>Invoke a skill with optional arguments.</p> <p>Parameters:</p> Name Type Description Default <code>skill_name</code> <code>str</code> <p>Name of the skill to invoke (without / prefix)</p> required <code>args</code> <code>str</code> <p>Optional arguments to pass to the skill</p> <code>''</code> <p>Returns:</p> Type Description <code>str</code> <p>The skill's instructions formatted with any provided arguments</p> Example <p>use_skill(\"commit\", args=\"Fix bug in auth\")</p> Source code in <code>patchpal/tools/user_interaction.py</code> <pre><code>def use_skill(skill_name: str, args: str = \"\") -&gt; str:\n    \"\"\"\n    Invoke a skill with optional arguments.\n\n    Args:\n        skill_name: Name of the skill to invoke (without / prefix)\n        args: Optional arguments to pass to the skill\n\n    Returns:\n        The skill's instructions formatted with any provided arguments\n\n    Example:\n        use_skill(\"commit\", args=\"Fix bug in auth\")\n    \"\"\"\n    _operation_limiter.check_limit(f\"use_skill({skill_name})\")\n\n    from patchpal.skills import get_skill\n\n    skill = get_skill(skill_name, repo_root=common.REPO_ROOT)\n\n    if not skill:\n        available_skills = list_skills()\n        return f\"Skill not found: {skill_name}\\n\\n{available_skills}\"\n\n    # Format the skill instructions with arguments if provided\n    instructions = skill.instructions\n    if args:\n        instructions = f\"{instructions}\\n\\nArguments: {args}\"\n\n    audit_logger.info(f\"USE_SKILL: {skill_name} (args={args[:50]})\")\n\n    return f\"Skill: {skill.name}\\n\\n{instructions}\"\n</code></pre>"},{"location":"reference/tools/#ask_user","title":"ask_user","text":""},{"location":"reference/tools/#patchpal.tools.user_interaction.ask_user","title":"<code>patchpal.tools.user_interaction.ask_user(question, options=None)</code>","text":"<p>Ask the user a question and wait for their response.</p> <p>This allows the agent to interactively clarify requirements, get decisions, or gather additional information during task execution.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>The question to ask the user</p> required <code>options</code> <code>Optional[list]</code> <p>Optional list of predefined answer choices (e.g., [\"yes\", \"no\", \"skip\"])     If provided, user can select from these or type a custom answer</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The user's answer as a string</p> Example <p>ask_user(\"Which authentication method should I use?\", options=[\"JWT\", \"OAuth2\", \"Session\"]) ask_user(\"Should I add error handling to all endpoints?\")</p> Source code in <code>patchpal/tools/user_interaction.py</code> <pre><code>def ask_user(question: str, options: Optional[list] = None) -&gt; str:\n    \"\"\"\n    Ask the user a question and wait for their response.\n\n    This allows the agent to interactively clarify requirements, get decisions,\n    or gather additional information during task execution.\n\n    Args:\n        question: The question to ask the user\n        options: Optional list of predefined answer choices (e.g., [\"yes\", \"no\", \"skip\"])\n                If provided, user can select from these or type a custom answer\n\n    Returns:\n        The user's answer as a string\n\n    Example:\n        ask_user(\"Which authentication method should I use?\", options=[\"JWT\", \"OAuth2\", \"Session\"])\n        ask_user(\"Should I add error handling to all endpoints?\")\n    \"\"\"\n    _operation_limiter.check_limit(f\"ask_user({question[:30]}...)\")\n\n    from prompt_toolkit import prompt\n    from prompt_toolkit.formatted_text import FormattedText\n    from rich.console import Console\n    from rich.markdown import Markdown\n    from rich.panel import Panel\n\n    console = Console()\n\n    # Format the question - use markdown rendering if it contains markdown syntax\n    console.print()\n\n    # Check if the question contains markdown code blocks or other markdown\n    has_markdown = any(marker in question for marker in [\"```\", \"**\", \"##\", \"- \", \"* \", \"1. \"])\n\n    if has_markdown:\n        # For markdown content, just use a simple header to keep code blocks copyable\n        console.print(\"[bold cyan]Question from Agent:[/bold cyan]\")\n        console.print()\n        md = Markdown(question)\n        console.print(md)\n        console.print()\n    else:\n        # Simple text question in a panel\n        console.print(\n            Panel(\n                question,\n                title=\"[bold cyan]Question from Agent[/bold cyan]\",\n                border_style=\"cyan\",\n                padding=(1, 2),\n            )\n        )\n\n    # Show options if provided\n    if options:\n        console.print(\"\\n[bold]Available options:[/bold]\")\n        for i, option in enumerate(options, 1):\n            console.print(f\"  {i}. {option}\")\n        console.print(\n            \"\\n[dim]You can select a number, type an option, or provide a custom answer.[/dim]\\n\"\n        )\n\n        # Get user input using prompt_toolkit for proper readline support\n        prompt_text = FormattedText([(\"ansibrightgreen bold\", \"Your answer:\"), (\"\", \" \")])\n        user_input = prompt(prompt_text).strip()\n\n        # Check if user entered a number corresponding to an option\n        try:\n            choice_num = int(user_input)\n            if 1 &lt;= choice_num &lt;= len(options):\n                answer = options[choice_num - 1]\n                console.print(f\"[dim]Selected: {answer}[/dim]\\n\")\n            else:\n                answer = user_input\n        except ValueError:\n            # Not a number, use as-is\n            answer = user_input\n    else:\n        # No options, just get free-form answer\n        prompt_text = FormattedText([(\"ansibrightgreen bold\", \"Your answer:\"), (\"\", \" \")])\n        answer = prompt(prompt_text).strip()\n        console.print()\n\n    audit_logger.info(f\"ASK_USER: Q: {question[:50]}... A: {answer[:50]}\")\n    return answer\n</code></pre>"},{"location":"reference/tools/#related","title":"Related","text":"<ul> <li>Built-In Tools Guide - Overview of all built-in tools</li> <li>Custom Tools - Creating your own tools</li> <li>Agent API - Using tools through the agent</li> </ul>"},{"location":"usage/autopilot/","title":"Autopilot Mode","text":"<p>Autopilot mode enables autonomous iterative development where the agent repeatedly works on a task until completion. Based on the \"Ralph Wiggum technique\" pioneered by Geoffrey Huntley, it embodies persistent iteration over perfection.</p> <p>\u26a0\ufe0f CRITICAL SAFETY WARNING: Autopilot disables PatchPal's permission system. ONLY use in isolated environments (Docker containers, VMs, throwaway projects). See examples/ralph/ for comprehensive safety guidelines.</p>"},{"location":"usage/autopilot/#quick-start","title":"Quick Start","text":"<pre><code># After pip install patchpal, autopilot is available immediately\n\n# Option 1: Direct command\npatchpal-autopilot \\\n  --prompt-file task.md \\\n  --completion-promise \"DONE\" \\\n  --max-iterations 50\n\n# Option 2: Use as a Python library\npython -c \"\nfrom patchpal.cli.autopilot import autopilot_loop\nautopilot_loop(\n    prompt='Build a calculator with tests. When complete, output: &lt;promise&gt;COMPLETE&lt;/promise&gt;',\n    completion_promise='COMPLETE',\n    max_iterations=20\n)\n\"\n</code></pre> <p>Custom Tools: Autopilot automatically loads custom tools from both <code>~/.patchpal/tools/</code> (global) and <code>.patchpal/tools/</code> (repository-specific), same as the interactive CLI. See Custom Tools for details.</p>"},{"location":"usage/autopilot/#how-it-works","title":"How It Works","text":"<p>The key insight: The agent sees its previous work in conversation history and can adjust its approach, notice failures, and try different solutions automatically.</p> <pre><code>1. Agent works on task\n2. Agent tries to exit\n3. Stop hook intercepts \u2190 Key mechanism!\n4. Same prompt fed back\n5. Agent sees previous work in history\n6. Agent adjusts approach\n7. Repeat until completion promise found\n</code></pre> <p>The agent never actually \"completes\" until it outputs the completion promise string.</p>"},{"location":"usage/autopilot/#key-principles","title":"Key Principles","text":"<ul> <li>Iteration &gt; Perfection: Let the loop refine the work, don't aim for perfect first try</li> <li>Failures Are Data: Deterministically bad means failures are predictable and informative</li> <li>Operator Skill Matters: Success depends on writing good prompts, not just having a good model</li> <li>Persistence Wins: Keep trying until success\u2014the loop handles retry logic automatically</li> </ul>"},{"location":"usage/autopilot/#writing-effective-prompts","title":"Writing Effective Prompts","text":"<p>Good autopilot prompts have:</p> <p>1. Clear Completion Criteria <pre><code># Success Criteria\n- All tests pass (pytest -v shows green)\n- Coverage &gt;80%\n- No linter errors\n- README with API documentation\n\nWhen complete, output: &lt;promise&gt;COMPLETE&lt;/promise&gt;\n</code></pre></p> <p>2. Self-Correction Pattern <pre><code># Process\n1. Write code in app.py\n2. Write tests in test_app.py\n3. Run tests: run_shell(\"pytest test_app.py -v\")\n4. If any fail, debug and fix\n5. Repeat until all pass\n</code></pre></p> <p>3. Incremental Goals <pre><code># Requirements\nPhase 1: Core CRUD operations\nPhase 2: Input validation\nPhase 3: Error handling\nPhase 4: Tests (&gt;80% coverage)\n</code></pre></p> <p>4. Escape Hatch <pre><code># If Stuck\nAfter 10 iterations without progress:\n- Document blocking issues in BLOCKED.md\n- List attempted approaches\n- Suggest alternatives\n</code></pre></p>"},{"location":"usage/autopilot/#real-world-examples","title":"Real-World Examples","text":"<p>See examples/ralph/ for complete examples: - simple_autopilot_example.py: Basic calculator task - multi_phase_todo_api_example.py: Multi-phase API build (3 sequential phases) - prompts/: Example prompt templates for different task types</p>"},{"location":"usage/autopilot/#using-as-a-python-library","title":"Using as a Python Library","text":"<pre><code>from patchpal.cli.autopilot import autopilot_loop\n\nresult = autopilot_loop(\n    prompt=\"\"\"\nBuild a REST API for todos.\n\nRequirements:\n- Flask app with CRUD endpoints\n- Input validation (title required, max 200 chars)\n- Unit tests with pytest (&gt;80% coverage)\n- All tests passing\n\nProcess:\n1. Create app.py with routes\n2. Write tests in test_app.py\n3. Run: run_shell(\"pytest test_app.py -v\")\n4. Fix failures and retry\n\nOutput: &lt;promise&gt;COMPLETE&lt;/promise&gt; when done.\n    \"\"\",\n    completion_promise=\"COMPLETE\",\n    max_iterations=30,\n    model=\"anthropic/claude-sonnet-4-5\"  # optional\n)\n\nif result:\n    print(\"\u2705 Task completed successfully!\")\nelse:\n    print(\"\u26a0\ufe0f Did not complete within max iterations\")\n</code></pre>"},{"location":"usage/autopilot/#safety-sandboxed-environments-only","title":"Safety: Sandboxed Environments Only","text":"<p>Why Isolation Is Critical:</p> <p>Autopilot runs with <code>PATCHPAL_REQUIRE_PERMISSION=false</code>: - No permission prompts for file modifications - No permission prompts for shell commands - Multiple iterations without human oversight - Potential for catastrophic mistakes</p> <p>Recommended Isolation:</p> <p>Option 1: Docker/Podman Container (Good) <pre><code># Create and run in isolated container\ndocker run -it --rm \\\n  -v $(pwd):/workspace \\\n  --memory=\"2g\" --cpus=\"2\" \\\n  python:3.11-slim bash\n\n# Inside container\npip install patchpal\npatchpal-autopilot --prompt-file task.md --completion-promise \"DONE\"\n</code></pre></p> <p>Option 2: Dedicated VM/Server (Best) <pre><code># Use a separate machine/VM with no access to production\nssh autopilot-sandbox\ncd /workspace/throwaway-project\npatchpal-autopilot --prompt-file task.md --completion-promise \"DONE\"\n</code></pre></p>"},{"location":"usage/autopilot/#best-practices","title":"Best Practices","text":"<p>Always: - \u2705 Use version control (commit before running) - \u2705 Run in isolated environments - \u2705 Start with low max-iterations (5-10) to validate prompts - \u2705 Monitor with <code>git status</code> or <code>watch -n 2 'git status --short'</code> - \u2705 Review all changes before committing</p> <p>Never: - \u274c Run on codebases in production - \u274c Run on your main development machine without container - \u274c Leave running unattended on important systems</p>"},{"location":"usage/autopilot/#real-world-results","title":"Real-World Results","text":"<p>The Ralph Wiggum technique has been successfully used for: - 6 repos at Y Combinator hackathon - Generated overnight - $50k contract for $297 in API costs - Complete tested project - CURSED programming language - Built over 3 months - Test-driven development - Excellent for TDD workflows</p> <p>See examples/ralph/ for comprehensive documentation, safety guidelines, and more examples.</p>"},{"location":"usage/autopilot/#learn-more","title":"Learn More","text":"<ul> <li>Comprehensive Guide: examples/ralph/ - Safety, prompts, patterns, troubleshooting</li> <li>Ralph Wiggum Technique Origins:</li> <li>https://www.humanlayer.dev/blog/brief-history-of-ralph</li> <li>https://awesomeclaude.ai/ralph-wiggum</li> <li>https://github.com/ghuntley/ralph</li> </ul>"},{"location":"usage/examples/","title":"Example Tasks","text":""},{"location":"usage/examples/#coding-tasks","title":"Coding Tasks","text":"<pre><code>Resolve this error message: \"UnicodeDecodeError: 'charmap' codec can't decode\"\n\nBuild a streamlit app to &lt;whatever you want&gt;\n\nCreate a bar chart for top 5 downloaded Python packages as of yesterday\n\nFind and implement best practices for async/await in Python\n\nAdd GitHub CI/CD for this project\n\nAdd type hints and basic logging to mymodule.py\n\nCreate unit tests for the utils module\n\nRefactor the authentication code for better security\n\nAdd error handling to all API calls\n\nLook up the latest FastAPI documentation and add dependency injection\n</code></pre>"},{"location":"usage/examples/#image-analysis-tasks","title":"Image Analysis Tasks","text":"<p>When using vision-capable models (GPT-4o, Claude 3.5 Sonnet, etc.), PatchPal can analyze images:</p> <pre><code>Look at screenshot.png and tell me what's wrong with the UI\n\nCompare before.jpg and after.jpg - what changed?\n\nAnalyze this architecture diagram: system-design.png\n\nWhat does this error screenshot show? error.png\n\nReview the UI mockup in design.png and suggest improvements\n\nExtract the text from this screenshot: terminal-output.png\n\nIs the layout in homepage.jpg mobile-responsive?\n\nAnalyze this chart visualization.png and explain the trends\n</code></pre> <p>How it works: Simply mention image files in your prompt. The agent will automatically use the <code>read_file</code> tool to load and analyze them.</p> <p>Supported formats: PNG, JPG, JPEG, GIF, BMP, WEBP (SVG is returned as text)</p>"},{"location":"usage/interactive/","title":"Interactive Usage","text":"<p>Simply run the <code>patchpal</code> command and type your requests interactively:</p> <pre><code>$ patchpal\n \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n \u2551  PatchPal - AI Coding and Automation Assistant \ud83e\udd16    \u2551\n \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nUsing model: anthropic/claude-sonnet-4-5\n\nType 'exit' to quit or '/help' to see available commands.\n\nYou: Add type hints and basic logging to my_module.py\n</code></pre> <p>The agent will process your request and show you the results. You can continue with follow-up tasks or type <code>exit</code> to quit.</p>"},{"location":"usage/interactive/#interactive-features","title":"Interactive Features","text":"<ul> <li>Path Autocompletion: Press <code>Tab</code> while typing file paths to see suggestions (e.g., <code>./src/mo</code> + Tab \u2192 <code>./src/models.py</code>)</li> <li>Skill Autocompletion: Type <code>/</code> followed by Tab to see available skills (e.g., <code>/comm</code> + Tab \u2192 <code>/commit</code>)</li> <li>Command History: Use \u2191 (up arrow) and \u2193 (down arrow) to navigate through previous commands within the current session</li> <li>Interrupt Agent: Press <code>Ctrl-C</code> during agent execution to stop the current task without exiting PatchPal</li> <li>Exit: Type <code>exit</code>, <code>quit</code>, or press <code>Ctrl-C</code> at the prompt to exit PatchPal</li> </ul>"},{"location":"usage/python-api/","title":"Python SDK","text":"<p>PatchPal can be used programmatically from Python scripts or a REPL, giving you full agent capabilities with an easy-to-use Python SDK (Software Development Kit). PatchPal supports both human-in-the-loop workflows (default) and fully autonomous operation through Autopilot mode. By default, users maintain control through interactive permission prompts, making it ideal for code assistance, debugging, and automation tasks that benefit from human oversight. For fully autonomous iterative development, see the Autopilot documentation.</p> <p>Complete API Reference</p> <p>For detailed API documentation with all parameters, return types, and method signatures, see the API Reference section.</p>"},{"location":"usage/python-api/#basic-usage","title":"Basic Usage","text":"<pre><code>from patchpal.agent import create_agent\n\n# Create an agent (uses default model or PATCHPAL_MODEL env var)\nagent = create_agent()\n\n# Or specify a model explicitly\nagent = create_agent(model_id=\"anthropic/claude-sonnet-4_5\")\n\n# Run the agent on a task\nresponse = agent.run(\"List all Python files in this directory\")\nprint(response)\n\n# Continue the conversation (history is maintained)\nresponse = agent.run(\"Now read the main agent file\")\nprint(response)\n</code></pre>"},{"location":"usage/python-api/#adding-custom-tools","title":"Adding Custom Tools","text":"<p>Custom tools can be used in three ways:</p> <ol> <li>Global tools: Place <code>.py</code> files in <code>~/.patchpal/tools/</code> (auto-discovered at startup)</li> <li>Repository-specific tools: Place <code>.py</code> files in <code>&lt;repo&gt;/.patchpal/tools/</code> (auto-discovered at startup)</li> <li>Python API: Pass functions directly to <code>create_agent(custom_tools=[...])</code></li> </ol> <p>All methods use the same tool schema auto-generation from Python functions with type hints and docstrings:</p> <pre><code>from patchpal.agent import create_agent\n\ndef calculator(x: int, y: int, operation: str = \"add\") -&gt; str:\n    \"\"\"Perform basic arithmetic operations.\n\n    Args:\n        x: First number\n        y: Second number\n        operation: Operation to perform (add, subtract, multiply, divide)\n\n    Returns:\n        Result as a string\n    \"\"\"\n    if operation == \"add\":\n        return f\"{x} + {y} = {x + y}\"\n    elif operation == \"subtract\":\n        return f\"{x} - {y} = {x - y}\"\n    elif operation == \"multiply\":\n        return f\"{x} * {y} = {x * y}\"\n    elif operation == \"divide\":\n        if y == 0:\n            return \"Error: Cannot divide by zero\"\n        return f\"{x} / {y} = {x / y}\"\n    return \"Unknown operation\"\n\n\ndef get_weather(city: str, units: str = \"celsius\") -&gt; str:\n    \"\"\"Get weather information for a city.\n\n    Args:\n        city: Name of the city\n        units: Temperature units (celsius or fahrenheit)\n\n    Returns:\n        Weather information string\n    \"\"\"\n    # Your implementation here (API call, etc.)\n    return f\"Weather in {city}: 22\u00b0{units[0].upper()}, Sunny\"\n\n\n# Create agent with custom tools\nagent = create_agent(\n    model_id=\"anthropic/claude-sonnet-4-5\",\n    custom_tools=[calculator, get_weather]\n)\n\n# Use the agent - it will call your custom tools when appropriate\nresponse = agent.run(\"What's 15 multiplied by 23?\")\nprint(response)\n\nresponse = agent.run(\"What's the weather in Paris?\")\nprint(response)\n</code></pre> <p>Key Points: - Custom tools are automatically converted to LLM tool schemas - Functions should have type hints and Google-style docstrings - The agent will call your functions when appropriate - Tool execution follows the same permission system as built-in tools</p>"},{"location":"usage/python-api/#advanced-usage","title":"Advanced Usage","text":"<pre><code>from patchpal.agent import PatchPalAgent\n\n# Create agent with custom configuration\nagent = PatchPalAgent(model_id=\"anthropic/claude-sonnet-4-5\")\n\n# Set custom max iterations for complex tasks\nresponse = agent.run(\"Refactor the entire codebase\", max_iterations=200)\n\n# Access conversation history\nprint(f\"Messages in history: {len(agent.messages)}\")\n\n# Check context window usage\nstats = agent.context_manager.get_usage_stats(agent.messages)\nprint(f\"Token usage: {stats['total_tokens']:,} / {stats['context_limit']:,}\")\nprint(f\"Usage: {stats['usage_percent']}%\")\n\n# Manually trigger compaction if needed\nif agent.context_manager.needs_compaction(agent.messages):\n    agent._perform_auto_compaction()\n\n# Track API costs (cumulative token counts across session)\nprint(f\"Total LLM calls: {agent.total_llm_calls}\")\nprint(f\"Cumulative input tokens: {agent.cumulative_input_tokens:,}\")\nprint(f\"Cumulative output tokens: {agent.cumulative_output_tokens:,}\")\nprint(f\"Total tokens: {agent.cumulative_input_tokens + agent.cumulative_output_tokens:,}\")\n</code></pre>"},{"location":"usage/python-api/#use-cases","title":"Use Cases","text":"<ul> <li>Interactive debugging: Use in Jupyter notebooks for hands-on debugging with agent assistance</li> <li>Automation scripts: Build scripts that use the agent for complex tasks with human oversight</li> <li>Custom workflows: Integrate PatchPal into your own tools and pipelines</li> <li>Code review assistance: Programmatic code analysis with permission controls</li> <li>Batch processing: Process multiple tasks programmatically while maintaining control</li> <li>Testing and evaluation: Test agent behavior with different prompts and configurations</li> </ul>"},{"location":"usage/python-api/#key-features","title":"Key Features","text":"<ul> <li>Human-in-the-loop design: Permission prompts ensure human oversight (unlike fully autonomous frameworks)</li> <li>Stateful conversations: Agent maintains full conversation history</li> <li>Custom tools: Add your own Python functions (via CLI auto-discovery or API parameter) with automatic schema generation</li> <li>Automatic context management: Auto-compaction works the same as CLI</li> <li>All built-in tools available: File operations, git, web search, skills, etc.</li> <li>Model flexibility: Works with any LiteLLM-compatible model</li> <li>Token tracking: Monitor API usage and costs in real-time</li> <li>Environment variables respected: All <code>PATCHPAL_*</code> settings apply</li> </ul>"},{"location":"usage/python-api/#patchpal-vs-other-agent-frameworks","title":"PatchPal vs. Other Agent Frameworks","text":"<p>PatchPal is designed to support both human-in-the-loop workflows (default) and fully autonomous operation via Autopilot mode:</p> Feature PatchPal (Interactive) PatchPal (Autopilot) Autonomous Frameworks Design Philosophy Human oversight &amp; control Autonomous iteration Autonomous execution Permission System Interactive prompts for sensitive operations Disabled (sandbox only) Typically no prompts Primary Use Case Code assistance, debugging, interactive tasks Iterative development, batch tasks Automated workflows, batch processing Safety Model Write boundary protection, command blocking Sandboxed environments required Varies by framework Custom Tools Yes, with automatic schema generation Yes, same tools as interactive Yes (varies by framework) Best For Developers who want AI assistance with control Throwaway projects, rapid prototyping Automation, research, agent benchmarks <p>The Python API uses the same agent implementation as the CLI, so you get the complete feature set including permissions, safety guardrails, and context management.</p>"}]}